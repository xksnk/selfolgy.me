"""
Chat Coach Service - Separate chat service with personalization
Independent service for AI-powered coaching conversations
"""
import time
import asyncpg
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timezone
import json
import sys
import re

# Add path for Phase 2 components
sys.path.append('/home/ksnk/n8n-enterprise/projects/selfology')

from data_access.user_dao import UserDAO
from data_access.vector_dao import VectorDAO
from data_access.coach_vector_dao import CoachVectorDAO
from services.message_embedding_service import MessageEmbeddingService
from core.config import get_config
from core.logging import chat_logger, LoggerMixin

# Phase 2 component imports
from coach.components.enhanced_ai_router import EnhancedAIRouter
from coach.components.adaptive_communication_style import AdaptiveCommunicationStyle

# ðŸ”¥ NEW: Phase 2-3 component imports (Deep Questions + Micro Interventions)
from coach.components.deep_question_generator import DeepQuestionGenerator
from coach.components.micro_interventions import MicroInterventions

# ðŸ”¥ TRACK 3: Confidence Calculator + Vector Storytelling (Phase 2-3)
from coach.components.confidence_calculator import ConfidenceCalculator
from coach.components.vector_storytelling import VectorStorytelling

# ðŸ”¥ NEW: AI Clients for REAL responses (not templates!)
from selfology_bot.ai.clients import ai_client_manager
from selfology_bot.ai.router import AIModel


@dataclass
class ChatResponse:
    """Response from chat service"""
    success: bool
    message: str
    response_text: Optional[str] = None
    ai_model_used: Optional[str] = None
    processing_time: Optional[float] = None
    insights_detected: Optional[List[str]] = None
    personality_updates: Optional[Dict[str, float]] = None


@dataclass
class UserContext:
    """User context for personalized responses"""
    user_id: str
    personality_profile: Optional[Dict[str, Any]] = None
    recent_messages: List[Dict[str, Any]] = None
    insights_history: List[Dict[str, Any]] = None
    assessment_data: Optional[Dict[str, Any]] = None
    onboarding_answers: List[Dict[str, Any]] = None  # ðŸ”¥ NEW: User's onboarding answers (work, goals, etc.)
    context_stories: List[Dict[str, Any]] = None  # ðŸ”¥ NEW: Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ (Ñ†ÐµÐ»Ð¸, Ð´Ð¸Ð»ÐµÐ¼Ð¼Ñ‹, ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚)
    current_mood: Optional[str] = None
    conversation_stage: str = "general"


class ChatCoachService(LoggerMixin):
    """
    Independent Chat Coach Service

    Features:
    - Personalized responses based on user's psychological profile
    - Context-aware conversations with memory
    - Insight detection and storage
    - Personality-adaptive communication style
    - Independent from assessment system
    - ðŸ”¥ NEW: Deep question generation + Micro interventions (Phase 2-3)
    """

    def __init__(self, db_pool: Optional[asyncpg.Pool] = None):
        self.config = get_config()
        self.db_pool = db_pool

        # Initialize DAOs
        self.user_dao = UserDAO(db_pool)
        self.vector_dao = VectorDAO()

        # âš¡ NEW: CoachVectorDAO for fast Qdrant access
        self.coach_vector_dao = CoachVectorDAO()
        self.logger.info("âœ… CoachVectorDAO initialized for semantic search")

        # ðŸ”¥ NEW: MessageEmbeddingService for semantic search
        self.embedding_service = MessageEmbeddingService()
        self.logger.info("âœ… MessageEmbeddingService initialized (1536D OpenAI embeddings)")

        # Phase 2 components
        self.enhanced_router = EnhancedAIRouter()
        self.adaptive_styler = AdaptiveCommunicationStyle()
        self.logger.info("âœ… Phase 2 components initialized (Enhanced Router + Adaptive Style)")

        # ðŸ”¥ NEW: Phase 2-3 components  
        self.question_generator = DeepQuestionGenerator()
        self.micro_interventions = MicroInterventions()
        self.logger.info("âœ… Phase 2-3 components initialized (Deep Questions + Micro Interventions)")
        
        # ðŸ”¥ TRACK 3: Confidence + Storytelling (Phase 2-3)
        self.confidence_calc = ConfidenceCalculator()
        self.storyteller = VectorStorytelling()
        self.logger.info("âœ… TRACK 3 components initialized (Confidence + Storytelling)")

        # ðŸ”¥ NEW: AI Client Manager for REAL AI responses!
        self.ai_client = ai_client_manager
        self.logger.info("âœ… AI Client Manager initialized (Claude + OpenAI) - REAL RESPONSES ENABLED!")

        # Service configuration
        self.chat_config = self.config.get_service_config("chat_coach")
        self.context_window = self.chat_config.get("context_window", 10)
        self.personality_weight = self.chat_config.get("personality_weight", 0.7)
        self.memory_retention_days = self.chat_config.get("memory_retention_days", 30)

        # Response templates for different personality types
        self.response_templates = self._initialize_response_templates()

        # Conversation state (in production would use Redis)
        self.conversation_states = {}  # user_id -> conversation state

        self.logger.info("Chat Coach Service initialized")

    def _markdown_to_html(self, text: str) -> str:
        """
        Convert Markdown formatting to HTML for Telegram

        Converts:
        - **bold** â†’ <b>bold</b>
        - _italic_ â†’ <i>italic</i>
        - __italic__ â†’ <i>italic</i>
        - ***bold italic*** â†’ <b><i>bold italic</i></b>
        """
        if not text:
            return text

        # Convert ***bold italic*** first (before splitting into bold and italic)
        text = re.sub(r'\*\*\*(.+?)\*\*\*', r'<b><i>\1</i></b>', text)

        # Convert **bold**
        text = re.sub(r'\*\*(.+?)\*\*', r'<b>\1</b>', text)

        # Convert _italic_ and __italic__
        text = re.sub(r'__(.+?)__', r'<i>\1</i>', text)
        text = re.sub(r'_(.+?)_', r'<i>\1</i>', text)

        return text

    async def start_chat_session(self, user_id: str) -> ChatResponse:
        """Start new chat session for user"""

        start_time = time.time()
        self.logger.log_service_call("start_chat_session", user_id)

        try:
            # Load user context
            user_context = await self._load_user_context(user_id)

            # Initialize conversation state
            self.conversation_states[user_id] = {
                "session_start": datetime.now(timezone.utc),
                "message_count": 0,
                "current_topic": None,
                "conversation_energy": 0.5,
                "last_insight": None
            }

            # Generate welcome message based on user profile
            welcome_message = await self._generate_welcome_message(user_context)

            # Convert Markdown to HTML for Telegram
            welcome_message_html = self._markdown_to_html(welcome_message)

            # Log chat message
            await self.user_dao.save_chat_message(
                user_id, welcome_message_html, "assistant",
                ai_model_used="personalized_template",
                response_time=time.time() - start_time
            )

            processing_time = time.time() - start_time
            self.logger.log_service_result("start_chat_session", True, processing_time)

            return ChatResponse(
                success=True,
                message="Chat session started",
                response_text=welcome_message_html,
                ai_model_used="personalized_template",
                processing_time=processing_time
            )

        except Exception as e:
            self.logger.log_error("CHAT_START_ERROR", f"Failed to start chat: {e}", user_id, e)
            return ChatResponse(
                success=False,
                message=f"Failed to start chat: {str(e)}"
            )

    async def process_message(self, user_id: str, message: str) -> ChatResponse:
        """Process user message and generate personalized response"""

        start_time = time.time()
        self.logger.log_service_call("process_message", user_id, message_length=len(message))

        try:
            # Load user context
            user_context = await self._load_user_context(user_id)

            # Save user message
            user_msg_id = await self.user_dao.save_chat_message(
                user_id, message, "user"
            )

            # Analyze message for insights
            insights_detected = await self._analyze_message_for_insights(message, user_context)

            # Detect message type and intent
            message_analysis = await self._analyze_message_intent(message, user_context)

            # ðŸ”¥ NEW: Enhanced AI Router with psychological context
            message_context = {
                'message': message,
                'crisis_detected': any(word in message.lower() for word in ['ÐºÑ€Ð¸Ð·Ð¸Ñ', 'ÑÑƒÐ¸Ñ†Ð¸Ð´', 'Ð½Ðµ Ñ…Ð¾Ñ‡Ñƒ Ð¶Ð¸Ñ‚ÑŒ']),
                'existential_question': any(word in message.lower() for word in ['ÑÐ¼Ñ‹ÑÐ» Ð¶Ð¸Ð·Ð½Ð¸', 'Ð·Ð°Ñ‡ÐµÐ¼', 'ÐºÑ‚Ð¾ Ñ']),
                'depth_level': 'SHADOW' if len(message) > 200 else 'CONSCIOUS',
                'breakthrough_magnitude': 0.0,
                'needs_action_plan': message_analysis.get('intent') == 'advice_request',
                'emotional_support_needed': message_analysis.get('intent') == 'emotional_sharing'
            }

            # Route to optimal AI model
            recommended_model = self.enhanced_router.route(message_context)
            self.logger.info(f"ðŸ¤– Enhanced Router selected: {recommended_model}")

            # ðŸ”¥ NEW: Semantic search for similar emotional states (~200ms embedding + < 20ms search)
            similar_states = []
            trajectory_insights = None

            if user_context.personality_profile:
                # ðŸ”¥ QUICK FIX: Disable broken semantic search (embedding space mismatch)
                # ROOT CAUSE: Comparing personality narrative embeddings vs user message embeddings
                # TODO: Create chat_messages collection with message embeddings (see AI Engineer analysis)
                similar_states = []
                self.logger.warning(f"âš ï¸ Semantic search DISABLED (embedding space mismatch - personality narratives vs user messages)")

                # 3. Analyze personality trajectory for storytelling (< 30ms)
                trajectory_insights = await self.coach_vector_dao.analyze_personality_trajectory(
                    int(user_id),
                    window=20
                )
                
                if trajectory_insights:
                    # ðŸ”¥ TRACK 3: Add evolution points for storytelling
                    evolution_points = await self.coach_vector_dao.get_personality_trajectory(
                        int(user_id),
                        limit=132  # Full personality evolution history
                    )
                    trajectory_insights['evolution_points'] = evolution_points
                    
                    self.logger.info(
                        f"ðŸ“ˆ Trajectory: {len(trajectory_insights.get('insights', []))} insights, "
                        f"{len(evolution_points)} evolution points"
                    )

            # Generate personalized response (Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ similar_states + trajectory)
            response_text = await self._generate_personalized_response(
                user_id, message, user_context, message_analysis, similar_states, trajectory_insights
            )

            # ðŸ”¥ NEW: Generate deep follow-up questions (Phase 2-3)
            user_context_dict = {
                'big_five': user_context.personality_profile.get('traits', {}).get('big_five', {}) if user_context.personality_profile else {},
                'conversation_stage': user_context.conversation_stage,
                'current_mood': user_context.current_mood,
                'personality_profile': user_context.personality_profile
            }

            message_ctx = {
                'intent': message_analysis.get('intent'),
                'domain': message_analysis.get('domain', 'general'),
                'emotional_intensity': message_analysis.get('emotional_intensity', 'medium'),
                'insights_detected': len(insights_detected) > 0,
                'goal_related': message_analysis.get('intent') == 'advice_request'
            }

            deep_questions = self.question_generator.generate_questions(
                user_context=user_context_dict,
                message_context=message_ctx,
                count=2
            )

            if deep_questions:
                # Add questions to response
                questions_text = "\n\nðŸ¤” **Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ ÑƒÐ³Ð»ÑƒÐ±Ð¸Ð¼ÑÑ:**\n" + "\n".join(f"â€¢ {q}" for q in deep_questions)
            else:
                questions_text = ""

            self.logger.info(f"ðŸ’­ Generated {len(deep_questions)} deep questions")

            # ðŸ”¥ NEW: Apply Micro Interventions to final response (Phase 2-3)
            intervention_context = {
                'negative_belief_detected': any(word in message.lower() for word in ['Ð½Ðµ Ð¼Ð¾Ð³Ñƒ', 'Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾', 'Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑÑ']),
                'negative_statement': message[:100] if any(word in message.lower() for word in ['Ð½Ðµ Ð¼Ð¾Ð³Ñƒ', 'Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾']) else '',
                'positive_state_detected': any(word in message.lower() for word in ['Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ', 'ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ', 'ÑÐ¼Ð¾Ð³']),
                'positive_state': 'ÑƒÑÐ¿ÐµÑ…' if 'Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ' in message.lower() else '',
                'comfort_zone_detected': message_analysis.get('intent') == 'progress_sharing'
            }

            final_response_with_interventions = self.micro_interventions.inject(
                response_text + questions_text,
                intervention_context
            )

            # Convert Markdown to HTML for Telegram
            final_response_html = self._markdown_to_html(final_response_with_interventions)

            # ðŸ”¥ TRACK 3: Store insights with confidence scores
            if insights_detected:
                for insight in insights_detected:
                    # Calculate confidence for insight
                    confidence, explanation = self.confidence_calc.calculate(
                        insight=insight,
                        user_context=user_context.__dict__
                    )
                    
                    insight['confidence'] = confidence
                    insight['confidence_explanation'] = explanation
                    
                    # Format insight with confidence
                    formatted_insight = self.confidence_calc.format_with_confidence(
                        insight["text"],
                        confidence,
                        explanation
                    )
                    
                    self.logger.info(f"ðŸ’¡ Insight confidence: {confidence:.2f} - {insight['type']}")
                    
                    await self.user_dao.save_user_insight(
                        user_id, formatted_insight, insight["type"],
                        insight.get("domain"), confidence
                    )

            # Update personality profile if significant markers detected
            personality_updates = await self._extract_personality_updates(message, user_context)
            if personality_updates:
                # This could trigger vector updates
                pass

            # ðŸ”¥ NEW: Save AI response with Enhanced Router's model selection + deep questions metadata
            ai_msg_id = await self.user_dao.save_chat_message(
                user_id, final_response_html, "assistant",
                ai_model_used=recommended_model,
                insights={"detected_insights": len(insights_detected), "deep_questions": len(deep_questions)},
                response_time=time.time() - start_time
            )

            # Update conversation state
            if user_id in self.conversation_states:
                self.conversation_states[user_id]["message_count"] += 1
                self.conversation_states[user_id]["last_interaction"] = datetime.now(timezone.utc)

                if insights_detected:
                    self.conversation_states[user_id]["last_insight"] = insights_detected[0]

            processing_time = time.time() - start_time
            self.logger.log_service_result("process_message", True, processing_time,
                                         insights_count=len(insights_detected))

            return ChatResponse(
                success=True,
                message="Message processed successfully",
                response_text=final_response_html,
                ai_model_used=recommended_model,
                processing_time=processing_time,
                insights_detected=[i["text"] for i in insights_detected],
                personality_updates=personality_updates
            )

        except Exception as e:
            self.logger.log_error("MESSAGE_PROCESSING_ERROR",
                                 f"Failed to process message: {e}", user_id, e)
            return ChatResponse(
                success=False,
                message=f"Failed to process message: {str(e)}"
            )

    async def get_conversation_history(self, user_id: str, limit: int = 20) -> ChatResponse:
        """Get conversation history for user"""

        self.logger.log_service_call("get_conversation_history", user_id, limit=limit)

        try:
            messages = await self.user_dao.get_recent_chat_history(user_id, limit)

            # Format messages for display
            formatted_history = []
            for msg in messages:
                formatted_history.append({
                    "timestamp": msg["timestamp"].isoformat(),
                    "type": msg["message_type"],
                    "content": msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"],
                    "ai_model": msg.get("ai_model_used")
                })

            self.logger.log_service_result("get_conversation_history", True)

            return ChatResponse(
                success=True,
                message="History retrieved",
                response_text=json.dumps(formatted_history, ensure_ascii=False)
            )

        except Exception as e:
            self.logger.log_error("HISTORY_RETRIEVAL_ERROR",
                                 f"Failed to get history: {e}", user_id, e)
            return ChatResponse(
                success=False,
                message=f"Failed to get history: {str(e)}"
            )

    async def _load_user_context(self, user_id: str) -> UserContext:
        """Load comprehensive user context for personalization

        ðŸ”¥ NEW: Uses Qdrant for fast semantic search (< 20ms)
        """

        # Get user profile with personality data
        user_profile = await self.user_dao.get_user_profile(user_id)

        # Get recent conversation history
        recent_messages = await self.user_dao.get_recent_chat_history(user_id, self.context_window)

        # Get user insights
        insights_history = await self.user_dao.get_user_insights(user_id, 10)

        # âš¡ NEW: Get personality vector from QDRANT (< 10ms)
        personality_vector = await self.coach_vector_dao.get_current_personality_vector(int(user_id))

        if personality_vector:
            self.logger.info(f"âœ… Loaded personality vector from Qdrant for user {user_id}")
        else:
            self.logger.warning(f"âš ï¸ No personality vector in Qdrant for user {user_id}")

        # ðŸ”¥ NEW: Get onboarding answers (work, goals, challenges, etc.)
        onboarding_answers = await self.user_dao.get_onboarding_answers(user_id, limit=30)
        if onboarding_answers:
            self.logger.info(f"âœ… Loaded {len(onboarding_answers)} onboarding answers for user {user_id}")
        else:
            self.logger.info(f"â„¹ï¸ No onboarding answers found for user {user_id}")

        # ðŸ”¥ NEW: Get context stories (ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹: Ð´Ð¸Ð»ÐµÐ¼Ð¼Ñ‹, Ñ†ÐµÐ»Ð¸, ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚)
        context_stories = await self.user_dao.get_context_stories(user_id, limit=10)
        if context_stories:
            self.logger.info(f"âœ… Loaded {len(context_stories)} context stories for user {user_id}")
        else:
            self.logger.info(f"â„¹ï¸ No context stories found for user {user_id}")

        # Analyze current mood from recent messages
        current_mood = self._analyze_current_mood(recent_messages)

        # Determine conversation stage
        conversation_stage = self._determine_conversation_stage(user_profile, recent_messages)

        return UserContext(
            user_id=user_id,
            personality_profile=personality_vector,
            recent_messages=recent_messages,
            insights_history=insights_history,
            assessment_data=user_profile.get("assessment_stats") if user_profile else None,
            onboarding_answers=onboarding_answers,
            context_stories=context_stories,
            current_mood=current_mood,
            conversation_stage=conversation_stage
        )

    async def _generate_welcome_message(self, user_context: UserContext) -> str:
        """Generate personalized welcome message"""

        user_profile = user_context.personality_profile
        assessment_complete = user_context.assessment_data and user_context.assessment_data.get("total_answers", 0) > 10

        # Personalize based on personality if available
        if user_profile and user_profile.get("traits"):
            # âš¡ NEW: Qdrant structure has "big_five" instead of "personality"
            personality = user_profile["traits"].get("big_five", {})

            # High extraversion - energetic greeting
            if personality.get("extraversion", 0) > 0.7:
                base_greeting = "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð Ð°Ð´ Ð½Ð°ÑˆÐµÐ¼Ñƒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÑŽ! Ð“Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ Ñ‚ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð²Ð°Ñ Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÐµÑ‚?"

            # High openness - creative greeting
            elif personality.get("openness", 0) > 0.7:
                base_greeting = "Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ! Ð’ÑÐµÐ³Ð´Ð° Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð¸Ð´ÐµÐ¸ Ð²Ð¼ÐµÑÑ‚Ðµ. Ðž Ñ‡ÐµÐ¼ Ð´ÑƒÐ¼Ð°ÐµÑ‚Ðµ?"

            # High conscientiousness - structured greeting
            elif personality.get("conscientiousness", 0) > 0.7:
                base_greeting = "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð“Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð°ÑˆÐ¸ Ð¼Ñ‹ÑÐ»Ð¸ Ð¸ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ."

            # Default
            else:
                base_greeting = "ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð“Ð¾Ñ‚Ð¾Ð² Ð²Ñ‹ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ. Ð§Ñ‚Ð¾ Ñƒ Ð²Ð°Ñ Ð½Ð° Ð´ÑƒÑˆÐµ?"

        else:
            base_greeting = "Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ! Ð¯ Ð²Ð°Ñˆ AI-ÐºÐ¾ÑƒÑ‡. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ ÑÐµÐ³Ð¾Ð´Ð½Ñ?"

        # Add context based on assessment status
        if assessment_complete:
            context_addition = "\n\nÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ Ð¼Ð¾Ð³Ñƒ Ð´Ð°Ñ‚ÑŒ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð²ÐµÑ‚Ñ‹."
        else:
            context_addition = "\n\nÐ ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ Ð¿Ñ€Ð¾Ð¹Ñ‚Ð¸ Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð°Ð½ÐºÐµÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ñ… ÑÐ¾Ð²ÐµÑ‚Ð¾Ð²."

        return base_greeting + context_addition

    async def _analyze_message_for_insights(self, message: str,
                                          user_context: UserContext) -> List[Dict[str, Any]]:
        """Analyze message for psychological insights"""

        insights = []
        message_lower = message.lower()

        # Insight patterns
        insight_patterns = [
            ("Ñ Ð¿Ð¾Ð½ÑÐ»", "realization"),
            ("Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ", "discovery"),
            ("Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÑŽ Ñ‡Ñ‚Ð¾", "understanding"),
            ("Ð¾ÑÐ¾Ð·Ð½Ð°ÑŽ", "awareness"),
            ("Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ", "conclusion")
        ]

        for pattern, insight_type in insight_patterns:
            if pattern in message_lower:
                # Extract the insight context
                pattern_index = message_lower.find(pattern)
                insight_context = message[max(0, pattern_index-20):pattern_index+100]

                insights.append({
                    "text": insight_context.strip(),
                    "type": f"spontaneous_{insight_type}",
                    "confidence": 0.7,
                    "domain": self._detect_psychological_domain(insight_context)
                })

        # Emotional state insights
        if any(word in message_lower for word in ["Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ", "Ð¼Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ", "Ñ Ð²"]):
            emotional_insight = self._extract_emotional_insight(message)
            if emotional_insight:
                insights.append(emotional_insight)

        # Goal-related insights
        if any(word in message_lower for word in ["Ñ…Ð¾Ñ‡Ñƒ", "Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÑŽ", "Ð¼ÐµÑ‡Ñ‚Ð°ÑŽ", "ÑÑ‚Ñ€ÐµÐ¼Ð»ÑŽÑÑŒ"]):
            goal_insight = self._extract_goal_insight(message)
            if goal_insight:
                insights.append(goal_insight)

        return insights

    async def _analyze_message_intent(self, message: str,
                                    user_context: UserContext) -> Dict[str, Any]:
        """Analyze message intent and determine response strategy"""

        message_lower = message.lower()

        # Question patterns
        if any(marker in message_lower for marker in ["ÐºÐ°Ðº", "Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ", "Ð¿Ð¾Ð¼Ð¾Ð³Ð¸", "ÑÐ¾Ð²ÐµÑ‚", "?"]):
            return {
                "intent": "advice_request",
                "urgency": "high" if any(word in message_lower for word in ["ÑÑ€Ð¾Ñ‡Ð½Ð¾", "Ð¿Ð¾Ð¼Ð¾Ð³Ð¸Ñ‚Ðµ", "Ð½Ðµ Ð·Ð½Ð°ÑŽ Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ"]) else "normal",
                "domain": self._detect_psychological_domain(message),
                "recommended_model": "gpt-4o"  # More sophisticated for advice
            }

        # Emotional sharing
        if any(marker in message_lower for marker in ["Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ", "Ð¿ÐµÑ€ÐµÐ¶Ð¸Ð²Ð°ÑŽ", "Ð±Ð¾Ð»Ð¸Ñ‚", "Ñ‚Ñ€ÑƒÐ´Ð½Ð¾"]):
            return {
                "intent": "emotional_sharing",
                "emotional_intensity": self._assess_emotional_intensity(message),
                "support_needed": True,
                "recommended_model": "gpt-4o-mini"
            }

        # Progress sharing
        if any(marker in message_lower for marker in ["Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ", "ÑÐ´ÐµÐ»Ð°Ð»", "ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ", "Ð´Ð¾ÑÑ‚Ð¸Ð³"]):
            return {
                "intent": "progress_sharing",
                "celebration_appropriate": True,
                "recommended_model": "gpt-4o-mini"
            }

        # General conversation
        return {
            "intent": "general_conversation",
            "recommended_model": "gpt-4o-mini"
        }

    async def _generate_personalized_response(
        self,
        user_id: str,
        message: str,
        user_context: UserContext,
        message_analysis: Dict[str, Any],
        similar_states: List[Dict[str, Any]] = None,
        trajectory_insights: Dict[str, Any] = None
    ) -> str:
        """Generate personalized response based on user's personality and context

        ðŸ”¥ NEW: Uses similar_states from Qdrant + trajectory insights for deeply personalized responses
        """

        intent = message_analysis.get("intent", "general_conversation")
        # âš¡ NEW: Qdrant structure has "big_five" instead of "personality"
        personality = user_context.personality_profile.get("traits", {}).get("big_five", {}) if user_context.personality_profile else {}

        # ðŸ”¥ HYBRID CONTEXT: Build enriched context from multiple sources
        context_enrichment = ""

        # 1. Recent conversation topics (ÐÐžÐ’ÐžÐ• - Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚ broken semantic search)
        recent_topics = self._extract_recent_topics_from_context(user_context)
        if recent_topics:
            context_enrichment += f"\n\nðŸ—¨ï¸ _ÐÐµÐ´Ð°Ð²Ð½Ð¾ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð»Ð¸: {', '.join(recent_topics)}_"
            self.logger.info(f"ðŸ’¬ Added recent topics: {recent_topics}")

        # 2. Work/business context from onboarding (ÐÐžÐ’ÐžÐ• - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ 84 Ð¾Ñ‚Ð²ÐµÑ‚Ð°!)
        if intent == "advice_request" and message_analysis.get("domain") == "work":
            work_background = self._extract_work_background_from_onboarding(user_context)
            if work_background:
                context_enrichment += f"\n\nðŸ’¼ _Ð’Ð°Ñˆ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {work_background}_"
                self.logger.info(f"ðŸ’¼ Added work background from onboarding")

        # 3. Personality trajectory insights (ÑƒÐ¶Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚)
        if trajectory_insights and trajectory_insights.get("insights"):
            # Add most relevant insight (first one is usually most significant)
            top_insight = trajectory_insights["insights"][0]
            context_enrichment += f"\n\nðŸ“ˆ _{top_insight}_"

        # ðŸ”¥ TRACK 3: Add personality journey narrative (Ð¢ÐžÐ›Ð¬ÐšÐž Ð´Ð»Ñ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²)
        if user_context.personality_profile and trajectory_insights:
            evolution_points = trajectory_insights.get('evolution_points', [])

            # ðŸ”¥ FIX: ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ storytelling Ð´Ð»Ñ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°
            intent = message_analysis.get("intent", "general_conversation")
            domain = message_analysis.get("domain", "general")

            # Storytelling Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚ÐµÐ½ Ð¢ÐžÐ›Ð¬ÐšÐž Ð´Ð»Ñ:
            # 1. Ð­Ð¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
            # 2. Ð’Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¿Ñ€Ð¾ self-identity
            # 3. Ð’Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¿Ñ€Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ/Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ
            is_emotional_context = (
                intent == "emotional_sharing" or
                domain == "emotions" or
                any(keyword in message.lower() for keyword in [
                    "ÐºÑ‚Ð¾ Ñ", "Ñ‡Ñ‚Ð¾ ÑÐ¾ Ð¼Ð½Ð¾Ð¹", "ÐºÐ°Ðº Ñ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»ÑÑ",
                    "Ð¼Ð¾Ð¹ Ð¿ÑƒÑ‚ÑŒ", "Ð¼Ð¾Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ", "Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ"
                ])
            )

            # Ð”Ð»Ñ Ð±Ð¸Ð·Ð½ÐµÑ-Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¸ advice_request - ÐÐ• Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
            is_action_oriented = (
                intent == "advice_request" or
                domain in ["work", "future"] or
                any(keyword in message.lower() for keyword in [
                    "Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ", "ÐºÐ°Ðº Ñ€ÐµÑˆÐ¸Ñ‚ÑŒ", "Ð¿Ð¾Ð¼Ð¾Ð³Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ",
                    "Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ", "Ð±Ð¸Ð·Ð½ÐµÑ", "Ð¿Ñ€Ð¾ÐµÐºÑ‚", "Ð±Ð»Ð¾Ð³"
                ])
            )

            if is_emotional_context and not is_action_oriented and len(evolution_points) >= 3:
                narrative = await self.storyteller.create_narrative(
                    user_id=int(user_id),
                    evolution_points=evolution_points
                )

                if narrative:
                    context_enrichment += f"\n\n{narrative}"
                    self.logger.info(f"ðŸ“– Added personality journey narrative ({len(narrative)} chars)")
            else:
                self.logger.info(f"ðŸ“– Skipped storytelling (not relevant for {intent}/{domain})")

        # ðŸ”¥ NEW: Call REAL AI instead of templates!
        try:
            # 1. Build system prompt with personality context
            system_prompt = self._build_ai_system_prompt(user_context, intent, context_enrichment)

            # 2. Build conversation messages
            messages = self._build_conversation_messages(user_context, message)

            # 3. Map Enhanced Router's model selection to AIModel enum
            recommended_model_str = self.enhanced_router.route({
                'message': message,
                'needs_action_plan': intent == 'advice_request',
                'emotional_support_needed': intent == 'emotional_sharing'
            })

            model_mapping = {
                'claude-3-5-sonnet': AIModel.CLAUDE_SONNET,
                'gpt-4o': AIModel.GPT_4,
                'gpt-4o-mini': AIModel.GPT_4O_MINI
            }
            ai_model = model_mapping.get(recommended_model_str, AIModel.GPT_4O_MINI)

            # 4. REAL AI CALL - This is where the magic happens!
            self.logger.info(f"ðŸ¤– Calling AI with model: {ai_model.value}")
            ai_response = await self.ai_client.generate_response(
                model=ai_model,
                messages=messages,
                system_prompt=system_prompt,
                max_tokens=1500,  # Enough for deep, detailed responses
                temperature=0.7   # Balanced creativity
            )

            self.logger.info(f"âœ… AI response generated: {len(ai_response)} chars")

            # 5. Add context enrichment to AI response
            final_response = ai_response
            if context_enrichment:
                final_response += context_enrichment

            return final_response

        except Exception as e:
            self.logger.error(f"âŒ AI call failed: {e}")
            # Fallback to simple template if AI fails
            return f"ðŸ’™ ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÑŽ Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, ÑÐµÐ¹Ñ‡Ð°Ñ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð° Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°.{context_enrichment}"

    def _extract_user_interests(self, user_context: UserContext) -> List[Dict[str, str]]:
        """
        Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹/ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¸Ð·Ñƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð· onboarding answers

        Returns:
            List[{direction: str, why: str}] - Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ Ð¾Ð±Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼
        """
        interests = []

        if not user_context.onboarding_answers:
            return interests

        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ psychological_insights Ð´Ð»Ñ Ð²Ñ‹ÑÐ²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²
        for answer in user_context.onboarding_answers:
            insights = answer.get('psychological_insights', '')

            if insights and isinstance(insights, str):
                insights_lower = insights.lower()

                # Ð˜Ñ‰ÐµÐ¼ Ñ‚ÐµÐ¼Ñ‹/Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹ Ð² Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð°Ñ…
                if any(keyword in insights_lower for keyword in ['Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÑ‚Ð²Ð¾', 'ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²', 'ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ', 'Ð´Ð¸Ð·Ð°Ð¹Ð½']):
                    interests.append({
                        'direction': 'Ð¢Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ (Ð´Ð¸Ð·Ð°Ð¹Ð½, Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾, ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²)',
                        'why': 'Ð²Ð¸Ð¶Ñƒ Ð²Ð°Ñˆ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð» Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ñ…'
                    })

                if any(keyword in insights_lower for keyword in ['Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ', 'Ð»ÑŽÐ´Ð¸', 'Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°', 'ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð¸Ñ€', 'ÐºÐ¾ÑƒÑ‡']):
                    interests.append({
                        'direction': 'ÐŸÐ¾Ð¼Ð¾Ð³Ð°ÑŽÑ‰Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ (ÐºÐ¾ÑƒÑ‡Ð¸Ð½Ð³, ÑÐ¾Ð²ÐµÑ‚Ñ‹, Ð½Ð°ÑÑ‚Ð°Ð²Ð½Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾)',
                        'why': 'Ð·Ð°Ð¼ÐµÑ‚Ð½Ð° Ð²Ð°ÑˆÐ° Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ð¼'
                    })

                if any(keyword in insights_lower for keyword in ['Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°', 'Ð¸Ð·ÑƒÑ‡Ð°Ñ‚ÑŒ', 'Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ', 'Ð°Ð½Ð°Ð»Ð¸Ð·', 'Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°']):
                    interests.append({
                        'direction': 'ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ (Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ, Ð¾Ð±Ð·Ð¾Ñ€Ñ‹, Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°)',
                        'why': 'Ð²Ð¸Ð´Ð½Ð° Ð²Ð°ÑˆÐ° ÑÐºÐ»Ð¾Ð½Ð½Ð¾ÑÑ‚ÑŒ Ðº Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¾Ð¼Ñƒ Ð°Ð½Ð°Ð»Ð¸Ð·Ñƒ'
                    })

                if any(keyword in insights_lower for keyword in ['Ð±Ð¸Ð·Ð½ÐµÑ', 'Ð¿Ñ€ÐµÐ´Ð¿Ñ€Ð¸Ð½Ð¸Ð¼', 'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³', 'Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ']):
                    interests.append({
                        'direction': 'Ð‘Ð¸Ð·Ð½ÐµÑ-ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ (ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸, ÐºÐµÐ¹ÑÑ‹, Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ)',
                        'why': 'Ð·Ð°Ð¼ÐµÑ‚ÐµÐ½ Ð²Ð°Ñˆ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑ Ðº Ð±Ð¸Ð·Ð½ÐµÑÑƒ Ð¸ Ñ€Ð¾ÑÑ‚Ñƒ'
                    })

                if any(keyword in insights_lower for keyword in ['Ñ‚ÐµÑ…Ð½Ð¾', 'it', 'Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼', 'ÐºÐ¾Ð´']):
                    interests.append({
                        'direction': 'Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ (IT, Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, Ð¸Ð½Ð½Ð¾Ð²Ð°Ñ†Ð¸Ð¸)',
                        'why': 'Ð²Ð¸Ð´Ð½Ð° Ð²Ð°ÑˆÐ° Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð¸Ð·Ð°'
                    })

        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
        unique_interests = []
        seen = set()
        for interest in interests:
            if interest['direction'] not in seen:
                unique_interests.append(interest)
                seen.add(interest['direction'])

        return unique_interests[:5]  # ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ 5 Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹

    def _generate_advice_response(self, message: str, personality: Dict[str, float],
                                user_context: UserContext, analysis: Dict[str, Any]) -> str:
        """Generate advice response adapted to personality"""

        domain = analysis.get("domain", "general")

        # ðŸ”¥ FIX: Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸ÑŽ Ð¸Ð· psychological_insights, ÐÐ• Ð¸Ð· ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ñ… raw_answer
        user_context_info = ""
        if user_context.onboarding_answers:
            # Ð˜Ñ‰ÐµÐ¼ ÐšÐžÐÐšÐ Ð•Ð¢ÐÐ«Ð• Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¿Ñ€Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ/Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸ÑŽ/ÐºÐ°Ñ€ÑŒÐµÑ€Ñƒ
            work_insights = []

            for answer in user_context.onboarding_answers:
                insights = answer.get('psychological_insights')

                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð² Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð°Ñ… Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ
                if insights and isinstance(insights, str):
                    insights_lower = insights.lower()
                    # Ð˜Ñ‰ÐµÐ¼ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð¿Ñ€Ð¾ Ð ÐÐ‘ÐžÐ¢Ð£ (Ð½Ðµ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ, Ð½Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¸)
                    if any(keyword in insights_lower for keyword in [
                        'Ñ€Ð°Ð±Ð¾Ñ‚Ð°', 'Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ñ', 'ÐºÐ°Ñ€ÑŒÐµÑ€Ð°', 'ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾',
                        'Ð´Ð¾Ð»Ð¶Ð½Ð¾ÑÑ‚ÑŒ', 'Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ÑÑ', 'Ñ‚Ñ€ÑƒÐ´Ð¸Ñ‚ÑÑ', 'Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ ÐºÐ°Ðº'
                    ]):
                        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°: ÐÐ• Ð¿Ñ€Ð¾ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ/ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð¾Ð²
                        if not any(health_word in insights_lower for health_word in [
                            'Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ', 'Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ', 'Ð²Ñ€Ð°Ñ‡', 'Ñ‚Ñ€ÐµÐ½ÐµÑ€ Ð´Ð»Ñ', 'ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð´Ð»Ñ'
                        ]):
                            work_insights.append(insights)

            # Ð•ÑÐ»Ð¸ Ð½Ð°ÑˆÐ»Ð¸ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¿Ñ€Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¸Ñ…
            if work_insights:
                # Ð‘ÐµÑ€ÐµÐ¼ ÑÐ°Ð¼Ñ‹Ð¹ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹ (Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¹)
                work_context = work_insights[0]
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑÑƒÑ‚ÑŒ (Ð¿ÐµÑ€Ð²Ñ‹Ðµ 80 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)
                if len(work_context) > 80:
                    work_context = work_context[:80] + "..."
                user_context_info = f"\n\n_ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐ¸Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð²Ð¸Ð¶Ñƒ: {work_context}_"
                self.logger.info(f"ðŸ’¼ Using work context from insights: {work_context[:50]}...")
            # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð¸Ð½ÑÐ°Ð¹Ñ‚Ð¾Ð² Ð¿Ñ€Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ - ÐÐ• Ð¿Ñ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸ÑŽ
            else:
                self.logger.info(f"ðŸ’¼ No work context found in onboarding answers, skipping context_info")

        # Base advice structure
        response = f"ðŸŽ¯ **ÐŸÐ¾Ð½ÑÐ» Ð²Ð°ÑˆÑƒ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ.**{user_context_info}\n\n"

        # Personality-adapted advice style
        if personality.get("conscientiousness", 0) > 0.7:
            # Structured, step-by-step advice
            response += "**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´:**\n"
            response += "1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ\n"
            response += "2. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑˆÐ°Ð³Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹\n"
            response += "3. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ñ€ÐµÐ°Ð»Ð¸ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÑ€Ð¾ÐºÐ¸\n\n"

        elif personality.get("openness", 0) > 0.7:
            # Creative, exploratory advice
            response += "**ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´:**\n"
            response += "â€¢ Ð Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ Ð½ÐµÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ\n"
            response += "â€¢ ÐŸÐ¾Ð´ÑƒÐ¼Ð°Ð¹Ñ‚Ðµ Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑÑ… Ð² ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸\n"
            response += "â€¢ Ð­ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð°Ð¼Ð¸\n\n"

        else:
            # ðŸ”¥ FIX #5: Ð”Ð»Ñ Ð±Ð¸Ð·Ð½ÐµÑ-Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² - ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²
            message_lower = message.lower()
            is_business_question = (
                domain == "work" and
                any(keyword in message_lower for keyword in [
                    'Ð±Ð»Ð¾Ð³', 'ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚', 'Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ', 'Ñ‡Ñ‚Ð¾ Ð¿Ð¾ÑÑ‚Ð¸Ñ‚ÑŒ',
                    'Ð±Ð¸Ð·Ð½ÐµÑ', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚', 'Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ', 'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ'
                ])
            )

            if is_business_question:
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
                interests = self._extract_user_interests(user_context)

                if interests:
                    response += "**ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ Ð²Ð¸Ð¶Ñƒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹:**\n\n"
                    for interest in interests:
                        response += f"â€¢ **{interest['direction']}**  \n  _{interest['why']}_\n\n"
                    response += "**ÐœÐ¾Ð¹ ÑÐ¾Ð²ÐµÑ‚:** Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ 2-3 Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸.\n\n"
                    self.logger.info(f"ðŸ’¡ Generated {len(interests)} concrete recommendations for business question")
                else:
                    # Fallback ÐµÑÐ»Ð¸ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹
                    response += "**ÐœÐ¾Ð¹ ÑÐ¾Ð²ÐµÑ‚:**\n"
                    response += "Ð Ð°Ð·Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.\n\n"
            else:
                # Balanced advice Ð´Ð»Ñ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
                response += "**ÐœÐ¾Ð¹ ÑÐ¾Ð²ÐµÑ‚:**\n"
                response += "Ð Ð°Ð·Ð»Ð¾Ð¶Ð¸Ñ‚Ðµ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸ Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.\n\n"

        # Add domain-specific advice
        if domain == "relationships":
            response += "ðŸ’™ **ÐŸÐ¾Ð¼Ð½Ð¸Ñ‚Ðµ:** Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð°Ñ ÐºÐ¾Ð¼Ð¼ÑƒÐ½Ð¸ÐºÐ°Ñ†Ð¸Ñ - Ð¾ÑÐ½Ð¾Ð²Ð° ÐºÑ€ÐµÐ¿ÐºÐ¸Ñ… Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ð¹."
        elif domain == "work":
            response += "ðŸš€ **Ð’Ð°Ð¶Ð½Ð¾:** Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ñ†ÐµÐ»Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ Ð²Ð°ÑˆÐ¸Ð¼ Ñ†ÐµÐ½Ð½Ð¾ÑÑ‚ÑÐ¼."
        elif domain == "emotions":
            response += "ðŸŒ± **ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°:** Ð²Ð°ÑˆÐ¸ ÑÐ¼Ð¾Ñ†Ð¸Ð¸ - Ñ†ÐµÐ½Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚ÑÑ…."

        response += "\n\nÐ“Ð¾Ñ‚Ð¾Ð² Ð¾Ð±ÑÑƒÐ´Ð¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»Ð¸! Ð§Ñ‚Ð¾ Ð²Ð°Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð±ÐµÑÐ¿Ð¾ÐºÐ¾Ð¸Ñ‚ Ð² ÑÑ‚Ð¾Ð¹ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸?"

        return response

    def _generate_supportive_response(self, message: str, personality: Dict[str, float],
                                    user_context: UserContext, analysis: Dict[str, Any]) -> str:
        """Generate supportive response for emotional sharing"""

        emotional_intensity = analysis.get("emotional_intensity", "medium")

        if emotional_intensity == "high":
            response = "ðŸ’™ **ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÑŽ, Ñ‡Ñ‚Ð¾ Ð²Ð°Ð¼ ÑÐµÐ¹Ñ‡Ð°Ñ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ‚ÑÐ¶ÐµÐ»Ð¾.**\n\n"
            response += "Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð´Ð¾Ð²ÐµÑ€Ð¸Ðµ. ÐŸÐ¾Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ð¼Ð¸ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð°Ð¼Ð¸ - ÑÑ‚Ð¾ ÑƒÐ¶Ðµ ÑˆÐ°Ð³ Ðº Ð¸Ñ… Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸ÑŽ.\n\n"
        else:
            response = "ðŸ¤— **Ð¡Ð»Ñ‹ÑˆÑƒ Ð²Ð°Ñ.**\n\n"
            response += "Ð’Ð°Ð¶Ð½Ð¾ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ð²Ð°Ñ‚ÑŒ ÑÐ²Ð¾Ð¸ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð° Ð¸ Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð¸Ð¼ Ð¼ÐµÑÑ‚Ð¾.\n\n"

        # Personality-adapted support
        if personality.get("agreeableness", 0) > 0.6:
            # They value harmony and relationships
            response += "**ðŸ’š ÐŸÐ¾Ð¼Ð½Ð¸Ñ‚Ðµ:**\n"
            response += "â€¢ Ð’Ñ‹ Ð½Ðµ Ð¾Ð´Ð¸Ð½Ð¾ÐºÐ¸ Ð² ÑÐ²Ð¾Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸ÑÑ…\n"
            response += "â€¢ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð±Ð»Ð¸Ð·ÐºÐ¸Ñ… Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ†ÐµÐ½Ð½Ð¾Ð¹\n"
            response += "â€¢ Ð—Ð°Ð±Ð¾Ñ‚Ð° Ð¾ ÑÐµÐ±Ðµ - Ð½Ðµ ÑÐ³Ð¾Ð¸Ð·Ð¼\n\n"

        elif personality.get("conscientiousness", 0) > 0.6:
            # They prefer practical solutions
            response += "**ðŸŽ¯ Ð§Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ:**\n"
            response += "â€¢ Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¿Ð»Ð°Ð½ ÑÐ°Ð¼Ð¾Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸\n"
            response += "â€¢ ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑˆÐ°Ð³Ð¸ Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸\n"
            response += "â€¢ ÐžÑ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ Ð² Ð¿Ñ€ÐµÐ¾Ð´Ð¾Ð»ÐµÐ½Ð¸Ð¸ Ñ‚Ñ€ÑƒÐ´Ð½Ð¾ÑÑ‚ÐµÐ¹\n\n"

        else:
            response += "**ðŸŒŸ ÐÐ°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ðµ:**\n"
            response += "Ð­Ñ‚Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ. Ð’Ñ‹ ÑÐ¿Ñ€Ð°Ð²Ð¸Ñ‚ÐµÑÑŒ.\n\n"

        response += "Ð¥Ð¾Ñ‚Ð¸Ñ‚Ðµ Ñ€Ð°ÑÑÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð±Ð¾Ð»ÑŒÑˆÐµ? Ð¯ Ð·Ð´ÐµÑÑŒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ñ‹ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ. ðŸ’š"

        return response

    def _generate_celebratory_response(self, message: str, personality: Dict[str, float],
                                     user_context: UserContext) -> str:
        """Generate celebratory response for progress sharing"""

        if personality.get("extraversion", 0) > 0.7:
            # Enthusiastic celebration
            response = "ðŸŽ‰ **Ð’Ð°Ñƒ, ÑÑ‚Ð¾ Ð¿Ð¾Ñ‚Ñ€ÑÑÐ°ÑŽÑ‰Ðµ!**\n\n"
            response += "Ð’Ð°Ñˆ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ Ð²Ð¿ÐµÑ‡Ð°Ñ‚Ð»ÑÐµÑ‚! ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°! ðŸš€\n\n"
        else:
            # Warm but measured celebration
            response = "âœ¨ **ÐŸÐ¾Ð·Ð´Ñ€Ð°Ð²Ð»ÑÑŽ Ñ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸ÐµÐ¼!**\n\n"
            response += "Ð­Ñ‚Ð¾ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ. ðŸ‘\n\n"

        response += "**ðŸŽ¯ Ð§Ñ‚Ð¾ ÑÑ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚:**\n"
        response += "â€¢ Ð’Ñ‹ Ð´Ð²Ð¸Ð¶ÐµÑ‚ÐµÑÑŒ Ð² Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð¼ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ð¸\n"
        response += "â€¢ Ð’Ð°ÑˆÐ¸ ÑƒÑÐ¸Ð»Ð¸Ñ Ð¿Ñ€Ð¸Ð½Ð¾ÑÑÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚\n"
        response += "â€¢ Ð£ Ð²Ð°Ñ ÐµÑÑ‚ÑŒ ÑÐ¸Ð»Ð° Ð¼ÐµÐ½ÑÑ‚ÑŒ ÑÐ²Ð¾ÑŽ Ð¶Ð¸Ð·Ð½ÑŒ\n\n"

        response += "ÐšÐ°ÐºÐ¸Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ ÑˆÐ°Ð³Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÐµÑ‚Ðµ? Ð“Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ! ðŸ’ª"

        return response

    def _generate_conversational_response(self, message: str, personality: Dict[str, float],
                                        user_context: UserContext) -> str:
        """Generate general conversational response"""

        response = "ðŸ’­ **Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾!**\n\n"

        # Reference their message
        if len(message) > 50:
            response += f"Ð’Ñ‹ Ð¿Ð¾Ð´ÐµÐ»Ð¸Ð»Ð¸ÑÑŒ Ð²Ð°Ð¶Ð½Ñ‹Ð¼Ð¸ Ð¼Ñ‹ÑÐ»ÑÐ¼Ð¸ Ð¾: \"{message[:80]}...\"\n\n"

        # Personality-adapted continuation
        if personality.get("openness", 0) > 0.7:
            response += "ÐœÐ½Ðµ Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ Ð²Ð°Ñˆ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ñ€Ð°Ð·Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸ÑÐ¼. ÐšÐ°ÐºÐ¸Ðµ Ð½Ð¾Ð²Ñ‹Ðµ Ð¸Ð´ÐµÐ¸ Ð¿Ñ€Ð¸Ñ…Ð¾Ð´ÑÑ‚ Ð² Ð³Ð¾Ð»Ð¾Ð²Ñƒ?\n\n"
        elif personality.get("conscientiousness", 0) > 0.7:
            response += "ÐŸÐ¾Ñ…Ð¾Ð¶Ðµ, Ð²Ñ‹ Ñ‚Ñ‰Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð±Ð´ÑƒÐ¼Ñ‹Ð²Ð°ÐµÑ‚Ðµ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ. ÐšÐ°ÐºÐ¸Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð°ÑÐ¿ÐµÐºÑ‚Ñ‹ Ð²Ð°Ð¶Ð½ÐµÐµ Ð²ÑÐµÐ³Ð¾?\n\n"
        else:
            response += "Ð Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ - Ñ‡Ñ‚Ð¾ Ð²Ð°Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð²Ð¾Ð»Ð½ÑƒÐµÑ‚ Ð² ÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐ¼Ðµ?\n\n"

        response += "ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ð¹Ñ‚Ðµ Ð´ÐµÐ»Ð¸Ñ‚ÑŒÑÑ Ð¼Ñ‹ÑÐ»ÑÐ¼Ð¸! ðŸ’¬"

        return response

    def _analyze_current_mood(self, recent_messages: List[Dict[str, Any]]) -> str:
        """Analyze current mood from recent messages"""

        if not recent_messages:
            return "neutral"

        # Simple sentiment analysis of recent user messages
        user_messages = [msg for msg in recent_messages[-5:] if msg["message_type"] == "user"]

        if not user_messages:
            return "neutral"

        # Count emotional words
        positive_count = 0
        negative_count = 0

        for msg in user_messages:
            content = msg["content"].lower()

            positive_words = ["Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾", "Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾", "Ñ€Ð°Ð´", "ÑÑ‡Ð°ÑÑ‚Ð»Ð¸Ð²", "Ð²Ð´Ð¾Ñ…Ð½Ð¾Ð²Ð»ÑÐµÑ‚"]
            negative_words = ["Ð¿Ð»Ð¾Ñ…Ð¾", "Ð³Ñ€ÑƒÑÑ‚Ð½Ð¾", "Ñ‚ÑÐ¶ÐµÐ»Ð¾", "Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°", "Ð±Ð¾Ð»Ð¸Ñ‚"]

            positive_count += sum(1 for word in positive_words if word in content)
            negative_count += sum(1 for word in negative_words if word in content)

        if negative_count > positive_count:
            return "negative"
        elif positive_count > negative_count:
            return "positive"
        else:
            return "neutral"

    def _determine_conversation_stage(self, user_profile: Optional[Dict],
                                    recent_messages: List[Dict[str, Any]]) -> str:
        """Determine what stage of conversation we're in"""

        if not user_profile:
            return "initial"

        total_messages = user_profile.get("chat_stats", {}).get("total_messages", 0) if user_profile else 0
        assessment_complete = user_profile.get("user", {}).get("onboarding_completed", False) if user_profile else False

        if total_messages < 5:
            return "getting_acquainted"
        elif not assessment_complete:
            return "pre_assessment"
        elif total_messages < 50:
            return "building_rapport"
        else:
            return "deep_coaching"

    def _detect_psychological_domain(self, text: str) -> str:
        """Detect psychological domain from text content"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ", "Ð»ÑŽÐ´Ð¸", "ÑÐµÐ¼ÑŒÑ", "Ð´Ñ€ÑƒÐ·ÑŒÑ", "Ð¿Ð°Ñ€Ñ‚Ð½ÐµÑ€"]):
            return "relationships"
        elif any(word in text_lower for word in ["Ñ€Ð°Ð±Ð¾Ñ‚Ð°", "ÐºÐ°Ñ€ÑŒÐµÑ€Ð°", "Ð±Ð¸Ð·Ð½ÐµÑ", "ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸"]):
            return "work"
        elif any(word in text_lower for word in ["Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ", "ÑÐ¼Ð¾Ñ†Ð¸Ð¸", "Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ", "Ð¿ÐµÑ€ÐµÐ¶Ð¸Ð²Ð°ÑŽ"]):
            return "emotions"
        elif any(word in text_lower for word in ["Ñ†ÐµÐ»ÑŒ", "Ð¼ÐµÑ‡Ñ‚Ð°", "Ð¿Ð»Ð°Ð½Ñ‹", "Ð±ÑƒÐ´ÑƒÑ‰ÐµÐµ"]):
            return "future"
        elif any(word in text_lower for word in ["Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ", "Ñ‚ÐµÐ»Ð¾", "ÑÐ°Ð¼Ð¾Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ðµ"]):
            return "health"
        else:
            return "general"

    def _assess_emotional_intensity(self, message: str) -> str:
        """Assess emotional intensity of message"""

        message_lower = message.lower()

        high_intensity_markers = ["Ð¾Ñ‡ÐµÐ½ÑŒ", "ÐºÑ€Ð°Ð¹Ð½Ðµ", "Ð½ÐµÐ²Ñ‹Ð½Ð¾ÑÐ¸Ð¼Ð¾", "ÑƒÐ¶Ð°ÑÐ½Ð¾", "Ð¿Ñ€ÐµÐºÑ€Ð°ÑÐ½Ð¾", "Ð²Ð¾ÑÑ…Ð¸Ñ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾"]
        medium_intensity_markers = ["Ð´Ð¾Ð²Ð¾Ð»ÑŒÐ½Ð¾", "Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾", "Ð²Ð¿Ð¾Ð»Ð½Ðµ"]

        if any(marker in message_lower for marker in high_intensity_markers):
            return "high"
        elif any(marker in message_lower for marker in medium_intensity_markers):
            return "medium"
        else:
            return "low"

    def _extract_emotional_insight(self, message: str) -> Optional[Dict[str, Any]]:
        """Extract emotional state insights from message"""

        # Simple pattern matching for emotional insights
        message_lower = message.lower()

        if "Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ" in message_lower:
            # Extract what follows "Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ"
            start_idx = message_lower.find("Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ") + len("Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ ÑÐµÐ±Ñ")
            emotional_state = message[start_idx:start_idx+50].strip()

            return {
                "text": f"Ð¢ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ: {emotional_state}",
                "type": "emotional_state",
                "domain": "emotions",
                "confidence": 0.8
            }

        return None

    def _extract_goal_insight(self, message: str) -> Optional[Dict[str, Any]]:
        """Extract goal-related insights from message"""

        message_lower = message.lower()
        goal_verbs = ["Ñ…Ð¾Ñ‡Ñƒ", "Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÑŽ", "Ð¼ÐµÑ‡Ñ‚Ð°ÑŽ", "ÑÑ‚Ñ€ÐµÐ¼Ð»ÑŽÑÑŒ", "ÑÐ¾Ð±Ð¸Ñ€Ð°ÑŽÑÑŒ"]

        for verb in goal_verbs:
            if verb in message_lower:
                start_idx = message_lower.find(verb)
                goal_description = message[start_idx:start_idx+100].strip()

                return {
                    "text": f"Ð’Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð½Ð°Ñ Ñ†ÐµÐ»ÑŒ/Ð¶ÐµÐ»Ð°Ð½Ð¸Ðµ: {goal_description}",
                    "type": "goal_expression",
                    "domain": "future",
                    "confidence": 0.7
                }

        return None

    async def _extract_personality_updates(self, message: str,
                                         user_context: UserContext) -> Optional[Dict[str, float]]:
        """Extract personality updates from message content"""

        updates = {}
        message_lower = message.lower()

        # Openness indicators
        if any(word in message_lower for word in ["Ð½Ð¾Ð²Ð¾Ðµ", "Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÑ‚Ð²Ð¾", "Ð¸Ð´ÐµÑ", "ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚"]):
            updates["openness"] = 0.05

        # Conscientiousness indicators
        if any(word in message_lower for word in ["Ð¿Ð»Ð°Ð½", "Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ", "Ð´Ð¸ÑÑ†Ð¸Ð¿Ð»Ð¸Ð½Ð°", "Ñ†ÐµÐ»ÑŒ"]):
            updates["conscientiousness"] = 0.05

        # Extraversion indicators
        if any(word in message_lower for word in ["Ð»ÑŽÐ´Ð¸", "ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ", "Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ", "Ð²ÐµÑ‡ÐµÑ€Ð¸Ð½ÐºÐ°"]):
            updates["extraversion"] = 0.05

        # Agreeableness indicators
        if any(word in message_lower for word in ["Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ", "Ð´Ð¾Ð±Ñ€Ð¾Ñ‚Ð°", "ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾"]):
            updates["agreeableness"] = 0.05

        return updates if updates else None

    def _initialize_response_templates(self) -> Dict[str, Dict[str, str]]:
        """Initialize response templates for different personality types"""

        return {
            "advice_request": {
                "high_conscientiousness": "Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ ÑÐ¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‡ÐµÑ‚ÐºÐ¸Ð¹ Ð¿Ð»Ð°Ð½ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ð¹...",
                "high_openness": "ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ñ€ÐµÑˆÐµÐ½Ð¸ÑŽ...",
                "high_extraversion": "ÐžÐ±ÑÑƒÐ´Ð¸Ñ‚Ðµ ÑÑ‚Ð¾ Ñ Ð±Ð»Ð¸Ð·ÐºÐ¸Ð¼Ð¸ Ð»ÑŽÐ´ÑŒÐ¼Ð¸...",
                "default": "Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð±ÐµÑ€ÐµÐ¼ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚ÑÐ¼..."
            },
            "emotional_support": {
                "high_agreeableness": "ÐŸÐ¾Ð½Ð¸Ð¼Ð°ÑŽ Ð²Ð°ÑˆÐ¸ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð°, ÑÑ‚Ð¾ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾...",
                "high_neuroticism": "Ð’Ð°Ð¶Ð½Ð¾ Ð·Ð°Ð±Ð¾Ñ‚Ð¸Ñ‚ÑŒÑÑ Ð¾ ÑÐ²Ð¾ÐµÐ¼ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸...",
                "default": "Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð´Ð¾Ð²ÐµÑ€Ð¸Ðµ. Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð½Ð°Ð¹Ð´ÐµÐ¼ ÑÐ¿Ð¾ÑÐ¾Ð±Ñ‹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸..."
            }
        }

    def _extract_recent_topics_from_context(self, user_context: UserContext) -> List[str]:
        """
        Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ‚ÐµÐ¼Ñ‹ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð° Ð¸Ð· Ð½ÐµÐ´Ð°Ð²Ð½ÐµÐ¹ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð°

        ðŸ”¥ FIX: Ð—Ð°Ð¼ÐµÐ½ÑÐµÑ‚ broken semantic search - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
        """
        topics = []

        if not user_context.recent_messages:
            return topics

        # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 10 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð½Ð° ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°
        for msg in user_context.recent_messages[-10:]:
            content = msg.get('content', '').lower()

            # Ð‘Ð¸Ð·Ð½ÐµÑ/Ñ€Ð°Ð±Ð¾Ñ‚Ð°
            if any(kw in content for kw in ['Ð±Ð»Ð¾Ð³', 'Ð±Ð¸Ð·Ð½ÐµÑ', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚', 'ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚', 'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ', 'ÐºÐ»Ð¸ÐµÐ½Ñ‚']):
                topics.append('Ð±Ð»Ð¾Ð³ Ð¸ Ð±Ð¸Ð·Ð½ÐµÑ-ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ')

            # ÐžÑ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ
            if any(kw in content for kw in ['Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ', 'Ð¿Ð°Ñ€Ñ‚Ð½ÐµÑ€', 'ÑÐµÐ¼ÑŒÑ', 'Ð´Ñ€ÑƒÐ·ÑŒÑ', 'Ð»ÑŽÐ±Ð¾Ð²ÑŒ']):
                topics.append('Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ Ð¸ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚ÑŒ')

            # Ð¡Ð°Ð¼Ð¾Ð¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ
            if any(kw in content for kw in ['Ð¿Ð¾Ð½ÑÑ‚ÑŒ ÑÐµÐ±Ñ', 'ÐºÑ‚Ð¾ Ñ', 'Ñ†ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸', 'Ñ†ÐµÐ»Ð¸', 'Ð¼ÐµÑ‡Ñ‚Ñ‹']):
                topics.append('ÑÐ°Ð¼Ð¾Ð¿Ð¾Ð·Ð½Ð°Ð½Ð¸Ðµ Ð¸ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒ')

            # Ð­Ð¼Ð¾Ñ†Ð¸Ð¸
            if any(kw in content for kw in ['Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ', 'Ñ‚Ñ€ÐµÐ²Ð¾Ð¶Ð½Ð¾', 'ÑÑ‚Ñ€Ð°Ñ…', 'Ñ€Ð°Ð´Ð¾ÑÑ‚ÑŒ', 'Ð³Ñ€ÑƒÑÑ‚ÑŒ']):
                topics.append('ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ')

            # Ð Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ
            if any(kw in content for kw in ['Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ', 'Ñ€Ð¾ÑÑ‚', 'Ð½Ð°Ð²Ñ‹ÐºÐ¸', 'Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ', 'Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ']):
                topics.append('Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ð½Ñ‹Ð¹ Ñ€Ð¾ÑÑ‚')

        # ÐžÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3 Ñ‚ÐµÐ¼Ñ‹
        unique_topics = list(dict.fromkeys(topics))[:3]
        return unique_topics

    def _extract_work_background_from_onboarding(self, user_context: UserContext) -> Optional[str]:
        """
        Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹/Ð±Ð¸Ð·Ð½ÐµÑÐ° Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¾Ð½Ð±Ð¾Ñ€Ð´Ð¸Ð½Ð³Ð°

        ðŸ”¥ FIX: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ 84 onboarding answers Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ð¸Ð· psychological_insights
        """
        if not user_context.onboarding_answers:
            return None

        work_contexts = []

        for answer in user_context.onboarding_answers:
            insights = answer.get('psychological_insights', '')

            if isinstance(insights, str):
                insights_lower = insights.lower()

                # Ð˜Ñ‰ÐµÐ¼ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹, Ð±Ð¸Ð·Ð½ÐµÑÐ°, Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð²
                if any(kw in insights_lower for kw in ['Ñ€Ð°Ð±Ð¾Ñ‚Ð°', 'Ð±Ð¸Ð·Ð½ÐµÑ', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚', 'Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ñ', 'ÐºÐ°Ñ€ÑŒÐµÑ€Ð°', 'ÐºÐ»Ð¸ÐµÐ½Ñ‚', 'ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ', 'Ð±Ð»Ð¾Ð³']):
                    # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 200 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
                    work_contexts.append(insights[:200])

        # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ ÑÐ°Ð¼Ñ‹Ð¹ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ (Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¹)
        if work_contexts:
            self.logger.info(f"ðŸ’¼ Found work context from onboarding: {len(work_contexts[0])} chars")
            return work_contexts[0]

        return None

    def _build_ai_system_prompt(self, user_context: UserContext, intent: str, context_enrichment: str) -> str:
        """
        Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ system prompt Ð´Ð»Ñ AI Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ

        ðŸ”¥ NEW: Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹, Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ð¸
        """
        personality = user_context.personality_profile.get("traits", {}).get("big_five", {}) if user_context.personality_profile else {}

        # ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ð½Ñ‹Ðµ Ñ‡ÐµÑ€Ñ‚Ñ‹
        traits_desc = []
        if personality:
            for trait, value in personality.items():
                if value > 0.7:
                    traits_desc.append(f"high {trait}")
                elif value < 0.3:
                    traits_desc.append(f"low {trait}")

        personality_context = f"User personality traits: {', '.join(traits_desc)}" if traits_desc else "New user, personality profile being built"

        # ðŸ”¥ NEW: Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð² (Ð´Ð¸Ð»ÐµÐ¼Ð¼Ñ‹, Ñ†ÐµÐ»Ð¸)
        context_stories_text = ""
        if user_context.context_stories:
            stories = [story.get('story_text', '') for story in user_context.context_stories[:3]]  # Top 3 most recent
            if stories:
                context_stories_text = "\n\nUser's current dilemmas and context:\n" + "\n".join([f"- {story}" for story in stories if story])

        # ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€Ð¾Ð»ÑŒ Ð¿Ð¾Ð´ Ñ‚Ð¸Ð¿ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        if intent == "advice_request":
            role_guidance = "Provide practical, actionable advice while considering their personality"
        elif intent == "emotional_sharing":
            role_guidance = "Offer empathetic support and emotional validation"
        elif intent == "progress_sharing":
            role_guidance = "Celebrate their achievements and encourage continued growth"
        else:
            role_guidance = "Engage in thoughtful, personalized conversation"

        prompt = f"""You are an empathetic AI psychology coach for Selfology.me platform.

USER CONTEXT:
{personality_context}{context_stories_text}
{context_enrichment if context_enrichment else "No additional context available yet"}

YOUR ROLE:
{role_guidance}

RESPONSE GUIDELINES:
- Length: 500-600 words (deep, thoughtful responses)
- Language: Russian (natural, conversational)
- Style: Warm but professional
- Personality adaptation: Reference their traits when relevant
- Include 1-2 thoughtful follow-up questions
- Balance emotional support with actionable insights
- Show genuine understanding of their situation

IMPORTANT:
- This is NOT a quick chatbot - take time to craft meaningful responses
- Reference their personality and context when relevant
- Ask questions that invite deeper self-reflection
- Avoid generic advice - make it personal to THEM"""

        return prompt

    def _build_conversation_messages(self, user_context: UserContext, current_message: str) -> List[Dict[str, str]]:
        """
        Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð° Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° AI

        ðŸ”¥ NEW: Ð’ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 5 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð´Ð»Ñ continuity
        """
        messages = []

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½ÐµÐ´Ð°Ð²Ð½ÑŽÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 5 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹)
        if user_context.recent_messages:
            for msg in user_context.recent_messages[-5:]:
                role = "user" if msg.get("role") == "user" or msg.get("message_type") == "user" else "assistant"
                content = msg.get("content", "")

                # ÐžÐ±Ñ€ÐµÐ·Ð°ÐµÐ¼ Ð¾Ñ‡ÐµÐ½ÑŒ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
                if len(content) > 500:
                    content = content[:500] + "..."

                messages.append({
                    "role": role,
                    "content": content
                })

        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
        messages.append({
            "role": "user",
            "content": current_message
        })

        return messages
