"""
–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ 14 —Å –ø–æ–ª–Ω–æ–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
"""

import asyncio
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent.parent / "intelligent_question_core"))

from selfology_bot.database import DatabaseService, OnboardingDAO
from selfology_bot.analysis import AnswerAnalyzer, EmbeddingCreator
from selfology_bot.analysis.personality_extractor import PersonalityExtractor
from selfology_bot.database.digital_personality_dao import DigitalPersonalityDAO
from intelligent_question_core.api.core_api import SelfologyQuestionCore
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def reprocess_answer_14():
    """–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ 14"""

    logger.info("="*80)
    logger.info("üîÑ REPROCESSING ANSWER 14 WITH FULL VECTORIZATION")
    logger.info("="*80)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    db_service = DatabaseService(
        host="localhost",
        port=5432,
        user="n8n",
        password="sS67wM+1zMBRFHAW4kj9HwFl5J6+veo7Nirx0/I+oiU=",
        database="n8n"
    )
    await db_service.initialize()

    dao = OnboardingDAO(db_service)
    personality_dao = DigitalPersonalityDAO(db_service)
    analyzer = AnswerAnalyzer()
    embedding_creator = EmbeddingCreator()
    personality_extractor = PersonalityExtractor()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º Question Core
    core_file_path = str(Path(__file__).parent.parent / "intelligent_question_core" / "data" / "selfology_intelligent_core.json")
    question_core = SelfologyQuestionCore(core_file_path)

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç–∞ 14
    query = """
        SELECT
            ua.id,
            ua.session_id,
            ua.question_json_id,
            ua.raw_answer,
            os.user_id
        FROM selfology.user_answers_new ua
        JOIN selfology.onboarding_sessions os ON ua.session_id = os.id
        WHERE ua.id = 14
    """

    async with db_service.get_connection() as conn:
        answer_row = await conn.fetchrow(query)

    if not answer_row:
        logger.error("‚ùå Answer 14 not found")
        await db_service.close()
        return

    user_id = answer_row['user_id']
    question_id = answer_row['question_json_id']
    user_answer = answer_row['raw_answer']

    logger.info(f"‚úÖ Found answer 14:")
    logger.info(f"   User: {user_id}")
    logger.info(f"   Question: {question_id}")
    logger.info(f"   Answer: {user_answer}")

    # –ü–æ–ª—É—á–∞–µ–º –≤–æ–ø—Ä–æ—Å –∏–∑ Question Core
    question = question_core.get_question(question_id)

    if not question:
        logger.error(f"‚ùå Question {question_id} not found in core")
        await db_service.close()
        return

    logger.info(f"‚úÖ Question loaded: {question['text'][:50]}...")

    # === –®–ê–ì 1: –ê–ù–ê–õ–ò–ó –û–¢–í–ï–¢–ê ===
    logger.info("\n" + "="*80)
    logger.info("üî¨ STEP 1: ANALYZING ANSWER")
    logger.info("="*80)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_context = {
        "user_id": user_id,
        "answer_id": 14,
        "question_number": 14,
        "answer_length": len(user_answer),
        "previous_answers_count": 13,
        "session_started": "2025-10-01T20:28:00",
        "previous_domains": []
    }

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
    analysis_result = await analyzer.analyze_answer(
        question_data=question,
        user_answer=user_answer,
        user_context=user_context
    )

    if not analysis_result:
        logger.error("‚ùå Analysis failed")
        await db_service.close()
        return

    logger.info(f"‚úÖ Analysis completed:")
    logger.info(f"   Quality: {analysis_result.get('quality_score', 0):.2f}")
    logger.info(f"   Model: {analysis_result.get('processing_metadata', {}).get('model_used')}")

    # === –®–ê–ì 2: –û–ë–ù–û–í–õ–ï–ù–ò–ï DIGITAL PERSONALITY ===
    logger.info("\n" + "="*80)
    logger.info("üß¨ STEP 2: UPDATING DIGITAL PERSONALITY")
    logger.info("="*80)

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –ª–∏—á–Ω–æ—Å—Ç—å
    current_personality = await personality_dao.get_personality(user_id)

    if not current_personality:
        logger.error("‚ùå No personality found")
        await db_service.close()
        return

    logger.info(f"‚úÖ Current personality loaded (completeness: {current_personality.get('completeness_score', 0):.2%})")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    extracted = await personality_extractor.extract_from_answer(
        question_text=question['text'],
        user_answer=user_answer,
        question_metadata=question.get('classification', {}),
        existing_personality=current_personality
    )

    import json
    if isinstance(extracted, str):
        extracted = json.loads(extracted)

    logger.info(f"‚úÖ Extracted personality data")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ª–∏—á–Ω–æ—Å—Ç—å—é
    updated_personality = personality_extractor.merge_extractions(current_personality, extracted)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    await personality_dao.update_personality(user_id, updated_personality, merge=False)

    logger.info(f"‚úÖ Personality updated")

    # === –®–ê–ì 3: –í–ï–ö–¢–û–†–ò–ó–ê–¶–ò–Ø ===
    logger.info("\n" + "="*80)
    logger.info("üìà STEP 3: CREATING VECTORS")
    logger.info("="*80)

    # –°–æ–∑–¥–∞—ë–º –≤–µ–∫—Ç–æ—Ä—ã
    vector_success = await embedding_creator.create_personality_vector(
        user_id=user_id,
        analysis_result=analysis_result,
        is_update=True  # –≠—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –Ω–µ –ø–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä
    )

    if vector_success:
        logger.info("‚úÖ Vectorization completed successfully!")
    else:
        logger.warning("‚ö†Ô∏è Vectorization returned False")

    # === –ü–†–û–í–ï–†–ö–ê ===
    logger.info("\n" + "="*80)
    logger.info("üîç VERIFICATION")
    logger.info("="*80)

    import requests

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º personality_profiles
    response = requests.get(f"http://localhost:6333/collections/personality_profiles/points/{user_id}")
    if response.status_code == 200:
        data = response.json()
        last_updated = data['result']['payload'].get('last_updated')
        logger.info(f"‚úÖ personality_profiles: Vector exists (last_updated: {last_updated})")
    else:
        logger.error(f"‚ùå personality_profiles: Vector not found")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º quick_match
    response = requests.get(f"http://localhost:6333/collections/quick_match/points/{user_id}")
    if response.status_code == 200:
        logger.info(f"‚úÖ quick_match: Vector exists")
    else:
        logger.error(f"‚ùå quick_match: Vector not found")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º personality_evolution
    response = requests.get(f"http://localhost:6333/collections/personality_evolution")
    if response.status_code == 200:
        data = response.json()
        count = data['result']['points_count']
        logger.info(f"‚ÑπÔ∏è  personality_evolution: {count} breakthrough moments stored")

    logger.info("\n" + "="*80)
    logger.info("üéâ ANSWER 14 REPROCESSED SUCCESSFULLY!")
    logger.info("="*80)

    await db_service.close()


if __name__ == "__main__":
    asyncio.run(reprocess_answer_14())
