#!/usr/bin/env python3
"""
–≠–¢–ê–ü 2: –°–ï–ö–í–ï–ù–ò–†–û–í–ê–ù–ò–ï
–î–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã –æ—Ç–æ–±—Ä–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
"""
import json
from pathlib import Path
from collections import defaultdict, Counter
import random
random.seed(42)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

# –ú–∞–ø–ø–∏–Ω–≥ –≥–ª—É–±–∏–Ω—ã –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
DEPTH_ORDER = {
    'SURFACE': 1,
    'CONSCIOUS': 2,
    'EDGE': 3,
    'SHADOW': 4,
    'CORE': 5
}

# –ú–∞–ø–ø–∏–Ω–≥ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏
ENERGY_WEIGHT = {
    'OPENING': -2,    # –õ–µ–≥–∫–∏–µ, –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ
    'NEUTRAL': 0,     # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ
    'HEALING': -1,    # –ò—Å—Ü–µ–ª—è—é—â–∏–µ
    'PROCESSING': 1,  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–µ
    'HEAVY': 2        # –¢—è–∂–µ–ª—ã–µ
}

def calculate_target_size(program_name, tagged_count):
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–≥—Ä–∞–º–º—ã"""

    # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏–∑ Notion - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö —Ä–∞–∑–º–µ—Ä
    existing_sizes = {
        '–ü–æ–¥—É–º–∞—Ç—å –æ –∂–∏–∑–Ω–∏': 42,
        '–ü–æ–¥—É–º–∞—Ç—å –æ –∫–∞—Ä—å–µ—Ä–µ –∏–ª–∏ –±–∏–∑–Ω–µ—Å–µ': 28,
        '–ó–∞–¥—É–º–∞—Ç—å—Å—è –æ –∑–¥–æ—Ä–æ–≤—å–µ': 20,
        '–ò–∑—É—á–∏—Ç—å —Å–µ–±—è': 15,
        '–£–ª—É—á—à–∏—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ': 15,
        '–ü–µ—Ä–µ–±—Ä–∞—Ç—å —Ü–µ–ª–∏': 8,
        '–û—Ç–Ω–æ—à–µ–Ω–∏–µ —Å —Å–∞–º–∏–º —Å–æ–±–æ–π': 7,
        '–ü–µ—Ä–µ–æ—Å–º—ã—Å–ª–∏—Ç—å —Ç–∞–π–º-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç': 7,
        '–ú–µ—á—Ç–∞—Ç–µ–ª–∏': 6,
        '–¢—Ä–µ–Ω–∞–∂—ë—Ä, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∂–∏—Ç—å': 6,
        '–†–µ—Ñ–ª–µ–∫—Å–∏—è': 5,
        '3 –∫–∏—Ç–∞ –æ—á–∏—â–µ–Ω–∏—è': 3,
        '–†–µ—Å—É—Ä—Å': 2
    }

    if program_name in existing_sizes:
        return existing_sizes[program_name]

    # –î–ª—è –Ω–æ–≤—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º - –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö
    if tagged_count >= 100:
        return min(40, tagged_count // 3)  # –ë–æ–ª—å—à–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã: 30-40
    elif tagged_count >= 50:
        return min(25, tagged_count // 2)  # –°—Ä–µ–¥–Ω–∏–µ: 20-25
    elif tagged_count >= 20:
        return min(15, tagged_count // 2)  # –ú–∞–ª—ã–µ: 10-15
    else:
        return min(10, tagged_count)       # –ú–∏–∫—Ä–æ: –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å –¥–æ 10

def group_by_theme(questions):
    """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Ç–µ–º–∞–º (–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤—ã—Ö —Å–ª–æ–≤)"""
    groups = defaultdict(list)

    for q in questions:
        # –ò–∑–≤–ª–µ—á—å –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞ –∫–∞–∫ —Ç–µ–º—É
        words = q['text'].lower().split()[:3]
        theme = ' '.join(words)

        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—â–∏–µ –Ω–∞—á–∞–ª–∞
        if any(w in theme for w in ['—á—Ç–æ', '–∫–∞–∫–æ–π', '–∫–∞–∫–∞—è', '–∫–∞–∫–æ–µ']):
            theme = '—á—Ç–æ'
        elif any(w in theme for w in ['–∫–∞–∫', '–∫–∞–∫–∏–º']):
            theme = '–∫–∞–∫'
        elif any(w in theme for w in ['–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º']):
            theme = '–ø–æ—á–µ–º—É'
        elif any(w in theme for w in ['–∫—Ç–æ', '–∫–æ–≥–æ', '–∫–æ–º—É']):
            theme = '–∫—Ç–æ'
        elif any(w in theme for w in ['–∫–æ–≥–¥–∞', '–≤ –∫–∞–∫–æ–π –º–æ–º–µ–Ω—Ç']):
            theme = '–∫–æ–≥–¥–∞'

        groups[theme].append(q)

    return groups

def select_diverse_questions(questions, target_size):
    """–í—ã–±—Ä–∞—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ –≤—Å–µ—Ö —Ç–µ–º"""

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ —Ç–µ–º–∞–º
    theme_groups = group_by_theme(questions)

    selected = []

    # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–≤ –º–µ–Ω—å—à–µ —Ü–µ–ª–µ–≤–æ–≥–æ - –±–µ—Ä–µ–º –≤—Å–µ
    if len(questions) <= target_size:
        return questions

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–≤–æ—Ç—É –ø–æ —Ç–µ–º–∞–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    questions_per_theme = max(1, target_size // len(theme_groups))

    # –°–Ω–∞—á–∞–ª–∞ –±–µ—Ä–µ–º –ø–æ –∫–≤–æ—Ç–µ –∏–∑ –∫–∞–∂–¥–æ–π —Ç–µ–º—ã
    for theme, theme_questions in theme_groups.items():
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≥–ª—É–±–∏–Ω–µ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–º—ã
        theme_questions.sort(key=lambda q: (
            DEPTH_ORDER.get(q['classification']['depth_level'], 99),
            q['id']
        ))

        # –í–∑—è—Ç—å –¥–æ –∫–≤–æ—Ç—ã
        selected.extend(theme_questions[:questions_per_theme])

    # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç - –¥–æ–±–∞–≤–∏—Ç—å –∏–∑ —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø
    if len(selected) < target_size:
        remaining = target_size - len(selected)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≥—Ä—É–ø–ø—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É
        sorted_groups = sorted(theme_groups.items(), key=lambda x: len(x[1]), reverse=True)

        for theme, theme_questions in sorted_groups:
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
            unused = [q for q in theme_questions if q not in selected]

            if unused:
                take = min(remaining, len(unused))
                selected.extend(unused[:take])
                remaining -= take

                if remaining <= 0:
                    break

    return selected[:target_size]

def check_energy_balance(sequence):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –±–∞–ª–∞–Ω—Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    issues = []
    heavy_count = 0

    for i, q in enumerate(sequence):
        energy = q['classification']['energy_dynamic']

        if energy == 'HEAVY':
            heavy_count += 1

            if heavy_count >= 3:
                issues.append({
                    'position': i + 1,
                    'issue': 'too_many_heavy',
                    'message': f'3+ HEAVY –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–¥—Ä—è–¥ (–ø–æ–∑–∏—Ü–∏–∏ {i-1}-{i+1})'
                })
        else:
            heavy_count = 0  # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞

    return issues

def rebalance_sequence(sequence):
    """–ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""

    rebalanced = []
    heavy_buffer = []  # –ë—É—Ñ–µ—Ä –¥–ª—è HEAVY –≤–æ–ø—Ä–æ—Å–æ–≤

    for q in sequence:
        energy = q['classification']['energy_dynamic']

        if energy == 'HEAVY':
            heavy_buffer.append(q)

            # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å 2 HEAVY - –≤—Å—Ç–∞–≤–∏—Ç—å —Ä–∞–∑–≥—Ä—É–∑–∫—É
            if len(heavy_buffer) >= 2:
                # –î–æ–±–∞–≤–∏—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ HEAVY
                rebalanced.extend(heavy_buffer)
                heavy_buffer = []

                # –ù–∞–π—Ç–∏ HEALING –∏–ª–∏ OPENING –≤–æ–ø—Ä–æ—Å –¥–∞–ª–µ–µ
                for future_q in sequence[sequence.index(q)+1:]:
                    if future_q['classification']['energy_dynamic'] in ['HEALING', 'OPENING']:
                        # –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –µ–≥–æ —Å—é–¥–∞
                        rebalanced.append(future_q)
                        sequence.remove(future_q)
                        break
        else:
            # –°–Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∑–∏—Ç—å –±—É—Ñ–µ—Ä HEAVY –µ—Å–ª–∏ –µ—Å—Ç—å
            if heavy_buffer:
                rebalanced.extend(heavy_buffer)
                heavy_buffer = []

            # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –Ω–µ-HEAVY
            rebalanced.append(q)

    # –î–æ–±–∞–≤–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è HEAVY –≤ –∫–æ–Ω—Ü–µ
    rebalanced.extend(heavy_buffer)

    return rebalanced

def sequence_program(program_name, tagged_questions, target_size=None):
    """–°–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""

    print(f"\nüîÑ –°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {program_name}")
    print(f"   –ü–æ–º–µ—á–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(tagged_questions)}")

    # –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_questions = []
    seen_ids = set()

    for q in tagged_questions:
        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –µ—Å–ª–∏ —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç
        if 'duplicate_of' in q:
            continue

        if q['id'] not in seen_ids:
            unique_questions.append(q)
            seen_ids.add(q['id'])

    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(unique_questions)}")

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä
    if target_size is None:
        target_size = calculate_target_size(program_name, len(unique_questions))

    print(f"   –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä: {target_size}")

    # –í—ã–±—Ä–∞—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    selected = select_diverse_questions(unique_questions, target_size)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≥–ª—É–±–∏–Ω–µ –∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–µ
    selected.sort(key=lambda q: (
        DEPTH_ORDER.get(q['classification']['depth_level'], 99),
        ENERGY_WEIGHT.get(q['classification']['energy_dynamic'], 0),
        q['id']
    ))

    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–π –±–∞–ª–∞–Ω—Å
    issues = check_energy_balance(selected)

    if issues:
        print(f"   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –±–∞–ª–∞–Ω—Å–æ–º: {len(issues)}")
        # –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å
        selected = rebalance_sequence(selected)
        print(f"   ‚úÖ –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ")

    # –ü—Ä–∏—Å–≤–æ–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏
    sequenced = []
    for i, q in enumerate(selected, 1):
        q_copy = q.copy()
        q_copy['program_position'] = i
        q_copy['program_status'] = 'included'
        sequenced.append(q_copy)

    # –ü–æ–º–µ—Ç–∏—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ
    excluded = []
    for q in unique_questions:
        if q not in selected:
            q_copy = q.copy()
            q_copy['program_status'] = 'excluded'

            # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–∏—á–∏–Ω—É –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            if len(unique_questions) > target_size * 2:
                q_copy['exclusion_reason'] = 'too_many_questions'
            else:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ –ø–æ—Ö–æ–∂–∏–π –≤–∫–ª—é—á–µ–Ω–Ω—ã–π
                included_texts = [sq['text'][:30] for sq in selected]
                if any(q['text'][:30] == it for it in included_texts):
                    q_copy['exclusion_reason'] = 'similar_included'
                else:
                    q_copy['exclusion_reason'] = 'theme_coverage'

            excluded.append(q_copy)

    print(f"   ‚úÖ –í–∫–ª—é—á–µ–Ω–æ: {len(sequenced)}")
    print(f"   ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–æ: {len(excluded)}")

    return {
        'program': program_name,
        'total_tagged': len(tagged_questions),
        'total_unique': len(unique_questions),
        'included_count': len(sequenced),
        'excluded_count': len(excluded),
        'questions_included': sequenced,
        'questions_excluded': excluded
    }

def main():
    print("üéØ –≠–¢–ê–ü 2: –°–ï–ö–í–ï–ù–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• –ü–†–û–ì–†–ê–ú–ú\n")
    print("="*80)

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –±–∞–∑—É
    data_file = Path('intelligent_question_core/data/selfology_questions_deduplicated.json')
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    questions = data['questions']

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≥—Ä–∞–º–º
    programs_file = Path('prompts/all_programs_list.json')
    with open(programs_file, 'r', encoding='utf-8') as f:
        programs = json.load(f)

    # –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º
    program_questions = defaultdict(list)

    for q in questions:
        for tagged_prog in q.get('programs_tagged', []):
            prog_name = tagged_prog['program']
            program_questions[prog_name].append(q)

    # –°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏
    all_sequences = []
    programs_with_questions = []
    programs_without_questions = []

    for program in programs:
        prog_name = program['name']

        if prog_name in program_questions:
            programs_with_questions.append(prog_name)

            # –°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞—Ç—å
            sequence = sequence_program(
                prog_name,
                program_questions[prog_name]
            )
            all_sequences.append(sequence)
        else:
            programs_without_questions.append(prog_name)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = Path('prompts/all_programs_sequenced.json')

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'total_programs': len(programs),
                'programs_with_questions': len(programs_with_questions),
                'programs_without_questions': len(programs_without_questions),
                'programs_needing_generation': programs_without_questions
            },
            'sequences': all_sequences
        }, f, ensure_ascii=False, indent=2)

    # –û–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –≤–æ–ø—Ä–æ—Å–æ–≤ —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ –ø–æ–∑–∏—Ü–∏—è–º–∏
    questions_updated = questions.copy()

    for seq in all_sequences:
        prog_name = seq['program']

        # –û–±–Ω–æ–≤–∏—Ç—å –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        for q in seq['questions_included']:
            # –ù–∞–π—Ç–∏ –≤–æ–ø—Ä–æ—Å –≤ –±–∞–∑–µ
            for base_q in questions_updated:
                if base_q['id'] == q['id']:
                    if 'programs_final' not in base_q:
                        base_q['programs_final'] = []

                    base_q['programs_final'].append({
                        'program': prog_name,
                        'position': q['program_position'],
                        'status': 'included'
                    })
                    break

        # –û–±–Ω–æ–≤–∏—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ
        for q in seq['questions_excluded']:
            for base_q in questions_updated:
                if base_q['id'] == q['id']:
                    if 'programs_final' not in base_q:
                        base_q['programs_final'] = []

                    base_q['programs_final'].append({
                        'program': prog_name,
                        'status': 'excluded',
                        'reason': q.get('exclusion_reason', 'unknown')
                    })
                    break

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –±–∞–∑—É
    data['questions'] = questions_updated

    final_db_file = Path('intelligent_question_core/data/selfology_final_sequenced.json')
    with open(final_db_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\n\n{'='*80}")
    print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")

    print(f"‚úÖ –ü—Ä–æ–≥—Ä–∞–º–º —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏: {len(programs_with_questions)}")
    for prog_name in programs_with_questions[:10]:
        seq = next(s for s in all_sequences if s['program'] == prog_name)
        print(f"   ‚Ä¢ {prog_name}: {seq['included_count']} –≤–æ–ø—Ä–æ—Å–æ–≤")

    if len(programs_with_questions) > 10:
        print(f"   ... –∏ –µ—â–µ {len(programs_with_questions) - 10}")

    print(f"\n‚ùå –ü—Ä–æ–≥—Ä–∞–º–º –±–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ (—Ç—Ä–µ–±—É—é—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏): {len(programs_without_questions)}")
    for prog_name in programs_without_questions:
        print(f"   ‚Ä¢ {prog_name}")

    total_included = sum(s['included_count'] for s in all_sequences)
    total_excluded = sum(s['excluded_count'] for s in all_sequences)

    print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤:")
    print(f"   –í–∫–ª—é—á–µ–Ω–æ –≤ –ø—Ä–æ–≥—Ä–∞–º–º—ã: {total_included}")
    print(f"   –ò—Å–∫–ª—é—á–µ–Ω–æ: {total_excluded}")

    print(f"\nüíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    print(f"   ‚Ä¢ {output_file}")
    print(f"   ‚Ä¢ {final_db_file}")

if __name__ == '__main__':
    main()