#!/usr/bin/env python3
"""
Script –¥–ª—è —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è elaborations –≤ intelligent core

üî¨ –ü–†–ò–ù–¶–ò–ü: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
üìã –ó–ê–î–ê–ß–ê: –°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å MD —Ñ–∞–π–ª —Å JSON –∏ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
üõ°Ô∏è –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨: Backup + –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
"""

import json
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

class ElaborationsUpdater:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ elaborate –≤ intelligent core"""
    
    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.json_file = self.base_path / "intelligent_question_core/data/selfology_intelligent_core.json"
        self.md_file = self.base_path / "intelligent_question_core/questions_with_elaborations.md"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.stats = {
            "md_questions_found": 0,
            "json_questions_total": 0,
            "matches_found": 0,
            "elaborations_added": 0,
            "classification_breakdown": {
                "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏_–ø–æ_–æ—Ç–≤–µ—Ç—É": 0,
                "–ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–∏—è": 0,
                "–ø—Ä–∏–∑—ã–≤—ã_–∫_–¥–µ–π—Å—Ç–≤–∏—é": 0,
                "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ_–æ–±—ä—è—Å–Ω–µ–Ω–∏—è": 0,
                "—Å–≤—è–∑—É—é—â–∏–µ_–∞–Ω–∞–ª–∏–∑—ã": 0
            }
        }
    
    def run_update(self) -> bool:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        
        try:
            print("üî¨ –ù–∞—á–∏–Ω–∞—é —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ elaborations...")
            
            # 1. –°–æ–∑–¥–∞–µ–º backup
            if not self._create_backup():
                return False
            
            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            json_data = self._load_json_data()
            md_elaborations = self._parse_md_elaborations()
            
            if not json_data or not md_elaborations:
                return False
            
            print(f"üìä JSON: {len(json_data['questions'])} –≤–æ–ø—Ä–æ—Å–æ–≤")
            print(f"üìä MD: {len(md_elaborations)} –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏")
            
            # 3. –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º
            updated_json = self._match_and_update(json_data, md_elaborations)
            
            # 4. –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if not self._validate_updated_json(updated_json):
                print("‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞ - –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º—Å—è –∫ backup")
                return False
            
            # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if self._save_updated_json(updated_json):
                self._print_statistics()
                print("‚úÖ Elaborations —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã!")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            return False
    
    def _create_backup(self) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ backup —Ñ–∞–π–ª–∞"""
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.json_file.with_suffix(f".backup_{timestamp}.json")
            
            shutil.copy2(self.json_file, backup_path)
            print(f"üõ°Ô∏è Backup —Å–æ–∑–¥–∞–Ω: {backup_path.name}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è backup: {e}")
            return False
    
    def _load_json_data(self) -> Optional[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ JSON –¥–∞–Ω–Ω—ã—Ö"""
        
        try:
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.stats["json_questions_total"] = len(data.get("questions", []))
            print(f"üìñ JSON –∑–∞–≥—Ä—É–∂–µ–Ω: {self.stats['json_questions_total']} –≤–æ–ø—Ä–æ—Å–æ–≤")
            return data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ JSON: {e}")
            return None
    
    def _parse_md_elaborations(self) -> Dict[str, Dict[str, str]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ MD —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π"""
        
        try:
            with open(self.md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            elaborations = {}
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π
            # –ò—â–µ–º: ### ... –í–æ–ø—Ä–æ—Å: "—Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞" ... **üí° –î–æ–ø–æ–ª–Ω–µ–Ω–∏–µ:** —Ç–µ–∫—Å—Ç
            pattern = r'###[^#]*?–í–æ–ø—Ä–æ—Å:[^"]*?"([^"]+)".*?\*\*üí°[^:]*:\*\*\s*(.*?)(?=\n---|\n###|$)'
            
            matches = re.findall(pattern, content, re.DOTALL | re.MULTILINE)
            
            for question_text, elaboration_text in matches:
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
                clean_question = question_text.strip()
                
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
                clean_elaboration = elaboration_text.strip()
                clean_elaboration = re.sub(r'\n+', '\n', clean_elaboration)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ç–∏–ø –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è
                elaboration_type = self._classify_elaboration(clean_elaboration)
                
                elaborations[clean_question] = {
                    "type": elaboration_type,
                    "content": clean_elaboration,
                    "priority": self._determine_priority(clean_elaboration)
                }
                
                self.stats["classification_breakdown"][elaboration_type] += 1
            
            self.stats["md_questions_found"] = len(elaborations)
            print(f"üìù –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(elaborations)} –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π –∏–∑ MD")
            
            return elaborations
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ MD: {e}")
            return {}
    
    def _classify_elaboration(self, elaboration_text: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ —Ç–∏–ø—É"""
        
        text_lower = elaboration_text.lower()
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –æ—Ç–≤–µ—Ç—É
        if any(word in text_lower for word in [
            "–æ—Ç–≤–µ—á–∞—è", "–æ—Ç–≤–µ—Ç–∏—Ç—å", "–Ω–∞–ø–∏—à–∏—Ç–µ", "–≤—ã–ø–∏—à–∏—Ç–µ", "–æ—Ç–Ω–µ—Å–∏—Ç–µ—Å—å", 
            "–≤–∞–∂–Ω–∞ –∫–∞–∂–¥–∞—è –¥–µ—Ç–∞–ª—å", "–Ω–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"
        ]):
            return "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏_–ø–æ_–æ—Ç–≤–µ—Ç—É"
        
        # –ü—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–∏—è
        elif any(word in text_lower for word in [
            "–Ω–µ –¥—É–º–∞–π—Ç–µ", "–Ω–µ –¥–µ—Ä–∂–∏—Ç–µ –≤ –≥–æ–ª–æ–≤–µ", "–Ω–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å",
            "–≤–∞–∂–Ω–æ", "–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ", "–≤–Ω–∏–º–∞–Ω–∏–µ"
        ]):
            return "–ø—Ä–µ–¥–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–∏—è"
        
        # –ü—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é
        elif any(word in text_lower for word in [
            "–ø—Ä–∏–¥—É–º–∞–π—Ç–µ", "—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ", "–¥–µ–π—Å—Ç–≤–∏—é", "—Å–¥–µ–ª–∞–π—Ç–µ",
            "–ø–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫", "–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è"
        ]):
            return "–ø—Ä–∏–∑—ã–≤—ã_–∫_–¥–µ–π—Å—Ç–≤–∏—é"
        
        # –ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        elif any(word in text_lower for word in [
            "—Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π", "–ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ", "—Å–∏—Å—Ç–µ–º–∞", "—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
            "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏", "–≤–∞–∂–Ω–æ –¥–ª—è"
        ]):
            return "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ_–æ–±—ä—è—Å–Ω–µ–Ω–∏—è"
        
        # –°–≤—è–∑—É—é—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç —Å–≤—è–∑–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Ç–µ–º–∞–º–∏)
        elif any(word in text_lower for word in [
            "—Å–≤—è–∑–∞–Ω–æ —Å", "–≤–ª–∏—è–µ—Ç –Ω–∞", "—Ä–∞—Å–∫—Ä—ã–≤–∞—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",
            "–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ", "—Ç–∞–∫–∂–µ"
        ]):
            return "—Å–≤—è–∑—É—é—â–∏–µ_–∞–Ω–∞–ª–∏–∑—ã"
        
        # Fallback - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        return "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏_–ø–æ_–æ—Ç–≤–µ—Ç—É"
    
    def _determine_priority(self, elaboration_text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è"""
        
        text_length = len(elaboration_text)
        
        if text_length > 300:
            return "high"
        elif text_length > 100:
            return "medium"
        else:
            return "low"
    
    def _match_and_update(
        self, 
        json_data: Dict[str, Any], 
        md_elaborations: Dict[str, Dict[str, str]]
    ) -> Dict[str, Any]:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏ —Ö–∏—Ä—É—Ä–≥–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ"""
        
        print("üîç –ù–∞—á–∏–Ω–∞—é —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤...")
        
        updated_questions = []
        
        for question in json_data["questions"]:
            question_text = question.get("text", "")
            
            # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ –±–ª–∏–∑–∫–æ–µ
            matching_elaboration = self._find_matching_elaboration(question_text, md_elaborations)
            
            if matching_elaboration:
                # –•–ò–†–£–†–ì–ò–ß–ï–°–ö–û–ï –î–û–ë–ê–í–õ–ï–ù–ò–ï - —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ "text"
                updated_question = {}
                
                for key, value in question.items():
                    updated_question[key] = value
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º elaborations —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ text
                    if key == "text":
                        updated_question["elaborations"] = matching_elaboration
                
                updated_questions.append(updated_question)
                self.stats["matches_found"] += 1
                self.stats["elaborations_added"] += 1
                
                print(f"‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {question.get('id', 'unknown')} - {matching_elaboration['type']}")
                
            else:
                # –û—Å—Ç–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                updated_questions.append(question)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å—é –æ—Å—Ç–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        updated_json = json_data.copy()
        updated_json["questions"] = updated_questions
        
        return updated_json
    
    def _find_matching_elaboration(
        self, 
        question_text: str, 
        elaborations: Dict[str, Dict[str, str]]
    ) -> Optional[Dict[str, str]]:
        """–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞"""
        
        # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if question_text in elaborations:
            return elaborations[question_text]
        
        # 2. –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        question_lower = question_text.lower()
        question_words = set(re.findall(r'\w+', question_lower))
        
        best_match = None
        best_score = 0.0
        
        for md_question, elaboration in elaborations.items():
            md_lower = md_question.lower()
            md_words = set(re.findall(r'\w+', md_lower))
            
            # –°—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤
            common_words = question_words.intersection(md_words)
            if len(question_words) > 0:
                similarity_score = len(common_words) / len(question_words)
                
                # –ï—Å–ª–∏ —Å—Ö–æ–∂–µ—Å—Ç—å –±–æ–ª—å—à–µ 70% - —Å—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
                if similarity_score > 0.7 and similarity_score > best_score:
                    best_score = similarity_score
                    best_match = elaboration
        
        return best_match
    
    def _validate_updated_json(self, updated_json: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ JSON"""
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            required_keys = ["core_metadata", "questions"]
            for key in required_keys:
                if key not in updated_json:
                    print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á: {key}")
                    return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
            original_count = self.stats["json_questions_total"]
            new_count = len(updated_json["questions"])
            
            if original_count != new_count:
                print(f"‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å: {original_count} ‚Üí {new_count}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã –∏–º–µ—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            for i, question in enumerate(updated_json["questions"]):
                required_question_keys = ["id", "text", "classification", "psychology"]
                for key in required_question_keys:
                    if key not in question:
                        print(f"‚ùå –í–æ–ø—Ä–æ—Å #{i} –Ω–µ –∏–º–µ–µ—Ç –∫–ª—é—á–∞: {key}")
                        return False
            
            print("‚úÖ JSON –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            return False
    
    def _save_updated_json(self, updated_json: Dict[str, Any]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ JSON"""
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            updated_json["core_metadata"]["last_updated"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            updated_json["core_metadata"]["elaborations_added"] = self.stats["elaborations_added"]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å –∫—Ä–∞—Å–∏–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            with open(self.json_file, 'w', encoding='utf-8') as f:
                json.dump(updated_json, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return False
    
    def _print_statistics(self):
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–ù–û–í–õ–ï–ù–ò–Ø:")
        print(f"üìñ –í–æ–ø—Ä–æ—Å–æ–≤ –≤ MD —Ñ–∞–π–ª–µ: {self.stats['md_questions_found']}")
        print(f"üìñ –í–æ–ø—Ä–æ—Å–æ–≤ –≤ JSON: {self.stats['json_questions_total']}")
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {self.stats['matches_found']}")
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ elaborations: {self.stats['elaborations_added']}")
        
        print("\nüè∑Ô∏è –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π:")
        for type_name, count in self.stats["classification_breakdown"].items():
            if count > 0:
                print(f"  ‚Ä¢ {type_name}: {count}")
        
        coverage = (self.stats['matches_found'] / max(1, self.stats['md_questions_found'])) * 100
        print(f"\nüìà –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage:.1f}% –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ MD –Ω–∞–π–¥–µ–Ω—ã –≤ JSON")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    updater = ElaborationsUpdater()
    
    print("üî¨ Selfology Elaborations Updater")
    print("=" * 50)
    
    success = updater.run_update()
    
    if success:
        print("\nüéâ –û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("üìÅ Backup —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        print("‚úÖ JSON —Ñ–∞–π–ª –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    else:
        print("\n‚ùå –û–ë–ù–û–í–õ–ï–ù–ò–ï –ù–ï –£–î–ê–õ–û–°–¨")
        print("üõ°Ô∏è –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–µ–Ω")
    
    return success

if __name__ == "__main__":
    main()