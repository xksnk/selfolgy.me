#!/usr/bin/env python3
"""
–°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–∑ Notion –ø—Ä–æ–≥—Ä–∞–º–º —Å –±–∞–∑–æ–π 1331 –≤–æ–ø—Ä–æ—Å
–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ program –∏ position
"""
import json
from pathlib import Path
from difflib import SequenceMatcher
import re

def normalize_text(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    # –£–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫
    text = re.sub(r'\s+', ' ', text)
    # –£–±—Ä–∞—Ç—å –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
    text = text.strip().rstrip('?.!,;:')
    # –ù–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
    text = text.lower()
    return text

def texts_similar(text1, text2, threshold=0.85):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤"""
    norm1 = normalize_text(text1)
    norm2 = normalize_text(text2)

    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if norm1 == norm2:
        return 1.0

    # Fuzzy matching
    ratio = SequenceMatcher(None, norm1, norm2).ratio()
    return ratio if ratio >= threshold else 0.0

def main():
    print("üîó –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –í–û–ü–†–û–°–û–í –ò–ó NOTION –° –ë–ê–ó–û–ô\n")
    print("="*80)

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∏–∑ Notion –ø—Ä–æ–≥—Ä–∞–º–º
    notion_file = Path('prompts/notion_programs_with_questions.json')
    with open(notion_file, 'r', encoding='utf-8') as f:
        notion_programs = json.load(f)

    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –≤–æ–ø—Ä–æ—Å–æ–≤
    db_file = Path('intelligent_question_core/data/selfology_intelligent_core_complete.json')
    with open(db_file, 'r', encoding='utf-8') as f:
        db_data = json.load(f)

    db_questions = db_data['questions']

    print(f"üìä –í–æ–ø—Ä–æ—Å–æ–≤ –≤ Notion –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö: {sum(p['total_questions'] for p in notion_programs)}")
    print(f"üìä –í–æ–ø—Ä–æ—Å–æ–≤ –≤ –±–∞–∑–µ: {len(db_questions)}\n")

    # –°–æ–∑–¥–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    # normalized_text -> list of db questions
    db_index = {}
    for q in db_questions:
        norm_text = normalize_text(q['text'])
        if norm_text not in db_index:
            db_index[norm_text] = []
        db_index[norm_text].append(q)

    # –°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å
    matches = []
    unmatched_notion = []

    for program in notion_programs:
        program_name = program['name']

        if program['total_questions'] == 0:
            continue

        print(f"\n{'‚îÄ'*80}")
        print(f"üìÑ –ü—Ä–æ–≥—Ä–∞–º–º–∞: {program_name}")
        print(f"   –í–æ–ø—Ä–æ—Å–æ–≤: {program['total_questions']}")

        program_matches = 0

        for position, notion_q in enumerate(program['questions'], 1):
            notion_text = notion_q['text']
            norm_notion = normalize_text(notion_text)

            # –ü–æ–∏—Å–∫ —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            if norm_notion in db_index:
                for db_q in db_index[norm_notion]:
                    matches.append({
                        'program': program_name,
                        'position': position,
                        'notion_text': notion_text,
                        'db_question_id': db_q['id'],
                        'db_text': db_q['text'],
                        'match_type': 'exact',
                        'similarity': 1.0
                    })
                    program_matches += 1
                    print(f"   ‚úÖ {position}. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {db_q['id']}")
                    break
            else:
                # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
                best_match = None
                best_similarity = 0.0

                for db_q in db_questions[:500]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 500 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    similarity = texts_similar(notion_text, db_q['text'], threshold=0.80)

                    if similarity > best_similarity:
                        best_similarity = similarity
                        best_match = db_q

                if best_match and best_similarity >= 0.80:
                    matches.append({
                        'program': program_name,
                        'position': position,
                        'notion_text': notion_text,
                        'db_question_id': best_match['id'],
                        'db_text': best_match['text'],
                        'match_type': 'fuzzy',
                        'similarity': best_similarity
                    })
                    program_matches += 1
                    print(f"   üî∏ {position}. –ü–æ—Ö–æ–∂–∏–π ({best_similarity:.0%}): {best_match['id']}")
                else:
                    unmatched_notion.append({
                        'program': program_name,
                        'position': position,
                        'text': notion_text
                    })
                    print(f"   ‚ùå {position}. –ù–ï –Ω–∞–π–¥–µ–Ω: {notion_text[:60]}...")

        print(f"   üìä –°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {program_matches}/{program['total_questions']}")

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_file = Path('prompts/program_question_matches.json')

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'matches': matches,
            'unmatched_notion_questions': unmatched_notion,
            'stats': {
                'total_notion_questions': sum(p['total_questions'] for p in notion_programs),
                'total_matches': len(matches),
                'exact_matches': sum(1 for m in matches if m['match_type'] == 'exact'),
                'fuzzy_matches': sum(1 for m in matches if m['match_type'] == 'fuzzy'),
                'unmatched': len(unmatched_notion)
            }
        }, f, ensure_ascii=False, indent=2)

    print(f"\n\n{'='*80}")
    print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("="*80)
    print(f"‚úÖ –í—Å–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}")
    print(f"   ‚Ä¢ –¢–æ—á–Ω—ã—Ö: {sum(1 for m in matches if m['match_type'] == 'exact')}")
    print(f"   ‚Ä¢ –ü–æ—Ö–æ–∂–∏—Ö: {sum(1 for m in matches if m['match_type'] == 'fuzzy')}")
    print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {len(unmatched_notion)}")
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

    # –ü–æ–∫–∞–∑–∞—Ç—å –Ω–µ—Å–æ–≤–ø–∞–≤—à–∏–µ
    if unmatched_notion:
        print(f"\n\nüîç –ù–ï–°–û–í–ü–ê–í–®–ò–ï –í–û–ü–†–û–°–´ (–ø–µ—Ä–≤—ã–µ 10):")
        for i, um in enumerate(unmatched_notion[:10], 1):
            print(f"{i}. [{um['program']}] {um['text'][:70]}...")

if __name__ == '__main__':
    main()
