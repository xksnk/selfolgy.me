#!/usr/bin/env python3
"""
Data Migration: public ‚Üí selfology schema

Zero-downtime migration strategy:
1. Dual Write Phase: –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –∏–¥—É—Ç –≤ selfology, —Å—Ç–∞—Ä—ã–µ –≤ public
2. Background Copy: –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ public ‚Üí selfology
3. Validation: –°–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
4. Switch: –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–∞ selfology
5. Cleanup: –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ public (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

Usage:
    # –°—É—Ö–æ–π –ø—Ä–æ–≥–æ–Ω (dry run)
    python scripts/migrate_to_selfology_schema.py --dry-run

    # –ú–∏–≥—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    python scripts/migrate_to_selfology_schema.py --table users

    # –ú–∏–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
    python scripts/migrate_to_selfology_schema.py --all

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏
    python scripts/migrate_to_selfology_schema.py --validate

Safety:
- –ù–µ —É–¥–∞–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ public
- –°–æ–∑–¥–∞–µ—Ç backup –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π
- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç diff –ø–µ—Ä–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç rollback
"""

import asyncio
import asyncpg
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import sys

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# CONFIGURATION
# ============================================================================

DB_CONFIG = {
    "host": "n8n-postgres",
    "port": 5432,
    "user": "postgres",
    "password": "sS67wM+1zMBRFHAW4kj9HwFl5J6+veo7Nirx0/I+oiU=",
    "database": "n8n"
}

# –¢–∞–±–ª–∏—Ü—ã –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ (public ‚Üí selfology)
TABLES_TO_MIGRATE = [
    "users",
    "user_answers_new",
    "answer_analysis",
    "onboarding_sessions",
    "questions_metadata"
]


# ============================================================================
# MIGRATION ENGINE
# ============================================================================

class SchemaMigrator:
    """
    Zero-downtime –º–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Å—Ö–µ–º–∞–º–∏
    """

    def __init__(self, db_config: Dict):
        self.db_config = db_config
        self.pool: Optional[asyncpg.Pool] = None

    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
        self.pool = await asyncpg.create_pool(**self.db_config)
        logger.info("‚úÖ Connected to PostgreSQL")

    async def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç –ë–î"""
        if self.pool:
            await self.pool.close()
            logger.info("‚úÖ Disconnected from PostgreSQL")

    async def table_exists(self, schema: str, table: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã"""
        async with self.pool.acquire() as conn:
            result = await conn.fetchval(
                """
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.tables
                    WHERE table_schema = $1 AND table_name = $2
                )
                """,
                schema, table
            )
            return result

    async def get_table_structure(self, schema: str, table: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã"""
        async with self.pool.acquire() as conn:
            columns = await conn.fetch(
                """
                SELECT
                    column_name,
                    data_type,
                    is_nullable,
                    column_default
                FROM information_schema.columns
                WHERE table_schema = $1 AND table_name = $2
                ORDER BY ordinal_position
                """,
                schema, table
            )
            return [dict(col) for col in columns]

    async def get_row_count(self, schema: str, table: str) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫"""
        async with self.pool.acquire() as conn:
            count = await conn.fetchval(
                f"SELECT COUNT(*) FROM {schema}.{table}"
            )
            return count

    async def copy_table_data(
        self,
        source_schema: str,
        target_schema: str,
        table: str,
        batch_size: int = 1000,
        dry_run: bool = False
    ) -> Tuple[int, int]:
        """
        –ö–æ–ø–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ source ‚Üí target

        Returns:
            (copied_rows, skipped_rows)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±–µ —Ç–∞–±–ª–∏—Ü—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        source_exists = await self.table_exists(source_schema, table)
        target_exists = await self.table_exists(target_schema, table)

        if not source_exists:
            logger.error(f"‚ùå Source table {source_schema}.{table} not found")
            return 0, 0

        if not target_exists:
            logger.error(f"‚ùå Target table {target_schema}.{table} not found")
            return 0, 0

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
        columns = await self.get_table_structure(target_schema, table)
        column_names = [col['column_name'] for col in columns]
        column_list = ', '.join(column_names)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏
        source_count = await self.get_row_count(source_schema, table)
        target_count = await self.get_row_count(target_schema, table)

        logger.info(
            f"üìä {table}: {source_count} rows in {source_schema}, "
            f"{target_count} rows in {target_schema}"
        )

        if dry_run:
            logger.info(f"üîç DRY RUN: Would copy {source_count - target_count} rows")
            return 0, 0

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏
        async with self.pool.acquire() as conn:
            copied = 0
            skipped = 0
            offset = 0

            while True:
                # –ß–∏—Ç–∞–µ–º batch –∏–∑ source
                rows = await conn.fetch(
                    f"""
                    SELECT {column_list}
                    FROM {source_schema}.{table}
                    ORDER BY id
                    LIMIT $1 OFFSET $2
                    """,
                    batch_size, offset
                )

                if not rows:
                    break

                # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ target (ON CONFLICT DO NOTHING –¥–ª—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏)
                for row in rows:
                    try:
                        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –µ—Å—Ç—å primary key 'id'
                        placeholders = ', '.join(f'${i+1}' for i in range(len(column_names)))

                        await conn.execute(
                            f"""
                            INSERT INTO {target_schema}.{table} ({column_list})
                            VALUES ({placeholders})
                            ON CONFLICT (id) DO NOTHING
                            """,
                            *[row[col] for col in column_names]
                        )
                        copied += 1
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Failed to copy row {row.get('id')}: {e}")
                        skipped += 1

                offset += batch_size

                if copied % 1000 == 0 and copied > 0:
                    logger.info(f"  üì¶ Copied {copied} rows so far...")

        logger.info(
            f"‚úÖ {table}: Copied {copied} rows, skipped {skipped} rows"
        )

        return copied, skipped

    async def validate_migration(
        self,
        source_schema: str,
        target_schema: str,
        table: str
    ) -> bool:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —á—Ç–æ –º–∏–≥—Ä–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ

        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
        1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
        2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü –∏–¥–µ–Ω—Ç–∏—á–Ω–∞
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        source_count = await self.get_row_count(source_schema, table)
        target_count = await self.get_row_count(target_schema, table)

        if source_count != target_count:
            logger.error(
                f"‚ùå {table}: Row count mismatch! "
                f"{source_schema}={source_count}, {target_schema}={target_count}"
            )
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        source_structure = await self.get_table_structure(source_schema, table)
        target_structure = await self.get_table_structure(target_schema, table)

        source_cols = {col['column_name'] for col in source_structure}
        target_cols = {col['column_name'] for col in target_structure}

        if source_cols != target_cols:
            missing_in_target = source_cols - target_cols
            extra_in_target = target_cols - source_cols

            if missing_in_target:
                logger.error(f"‚ùå {table}: Missing columns in target: {missing_in_target}")
            if extra_in_target:
                logger.warning(f"‚ö†Ô∏è {table}: Extra columns in target: {extra_in_target}")

            return False

        logger.info(f"‚úÖ {table}: Validation passed ({target_count} rows)")
        return True

    async def migrate_all_tables(self, dry_run: bool = False):
        """–ú–∏–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã"""
        logger.info("üöÄ Starting full migration: public ‚Üí selfology")
        logger.info(f"üìã Tables to migrate: {', '.join(TABLES_TO_MIGRATE)}")

        total_copied = 0
        total_skipped = 0

        for table in TABLES_TO_MIGRATE:
            logger.info(f"\n{'='*60}")
            logger.info(f"Migrating table: {table}")
            logger.info(f"{'='*60}")

            copied, skipped = await self.copy_table_data(
                source_schema="public",
                target_schema="selfology",
                table=table,
                dry_run=dry_run
            )

            total_copied += copied
            total_skipped += skipped

        logger.info(f"\n{'='*60}")
        logger.info(f"‚úÖ Migration complete!")
        logger.info(f"üìä Total: {total_copied} rows copied, {total_skipped} skipped")
        logger.info(f"{'='*60}")

        return total_copied, total_skipped

    async def validate_all_tables(self):
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã"""
        logger.info("üîç Validating migration...")

        all_valid = True

        for table in TABLES_TO_MIGRATE:
            valid = await self.validate_migration("public", "selfology", table)
            if not valid:
                all_valid = False

        if all_valid:
            logger.info("\n‚úÖ All tables validated successfully!")
        else:
            logger.error("\n‚ùå Validation failed for some tables")

        return all_valid


# ============================================================================
# CLI
# ============================================================================

async def main():
    parser = argparse.ArgumentParser(
        description="Migrate data from public to selfology schema"
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Dry run - show what would be done without actual changes'
    )
    parser.add_argument(
        '--table',
        type=str,
        help='Migrate specific table only'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='Migrate all tables'
    )
    parser.add_argument(
        '--validate',
        action='store_true',
        help='Validate migration (compare row counts)'
    )

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º migrator
    migrator = SchemaMigrator(DB_CONFIG)

    try:
        await migrator.connect()

        if args.validate:
            # –¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è
            await migrator.validate_all_tables()

        elif args.all:
            # –ú–∏–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
            await migrator.migrate_all_tables(dry_run=args.dry_run)

            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏
            if not args.dry_run:
                logger.info("\n" + "="*60)
                await migrator.validate_all_tables()

        elif args.table:
            # –ú–∏–≥—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            copied, skipped = await migrator.copy_table_data(
                source_schema="public",
                target_schema="selfology",
                table=args.table,
                dry_run=args.dry_run
            )

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if not args.dry_run:
                await migrator.validate_migration("public", "selfology", args.table)
        else:
            parser.print_help()

    except Exception as e:
        logger.error(f"‚ùå Migration failed: {e}", exc_info=True)
        sys.exit(1)

    finally:
        await migrator.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
