#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç embedded JSON –¥–∞–Ω–Ω—ã–µ –æ—Ç –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤
–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª.
"""

import json
from pathlib import Path
from collections import Counter
from datetime import datetime

# ============================================================================
# EMBEDDED JSON DATA FROM AGENTS (Generated by Claude Opus 4)
# ============================================================================

# –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –î–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
# –°–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞—Å—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è

def load_generated_blocks():
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –±–ª–æ–∫–∏ –≤–æ–ø—Ä–æ—Å–æ–≤

    –í–ê–ñ–ù–û: –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–æ–ª–Ω–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∏–∂–µ
    JSON –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ Task outputs
    """

    # TODO: –°–∫–æ–ø–∏—Ä—É–π JSON arrays –∏–∑ Task outputs –≤ —ç—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    blocks = {
        "EDGE": [],  # 75 questions from Task output 1
        "SHADOW": [],  # 40 questions from Task output 2
        "CORE": [],  # 25 questions from Task output 3
        "HEALING": [],  # 60 questions from Task output 4
        "EMOTIONS": [],  # 50 questions from Task output 5
        "RELATIONSHIPS": [],  # 50 questions from Task output 6
        "GOALS": [],  # 50 questions from Task output 7
        "FEARS": [],  # 30 questions from Task output 8
        "VALUES": [],  # 30 questions from Task output 9
        "ENTRY": [],  # 50 questions from Task output 10
        "DEEPENING": [],  # 100 questions from Task output 11
        "INTEGRATING": [],  # 50 questions from Task output 12
        "TRANSFORMING": []  # 30 questions from Task output 13
    }

    return blocks


def merge_all_questions(blocks):
    """–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –±–ª–æ–∫–∏ –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫"""

    all_questions = []

    for block_name, questions in blocks.items():
        if questions:
            all_questions.extend(questions)
            print(f"  ‚úÖ {block_name}: {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        else:
            print(f"  ‚ö†Ô∏è {block_name}: –ü–£–°–¢–û–ô (–Ω—É–∂–Ω–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å)")

    return all_questions


def validate_questions(questions):
    """–ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤"""

    issues = []

    required_fields = ["id", "text", "classification", "psychology", "processing_hints"]

    for idx, q in enumerate(questions):
        q_id = q.get("id", f"question_{idx}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in required_fields:
            if field not in q:
                issues.append(f"{q_id}: missing field '{field}'")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ classification
        if "classification" in q:
            cls = q["classification"]
            if "domain" not in cls:
                issues.append(f"{q_id}: missing classification.domain")
            elif cls["domain"] in ["patterns", "past_present", "evolution", "lessons", "contradictions"]:
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã –∏–∑ INTEGRATING
                issues.append(f"{q_id}: non-standard domain '{cls['domain']}' (needs mapping)")

    return issues


def fix_integrating_domains(questions):
    """–ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã –≤ INTEGRATING –≤–æ–ø—Ä–æ—Å–∞—Ö"""

    domain_mapping = {
        "patterns": "IDENTITY",
        "past_present": "PAST",
        "contradictions": "IDENTITY",
        "lessons": "GROWTH",
        "evolution": "GROWTH"
    }

    fixed_count = 0

    for q in questions:
        cls = q.get("classification", {})
        domain = cls.get("domain")

        if domain in domain_mapping:
            old_domain = domain
            cls["domain"] = domain_mapping[domain]
            fixed_count += 1
            print(f"    Fixed {q['id']}: {old_domain} ‚Üí {cls['domain']}")

    if fixed_count > 0:
        print(f"  ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {fixed_count} –¥–æ–º–µ–Ω–æ–≤")

    return questions


def calculate_statistics(questions):
    """–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""

    stats = {
        "total": len(questions),
        "domains": Counter(),
        "depth_levels": Counter(),
        "energy_dynamics": Counter(),
        "journey_stages": Counter(),
        "complexity": Counter(),
        "trust_requirement": Counter()
    }

    for q in questions:
        cls = q.get("classification", {})
        psy = q.get("psychology", {})

        stats["domains"][cls.get("domain")] += 1
        stats["depth_levels"][cls.get("depth_level")] += 1
        stats["energy_dynamics"][cls.get("energy_dynamic")] += 1
        stats["journey_stages"][cls.get("journey_stage")] += 1
        stats["complexity"][psy.get("complexity")] += 1
        stats["trust_requirement"][psy.get("trust_requirement")] += 1

    return stats


def print_statistics(stats):
    """–í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""

    print("\n" + "="*80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–• –í–û–ü–†–û–°–û–í")
    print("="*80)
    print(f"\n–í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {stats['total']}\n")

    print("üè∑Ô∏è  DOMAINS:")
    for domain, count in sorted(stats["domains"].items(), key=lambda x: x[1], reverse=True):
        pct = count / stats["total"] * 100
        print(f"  {domain:20s} {count:3d} ({pct:5.1f}%)")

    print("\nüìä DEPTH LEVELS:")
    for depth, count in sorted(stats["depth_levels"].items(), key=lambda x: x[1], reverse=True):
        pct = count / stats["total"] * 100
        print(f"  {depth:20s} {count:3d} ({pct:5.1f}%)")

    print("\n‚ö° ENERGY DYNAMICS:")
    for energy, count in sorted(stats["energy_dynamics"].items(), key=lambda x: x[1], reverse=True):
        pct = count / stats["total"] * 100
        print(f"  {energy:20s} {count:3d} ({pct:5.1f}%)")

    print("\nüöÄ JOURNEY STAGES:")
    for stage, count in sorted(stats["journey_stages"].items(), key=lambda x: x[1], reverse=True):
        pct = count / stats["total"] * 100
        print(f"  {stage:20s} {count:3d} ({pct:5.1f}%)")


def save_merged_file(questions, stats):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª"""

    result = {
        "metadata": {
            "version": "2.0",
            "title": "AI Generated Questions - Missing Categories",
            "generation_date": datetime.now().strftime("%Y-%m-%d"),
            "generation_model": "claude-opus-4",
            "total_questions": len(questions),
            "categories": {
                "depth_levels": dict(stats["depth_levels"]),
                "energy_dynamics": dict(stats["energy_dynamics"]),
                "journey_stages": dict(stats["journey_stages"]),
                "domains": dict(stats["domains"])
            }
        },
        "questions": questions
    }

    project_root = Path(__file__).parent.parent
    output_file = project_root / "intelligent_question_core" / "data" / "generated_questions_v2.json"

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {output_file.stat().st_size / 1024:.1f} KB")

    return output_file


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""

    print("üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤\n")

    # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–ª–æ–∫–∏
    print("üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –±–ª–æ–∫–æ–≤...")
    blocks = load_generated_blocks()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã
    empty_blocks = [name for name, data in blocks.items() if not data]
    if empty_blocks:
        print(f"\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –°–ª–µ–¥—É—é—â–∏–µ –±–ª–æ–∫–∏ –ü–£–°–¢–´–ï:")
        for block in empty_blocks:
            print(f"  - {block}")
        print(f"\nüìù –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π —Å–∫—Ä–∏–ø—Ç –∏ –¥–æ–±–∞–≤—å JSON –¥–∞–Ω–Ω—ã–µ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ blocks[]")
        print(f"   –î–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ Task outputs –≤—ã—à–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ")
        return

    # 2. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å
    print("\nüîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤...")
    all_questions = merge_all_questions(blocks)

    if not all_questions:
        print("\n‚ùå –ù–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è!")
        return

    # 3. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    print("\nüîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤...")
    all_questions = fix_integrating_domains(all_questions)

    # 4. –í–∞–ª–∏–¥–∞—Ü–∏—è
    print("\n‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è...")
    issues = validate_questions(all_questions)

    if issues:
        print(f"\n‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(issues)}")
        for issue in issues[:10]:
            print(f"  - {issue}")
        if len(issues) > 10:
            print(f"  ... –∏ –µ—â–µ {len(issues) - 10} –ø—Ä–æ–±–ª–µ–º")
    else:
        print("  ‚úÖ –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã –≤–∞–ª–∏–¥–Ω—ã!")

    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
    stats = calculate_statistics(all_questions)
    print_statistics(stats)

    # 6. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...")
    output_file = save_merged_file(all_questions, stats)

    print("\n" + "="*80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("="*80)
    print(f"\n–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {len(all_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
    print(f"–§–∞–π–ª: {output_file}")
    print(f"\n–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
    print(f"  python3 scripts/validate_questions_completeness.py")


if __name__ == "__main__":
    main()
