"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç Phase 2-3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≤ ChatCoachService

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –≤—Å–µ 6 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –∏ —Ä–∞–±–æ—Ç–∞—é—Ç:
- Enhanced AI Router
- Adaptive Communication Style
- Deep Question Generator
- Micro Interventions
- Confidence Calculator
- Vector Storytelling
"""
import sys
sys.path.append('/home/ksnk/n8n-enterprise/projects/selfology')

from coach.components.enhanced_ai_router import EnhancedAIRouter
from coach.components.adaptive_communication_style import AdaptiveCommunicationStyle
from coach.components.deep_question_generator import DeepQuestionGenerator
from coach.components.micro_interventions import MicroInterventions
from coach.components.confidence_calculator import ConfidenceCalculator
from coach.components.vector_storytelling import VectorStorytelling


def test_enhanced_router():
    """–¢–µ—Å—Ç Enhanced AI Router"""
    print("\nüß™ –¢–µ—Å—Ç 1: Enhanced AI Router")

    router = EnhancedAIRouter()

    # Test crisis detection ‚Üí Claude Sonnet
    crisis_context = {
        'message': '–Ø –≤ –∫—Ä–∏–∑–∏—Å–µ, –Ω–µ –∑–Ω–∞—é —á—Ç–æ –¥–µ–ª–∞—Ç—å',
        'crisis_detected': True,
        'existential_question': False,
        'depth_level': 'SHADOW'
    }
    model = router.route(crisis_context)
    assert model == 'claude-3-5-sonnet', f"Expected claude-3-5-sonnet, got {model}"
    print(f"  ‚úÖ Crisis ‚Üí {model}")

    # Test simple chat ‚Üí GPT-4o-mini
    simple_context = {
        'message': '–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?',
        'crisis_detected': False,
        'existential_question': False
    }
    model = router.route(simple_context)
    assert model == 'gpt-4o-mini', f"Expected gpt-4o-mini, got {model}"
    print(f"  ‚úÖ Simple ‚Üí {model}")

    print("  ‚úÖ Enhanced Router —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def test_adaptive_style():
    """–¢–µ—Å—Ç Adaptive Communication Style"""
    print("\nüß™ –¢–µ—Å—Ç 2: Adaptive Communication Style")

    styler = AdaptiveCommunicationStyle()

    # Test high openness ‚Üí profound depth
    user_context = {
        'personality_profile': {
            'traits': {
                'big_five': {
                    'openness': 0.9,
                    'conscientiousness': 0.5,
                    'extraversion': 0.6,
                    'agreeableness': 0.7,
                    'neuroticism': 0.4
                }
            }
        },
        'current_mood': 'positive',
        'conversation_stage': 'deep_coaching'
    }

    style = styler.determine_style(user_context)
    assert style['depth_level'] in ['deep', 'profound'], f"Expected deep/profound, got {style['depth_level']}"
    print(f"  ‚úÖ High openness ‚Üí depth={style['depth_level']}")

    # Test format_response
    response = "–≠—Ç–æ –±–∞–∑–æ–≤—ã–π –æ—Ç–≤–µ—Ç."
    formatted = styler.format_response(response, style)
    assert len(formatted) > 0, "Formatted response is empty"
    print(f"  ‚úÖ Response formatting —Ä–∞–±–æ—Ç–∞–µ—Ç")

    print("  ‚úÖ Adaptive Style —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def test_deep_questions():
    """–¢–µ—Å—Ç Deep Question Generator"""
    print("\nüß™ –¢–µ—Å—Ç 3: Deep Question Generator")

    generator = DeepQuestionGenerator()

    user_context = {
        'big_five': {
            'openness': 0.8,
            'conscientiousness': 0.6
        },
        'conversation_stage': 'deep_coaching'
    }

    message_context = {
        'intent': 'advice_request',
        'domain': 'relationships',
        'insights_detected': True
    }

    questions = generator.generate_questions(user_context, message_context, count=2)
    assert isinstance(questions, list), "Questions should be a list"
    assert len(questions) <= 2, f"Expected max 2 questions, got {len(questions)}"

    if questions:
        print(f"  ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(questions)} –≤–æ–ø—Ä–æ—Å–æ–≤:")
        for q in questions:
            print(f"    ‚Ä¢ {q[:80]}...")

    print("  ‚úÖ Deep Questions —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def test_micro_interventions():
    """–¢–µ—Å—Ç Micro Interventions"""
    print("\nüß™ –¢–µ—Å—Ç 4: Micro Interventions")

    interventions = MicroInterventions()

    # Test reframing
    response = "–í–æ—Ç –≤–∞—à –æ—Ç–≤–µ—Ç."
    context = {
        'negative_belief_detected': True,
        'negative_statement': '–Ø –Ω–µ –º–æ–≥—É —ç—Ç–æ–≥–æ —Å–¥–µ–ª–∞—Ç—å'
    }

    result = interventions.inject(response, context)
    assert len(result) >= len(response), "Intervention should add content"
    print(f"  ‚úÖ Reframing –ø—Ä–∏–º–µ–Ω–µ–Ω (–¥–ª–∏–Ω–∞: {len(response)} ‚Üí {len(result)})")

    # Test anchoring
    context_positive = {
        'positive_state_detected': True,
        'positive_state': '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'
    }

    result = interventions.inject(response, context_positive)
    assert "üí´" in result or len(result) >= len(response), "Anchoring should work"
    print(f"  ‚úÖ Anchoring –ø—Ä–∏–º–µ–Ω–µ–Ω")

    print("  ‚úÖ Micro Interventions —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def test_confidence_calculator():
    """–¢–µ—Å—Ç Confidence Calculator"""
    print("\nüß™ –¢–µ—Å—Ç 5: Confidence Calculator")

    calc = ConfidenceCalculator()

    insight = {
        'text': '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–æ—Å—Ç –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç–∏',
        'type': 'spontaneous_realization',
        'domain': 'emotions'
    }

    user_context = {
        'personality_profile': {
            'traits': {
                'big_five': {
                    'openness': 0.7,
                    'conscientiousness': 0.6
                }
            }
        },
        'insights_history': [
            {'text': 'Previous insight 1'},
            {'text': 'Previous insight 2'}
        ]
    }

    confidence, explanation = calc.calculate(insight, user_context)

    assert 0.0 <= confidence <= 1.0, f"Confidence should be 0-1, got {confidence}"
    assert isinstance(explanation, str), "Explanation should be string"
    assert len(explanation) > 0, "Explanation should not be empty"

    print(f"  ‚úÖ Confidence: {confidence:.2f}")
    print(f"  ‚úÖ Explanation: {explanation[:80]}...")

    # Test formatting
    formatted = calc.format_with_confidence(insight['text'], confidence, explanation)
    assert insight['text'] in formatted, "Original text should be in formatted output"

    print("  ‚úÖ Confidence Calculator —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def test_vector_storytelling():
    """–¢–µ—Å—Ç Vector Storytelling"""
    print("\nüß™ –¢–µ—Å—Ç 6: Vector Storytelling (mock data)")

    storyteller = VectorStorytelling()

    # Mock evolution points
    evolution_points = [
        {
            'big_five': {'openness': 0.5, 'conscientiousness': 0.6},
            'is_milestone': False,
            'delta_magnitude': 0.1
        },
        {
            'big_five': {'openness': 0.7, 'conscientiousness': 0.65},
            'is_milestone': True,
            'delta_magnitude': 0.35,
            'trigger': '—Å–∞–º–æ–∞–Ω–∞–ª–∏–∑',
            'new_quality': '—Ç–≤–æ—Ä—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ'
        },
        {
            'big_five': {'openness': 0.75, 'conscientiousness': 0.7},
            'is_milestone': False,
            'delta_magnitude': 0.15
        }
    ]

    # Note: create_narrative is async, but we can test sync parts
    breakthroughs = storyteller._find_breakthroughs(evolution_points)
    assert isinstance(breakthroughs, list), "Breakthroughs should be a list"
    print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(breakthroughs)} –ø—Ä–æ—Ä—ã–≤–æ–≤")

    # Test archetype description
    archetype = storyteller._describe_archetype(evolution_points[1])
    assert isinstance(archetype, str), "Archetype should be string"
    print(f"  ‚úÖ –ê—Ä—Ö–µ—Ç–∏–ø: {archetype}")

    # Test trajectory
    trajectory = storyteller._describe_trajectory(evolution_points[0], evolution_points[2])
    assert isinstance(trajectory, str), "Trajectory should be string"
    print(f"  ‚úÖ –¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è: {trajectory[:80]}...")

    print("  ‚úÖ Vector Storytelling —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("=" * 70)
    print("üöÄ –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PHASE 2-3 –ö–û–ú–ü–û–ù–ï–ù–¢–û–í")
    print("=" * 70)

    try:
        test_enhanced_router()
        test_adaptive_style()
        test_deep_questions()
        test_micro_interventions()
        test_confidence_calculator()
        test_vector_storytelling()

        print("\n" + "=" * 70)
        print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("=" * 70)
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print("  ‚Ä¢ Enhanced AI Router: ‚úÖ")
        print("  ‚Ä¢ Adaptive Communication Style: ‚úÖ")
        print("  ‚Ä¢ Deep Question Generator: ‚úÖ")
        print("  ‚Ä¢ Micro Interventions: ‚úÖ")
        print("  ‚Ä¢ Confidence Calculator: ‚úÖ")
        print("  ‚Ä¢ Vector Storytelling: ‚úÖ")
        print("\nüéâ Phase 2-3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

        return True

    except AssertionError as e:
        print(f"\n‚ùå –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù: {e}")
        return False
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
