#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–Ω–∏–≥ Selfology
–°–æ–∑–¥–∞—ë—Ç –¥–≤–µ –∫–Ω–∏–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –≤–æ–ø—Ä–æ—Å–æ–≤:
- –ö–Ω–∏–≥–∞ 1: 29 –ø—Ä–æ–≥—Ä–∞–º–º —Å–∞–º–æ–ø–æ–∑–Ω–∞–Ω–∏—è (–ø–æ —Ç–µ–º–∞–º)
- –ö–Ω–∏–≥–∞ 2: –ü—É—Ç—å –≤ –≥–ª—É–±–∏–Ω—É (–æ—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∫ —Å–ª–æ–∂–Ω–æ–º—É)
"""

import json
import os
from pathlib import Path
from datetime import datetime

# –ü—É—Ç–∏
BASE_DIR = Path(__file__).parent.parent.parent.parent
SOURCE_JSON = BASE_DIR / "intelligent_question_core/data/selfology_programs_v2.json"
TRANSLATIONS_DIR = BASE_DIR / "intelligent_question_core/data/translations"
TEMPLATES_DIR = Path(__file__).parent.parent / "templates"
OUTPUT_DIR = Path(__file__).parent.parent / "exports"

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
LANGUAGES = ["ru"]  # –ü–æ–∫–∞ —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π, –ø–æ—Ç–æ–º –¥–æ–±–∞–≤–∏–º en, es

DEPTH_LABELS = {
    "ru": {
        "Foundation": "–ü–û–í–ï–†–•–ù–û–°–¢–¨",
        "Exploration": "–ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï",
        "Integration": "–ì–õ–£–ë–ò–ù–ê"
    },
    "en": {
        "Foundation": "SURFACE",
        "Exploration": "EXPLORATION",
        "Integration": "DEPTH"
    },
    "es": {
        "Foundation": "SUPERFICIE",
        "Exploration": "EXPLORACI√ìN",
        "Integration": "PROFUNDIDAD"
    }
}

DEPTH_TIME = {
    "Foundation": "5‚Äì10",
    "Exploration": "10‚Äì20",
    "Integration": "15‚Äì30"
}

DEPTH_NAMES = {
    "ru": {
        "Foundation": "–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å",
        "Exploration": "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
        "Integration": "–ì–ª—É–±–∏–Ω–∞"
    }
}

PART_DESCRIPTIONS = {
    "ru": {
        "Foundation": "–†–∞–∑–º–∏–Ω–∫–∞ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è. –õ—ë–≥–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã, —á—Ç–æ–±—ã –≤–æ–π—Ç–∏ –≤ –∫–æ–Ω—Ç–∞–∫—Ç —Å —Å–æ–±–æ–π.",
        "Exploration": "–û–ø—É—Å–∫–∞–µ–º—Å—è –≥–ª—É–±–∂–µ. –ó–¥–µ—Å—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞—Å—Ç–æ—è—â–∞—è —Ä–∞–±–æ—Ç–∞. –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.",
        "Integration": "–ì–ª—É–±–∏–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞. –≠—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã —Ç—Ä–µ–±—É—é—Ç —Å–∏–ª, –≤—Ä–µ–º–µ–Ω–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞."
    }
}


def escape_latex(text):
    """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã LaTeX –∏ —É–±—Ä–∞—Ç—å emoji"""
    if not text:
        return text

    # –£–±–∏—Ä–∞–µ–º emoji –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    cleanup = [
        ('‚Üí', '‚Äî'),  # –°—Ç—Ä–µ–ª–∫–∞ –Ω–∞ —Ç–∏—Ä–µ
        ('ü§ñ', ''),   # –†–æ–±–æ—Ç
        ('üö®', ''),   # –°–∏—Ä–µ–Ω–∞
        ('üå±', ''),   # –†–æ—Å—Ç–æ–∫
        ('üîç', ''),   # –õ—É–ø–∞
        ('üíé', ''),   # –ê–ª–º–∞–∑
        ('‚è±Ô∏è', ''),   # –¢–∞–π–º–µ—Ä
        ('‚ö†Ô∏è', ''),   # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
    ]
    for old, new in cleanup:
        text = text.replace(old, new)

    # –ü–æ—Ä—è–¥–æ–∫ –≤–∞–∂–µ–Ω - & –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–≤—ã–º
    replacements = [
        ('\\', '\\textbackslash{}'),
        ('&', '\\&'),
        ('%', '\\%'),
        ('$', '\\$'),
        ('#', '\\#'),
        ('_', '\\_'),
        ('{', '\\{'),
        ('}', '\\}'),
        ('~', '\\textasciitilde{}'),
        ('^', '\\textasciicircum{}'),
    ]
    for old, new in replacements:
        text = text.replace(old, new)
    return text


def load_source():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π JSON"""
    with open(SOURCE_JSON, "r", encoding="utf-8") as f:
        return json.load(f)


def load_translations(lang):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –¥–ª—è —è–∑—ã–∫–∞"""
    if lang == "ru":
        return None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª

    translations = {}
    for file_type in ["questions", "blocks", "programs"]:
        path = TRANSLATIONS_DIR / f"{file_type}_{lang}.json"
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                translations[file_type] = json.load(f)
        else:
            translations[file_type] = {}

    return translations


def get_text(item, field, translations, item_type):
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –Ω—É–∂–Ω–æ–º —è–∑—ã–∫–µ"""
    if translations is None:
        return item.get(field, "")

    item_id = item.get("id", "")
    trans_dict = translations.get(item_type, {})

    if item_id in trans_dict:
        if isinstance(trans_dict[item_id], dict):
            return trans_dict[item_id].get(field, item.get(field, ""))
        return trans_dict[item_id]

    return item.get(field, "")  # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª


def load_template(lang, template_name):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —à–∞–±–ª–æ–Ω –Ω–∞ –Ω—É–∂–Ω–æ–º —è–∑—ã–∫–µ"""
    path = TEMPLATES_DIR / lang / f"{template_name}.md"
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    return ""


def format_question_block(questions, translations, start_num=1):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –±–ª–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–æ, –±–µ–∑ –º–µ—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
    lines = []
    for i, question in enumerate(questions, start_num):
        q_text = get_text(question, "text", translations, "questions")
        q_text = escape_latex(q_text)
        lines.append(f"**{i}.** {q_text}")
        lines.append("")
    return "\n".join(lines)


def generate_book1(lang):
    """
    –ö–Ω–∏–≥–∞ 1: 29 –ø—Ä–æ–≥—Ä–∞–º–º —Å–∞–º–æ–ø–æ–∑–Ω–∞–Ω–∏—è
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –≥–ª–∞–≤—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º, –≤–Ω—É—Ç—Ä–∏ ‚Äî –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
    """
    print(f"  –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ö–Ω–∏–≥—É 1 ({lang})...")

    data = load_source()
    trans = load_translations(lang)

    output = []

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è Pandoc
    output.append("---")
    output.append("title: 29 –ø—Ä–æ–≥—Ä–∞–º–º —Å–∞–º–æ–ø–æ–∑–Ω–∞–Ω–∏—è")
    output.append("subtitle: –ö–Ω–∏–≥–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏")
    output.append("author: Selfology")
    output.append(f"date: {datetime.now().strftime('%Y')}")
    output.append("lang: ru")
    output.append("---")
    output.append("")

    # –í–≤–æ–¥–Ω–∞—è —á–∞—Å—Ç—å
    output.append(load_template(lang, "intro"))
    output.append("")
    output.append("\\newpage")
    output.append("")

    # –ì–ª–∞–≤—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º
    for prog_idx, program in enumerate(data["programs"], 1):
        program_name = escape_latex(get_text(program, "name", trans, "programs"))

        output.append(f"# {prog_idx}. {program_name}")
        output.append("")

        # –ö–ª–∞—Å—Ç–µ—Ä—ã
        for block in program["blocks"]:
            block_name = escape_latex(get_text(block, "name", trans, "blocks"))
            block_desc = escape_latex(get_text(block, "description", trans, "blocks"))
            block_type = block.get("type", "Foundation")

            depth_label = DEPTH_LABELS.get(lang, {}).get(block_type, "")
            time = DEPTH_TIME.get(block_type, "10")

            # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫: –£–†–û–í–ï–ù–¨ \n –ù–∞–∑–≤–∞–Ω–∏–µ ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –≤—Ä–µ–º—è
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å—Ç—ã–π LaTeX –¥–ª—è samepage (markdown –≤–Ω—É—Ç—Ä–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
            desc_time = f" ‚Äî {block_desc}" if block_desc else ""
            output.append("\\begin{samepage}")
            output.append(f"\\subsection{{{depth_label}}}")
            output.append(f"\\section{{{block_name}{desc_time} ‚Äî \\textasciitilde{{}}{time} –º–∏–Ω}}")
            output.append("\\end{samepage}")
            output.append("")

            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è Integration
            if block_type == "Integration":
                output.append(load_template(lang, "warnings"))
                output.append("")

            # –í–æ–ø—Ä–æ—Å—ã
            output.append(format_question_block(block["questions"], trans))
            output.append("")

        output.append("\\newpage")
        output.append("")

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    output.append(load_template(lang, "conclusion"))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    output_path = OUTPUT_DIR / lang / "book1_programs.md"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(output))

    print(f"    ‚úÖ {output_path}")
    return output_path


def interleave_by_program(blocks):
    """–ß–µ—Ä–µ–¥–æ–≤–∞—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è"""
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º
    by_program = {}
    for b in blocks:
        prog_id = b["program"]["id"]
        if prog_id not in by_program:
            by_program[prog_id] = []
        by_program[prog_id].append(b)

    # –ß–µ—Ä–µ–¥—É–µ–º
    result = []
    program_lists = list(by_program.values())
    if not program_lists:
        return result

    max_len = max(len(lst) for lst in program_lists)

    for i in range(max_len):
        for lst in program_lists:
            if i < len(lst):
                result.append(lst[i])

    return result


def generate_book2(lang):
    """
    –ö–Ω–∏–≥–∞ 2: –ü—É—Ç—å –≤ –≥–ª—É–±–∏–Ω—É
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞: 3 —á–∞—Å—Ç–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ, –∫–ª–∞—Å—Ç–µ—Ä—ã —á–µ—Ä–µ–¥—É—é—Ç—Å—è –ø–æ —Ç–µ–º–∞–º
    """
    print(f"  –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ö–Ω–∏–≥—É 2 ({lang})...")

    data = load_source()
    trans = load_translations(lang)

    # –°–æ–±—Ä–∞—Ç—å –≤—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
    all_blocks = []
    for program in data["programs"]:
        for block in program["blocks"]:
            all_blocks.append({
                "block": block,
                "program": program
            })

    # –†–∞–∑–±–∏—Ç—å –ø–æ —Ç–∏–ø–∞–º
    foundation = [b for b in all_blocks if b["block"].get("type") == "Foundation"]
    exploration = [b for b in all_blocks if b["block"].get("type") == "Exploration"]
    integration = [b for b in all_blocks if b["block"].get("type") == "Integration"]

    # –ß–µ—Ä–µ–¥–æ–≤–∞—Ç—å —Ç–µ–º—ã
    foundation = interleave_by_program(foundation)
    exploration = interleave_by_program(exploration)
    integration = interleave_by_program(integration)

    output = []

    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    output.append("---")
    output.append("title: –ü—É—Ç—å –≤ –≥–ª—É–±–∏–Ω—É")
    output.append("subtitle: –û—Ç –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∫ —Å—É—Ç–∏")
    output.append("author: Selfology")
    output.append(f"date: {datetime.now().strftime('%Y')}")
    output.append("lang: ru")
    output.append("---")
    output.append("")

    # –í–≤–æ–¥–Ω–∞—è —á–∞—Å—Ç—å
    output.append(load_template(lang, "intro"))
    output.append("")
    output.append("\\newpage")
    output.append("")

    # –¢—Ä–∏ —á–∞—Å—Ç–∏
    parts = [
        ("Foundation", foundation, "–ß–ê–°–¢–¨ 1"),
        ("Exploration", exploration, "–ß–ê–°–¢–¨ 2"),
        ("Integration", integration, "–ß–ê–°–¢–¨ 3")
    ]

    for block_type, blocks, part_name in parts:
        depth_label = DEPTH_LABELS.get(lang, {}).get(block_type, "")
        depth_name = DEPTH_NAMES.get(lang, {}).get(block_type, block_type)
        description = PART_DESCRIPTIONS.get(lang, {}).get(block_type, "")

        output.append(f"# {part_name}: {depth_label}")
        output.append("")
        output.append(f"*{description}*")
        output.append("")

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è Integration
        if block_type == "Integration":
            output.append(load_template(lang, "warnings"))
            output.append("")

        output.append("---")
        output.append("")

        # –ö–ª–∞—Å—Ç–µ—Ä—ã
        for item in blocks:
            block = item["block"]
            program = item["program"]

            program_name = escape_latex(get_text(program, "name", trans, "programs"))
            block_name = escape_latex(get_text(block, "name", trans, "blocks"))
            block_desc = escape_latex(get_text(block, "description", trans, "blocks"))

            time = DEPTH_TIME.get(block_type, "10")

            # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å samepage (—á–∏—Å—Ç—ã–π LaTeX)
            desc_time = f" ‚Äî {block_desc}" if block_desc else ""
            output.append("\\begin{samepage}")
            output.append(f"\\section{{[{program_name}] {block_name}{desc_time} ‚Äî \\textasciitilde{{}}{time} –º–∏–Ω}}")
            output.append("\\end{samepage}")
            output.append("")

            # –í–æ–ø—Ä–æ—Å—ã
            output.append(format_question_block(block["questions"], trans))
            output.append("")

        output.append("\\newpage")
        output.append("")

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    output.append(load_template(lang, "conclusion"))

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    output_path = OUTPUT_DIR / lang / "book2_depth.md"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(output))

    print(f"    ‚úÖ {output_path}")
    return output_path


def main():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–Ω–∏–≥"""
    print("=" * 50)
    print("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–Ω–∏–≥ Selfology")
    print("=" * 50)
    print()

    for lang in LANGUAGES:
        print(f"–Ø–∑—ã–∫: {lang.upper()}")

        # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        (OUTPUT_DIR / lang).mkdir(parents=True, exist_ok=True)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        book1_path = generate_book1(lang)
        book2_path = generate_book2(lang)

        print()

    print("=" * 50)
    print("–ì–æ—Ç–æ–≤–æ!")
    print()
    print("–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PDF:")
    print("  python generate_books.py --pdf")
    print("=" * 50)


if __name__ == "__main__":
    main()
