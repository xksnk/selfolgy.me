#!/usr/bin/env python3
"""
AI Question Validator â€” 3-ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ pipeline Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ².

Ğ­Ñ‚Ğ°Ğ¿ 1: Ğ˜Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° (GPT-4o-mini â€” Ğ´Ñ‘ÑˆĞµĞ²Ğ¾)
Ğ­Ñ‚Ğ°Ğ¿ 2: ĞšĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ² (GPT-4o â€” Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ)
Ğ­Ñ‚Ğ°Ğ¿ 3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… (Claude â€” ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
    python validate_questions.py                    # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ¾Ğ½
    python validate_questions.py --stage 1         # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ°Ğ¿ 1
    python validate_questions.py --dry-run         # Ğ‘ĞµĞ· API Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²
    python validate_questions.py --sample 10       # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ 10 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² (Ñ‚ĞµÑÑ‚)
"""

import json
import asyncio
import argparse
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Optional
import os
import sys

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ñ€ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ² path
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / ".env")

import openai
from openai import AsyncOpenAI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATA_FILE = PROJECT_ROOT / "intelligent_question_core/data/selfology_programs_v2.json"
OUTPUT_DIR = PROJECT_ROOT / "products/book/exports/validation"

# ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ğ¿Ğ¾Ğ²
MODELS = {
    "stage1": "gpt-4o-mini",      # Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ½Ğ¸Ğ½Ğ³ ~$0.50 Ğ·Ğ° 674 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
    "stage2": "gpt-4o",           # ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ~$2 Ğ·Ğ° 190 ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²
    "stage3": "gpt-4o",           # ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ ~$1 Ğ·Ğ° ~50 Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ…
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞ ĞĞœĞŸĞ¢Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STAGE1_SYSTEM = """Ğ¢Ñ‹ Ğ¿ÑĞ¸Ñ…Ğ¾Ñ‚ĞµÑ€Ğ°Ğ¿ĞµĞ²Ñ‚-Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‰Ğ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ ĞºĞ½Ğ¸Ğ³Ğ¸ ÑĞ°Ğ¼Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ.

Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ ĞĞ”Ğ˜Ğ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾ ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸ÑĞ¼ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°.

ĞšĞ Ğ˜Ğ¢Ğ•Ğ Ğ˜Ğ˜ ĞĞ¦Ğ•ĞĞšĞ˜:

1. **safety_score** (1-10): ĞĞ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞµĞ½ Ğ´Ğ»Ñ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ
   - 10: ĞŸĞ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞµĞ½, Ğ¼ÑĞ³ĞºĞ¸Ğ¹
   - 7-9: Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞµĞ½, Ğ½Ğ¾ Ğ·Ğ°Ñ‚Ñ€Ğ°Ğ³Ğ¸Ğ²Ğ°ĞµÑ‚ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹
   - 4-6: ĞœĞ¾Ğ¶ĞµÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¸ÑĞºĞ¾Ğ¼Ñ„Ğ¾Ñ€Ñ‚ Ñƒ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ñ‹Ñ… Ğ»ÑĞ´ĞµĞ¹
   - 1-3: ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ‚Ñ€Ğ°Ğ²Ğ¼Ğ¸Ñ€ÑƒÑÑ‰Ğ¸Ğ¹

2. **tone**: Ğ¢Ğ¾Ğ½ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
   - "soft" â€” Ğ¼ÑĞ³ĞºĞ¸Ğ¹, Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‰Ğ¸Ğ¹
   - "neutral" â€” Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹, Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹
   - "direct" â€” Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹, Ğ½Ğ¾ ÑƒĞ²Ğ°Ğ¶Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹
   - "harsh" â€” Ğ¶Ñ‘ÑÑ‚ĞºĞ¸Ğ¹, Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒÑÑ ĞºĞ°Ğº ĞºÑ€Ğ¸Ñ‚Ğ¸ĞºĞ°

3. **has_labels**: Ğ•ÑÑ‚ÑŒ Ğ»Ğ¸ Ğ½Ğ°Ğ²ĞµÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ÑÑ€Ğ»Ñ‹ĞºĞ¾Ğ² Ğ½Ğ° Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ
   - true â€” Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ Ñ‡ĞµĞ¼-Ñ‚Ğ¾ ("Ñ‚Ñ‹ Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ğ¸Ğº", "Ñ‚Ñ‹ ÑĞ»Ğ°Ğ±Ñ‹Ğ¹")
   - false â€” Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸ÑÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¾Ğ¿Ñ‹Ñ‚ Ğ±ĞµĞ· ÑÑ€Ğ»Ñ‹ĞºĞ¾Ğ²

4. **depth_level**: Ğ“Ğ»ÑƒĞ±Ğ¸Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
   - "surface" â€” Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹, Ğ¾ Ñ„Ğ°ĞºÑ‚Ğ°Ñ…
   - "conscious" â€” Ğ¾ Ğ¼Ñ‹ÑĞ»ÑÑ… Ğ¸ Ğ¼Ğ½ĞµĞ½Ğ¸ÑÑ…
   - "edge" â€” Ğ¾ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ°Ñ… Ğ¸ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
   - "shadow" â€” Ğ¾ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¼, Ğ±Ğ¾Ğ»ĞµĞ·Ğ½ĞµĞ½Ğ½Ğ¾Ğ¼

5. **issues**: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ (Ğ¼Ğ°ÑÑĞ¸Ğ² ÑÑ‚Ñ€Ğ¾Ğº). Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
   - "toxic_label" â€” Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ¾Ğ¼
   - "too_harsh" â€” ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¶Ñ‘ÑÑ‚ĞºĞ°Ñ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°
   - "double_bind" â€” Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ¾Ñ€ĞµÑ‡Ğ¸Ğ²Ğ¾Ğµ Ğ¿Ğ¾ÑĞ»Ğ°Ğ½Ğ¸Ğµ
   - "presumes_negative" â€” Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ² Ñƒ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ
   - "grammatical" â€” Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°
   - "unclear" â€” Ğ½ĞµÑÑĞ½Ğ°Ñ Ñ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ°
   - [] â€” Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ½ĞµÑ‚

6. **needs_review**: ĞÑƒĞ¶Ğ½Ğ° Ğ»Ğ¸ Ñ€ÑƒÑ‡Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° (true/false)

Ğ’ĞĞ–ĞĞ:
- Ğ¡Ğ»Ğ¾Ğ²Ğ¾ "Ğ½ĞµĞ°Ğ´ĞµĞºĞ²Ğ°Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ" Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ "ÑÑ‚Ñ€Ğ°Ñ… Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ½ĞµĞ°Ğ´ĞµĞºĞ²Ğ°Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸" â€” ÑÑ‚Ğ¾ Ğ¿ÑĞ¸Ñ…Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½, ĞĞ• Ğ¾ÑĞºĞ¾Ñ€Ğ±Ğ»ĞµĞ½Ğ¸Ğµ
- Ğ¡Ğ»Ğ¾Ğ²Ğ¾ "ÑĞ»Ğ°Ğ±Ğ¾ÑÑ‚ÑŒ" Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ "Ñ ĞºĞµĞ¼ Ñ‚Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ Ğ±Ñ‹Ñ‚ÑŒ ÑĞ»Ğ°Ğ±Ñ‹Ğ¼" â€” ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ, ĞĞ• ÑÑ€Ğ»Ñ‹Ğº
- ĞÑ†ĞµĞ½Ğ¸Ğ²Ğ°Ğ¹ ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢, Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ»Ğ¾Ğ²Ğ°

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON Ğ±ĞµĞ· ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²."""

STAGE1_USER = """ĞÑ†ĞµĞ½Ğ¸ ÑÑ‚Ğ¾Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· ĞºĞ½Ğ¸Ğ³Ğ¸ ÑĞ°Ğ¼Ğ¾Ğ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ:

ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°: {program}
ĞšĞ»Ğ°ÑÑ‚ĞµÑ€: {cluster} ({cluster_type})
ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ² ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğµ: {position}/{total}

Ğ’ĞĞŸĞ ĞĞ¡: "{question}"

Ğ’ĞµÑ€Ğ½Ğ¸ JSON:
{{
  "safety_score": <1-10>,
  "tone": "<soft|neutral|direct|harsh>",
  "has_labels": <true|false>,
  "depth_level": "<surface|conscious|edge|shadow>",
  "issues": ["issue1", "issue2"] Ğ¸Ğ»Ğ¸ [],
  "needs_review": <true|false>,
  "comment": "<ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹>"
}}"""

STAGE2_SYSTEM = """Ğ¢Ñ‹ Ğ¿ÑĞ¸Ñ…Ğ¾Ñ‚ĞµÑ€Ğ°Ğ¿ĞµĞ²Ñ‚, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‰Ğ¸Ğ¹ ĞŸĞĞ¡Ğ›Ğ•Ğ”ĞĞ’ĞĞ¢Ğ•Ğ›Ğ¬ĞĞĞ¡Ğ¢Ğ¬ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğµ.

ĞšĞ»Ğ°ÑÑ‚ĞµÑ€ â€” ÑÑ‚Ğ¾ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ğ¸Ğ· 3-7 Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ´Ñ€ÑĞ´.
Ğ’Ğ°Ğ¶Ğ½Ğ° ĞŸĞ›ĞĞ’ĞĞĞ¡Ğ¢Ğ¬ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ° Ğ¸ Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ñ€ĞµĞ·ĞºĞ¸Ñ… ÑĞºĞ°Ñ‡ĞºĞ¾Ğ².

ĞšĞ Ğ˜Ğ¢Ğ•Ğ Ğ˜Ğ˜:

1. **flow_score** (1-10): ĞŸĞ»Ğ°Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¾Ğ² Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸
   - 10: Ğ˜Ğ´ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº, ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾
   - 7-9: Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ ÑĞºĞ°Ñ‡ĞºĞ°Ğ¼Ğ¸
   - 4-6: Ğ—Ğ°Ğ¼ĞµÑ‚Ğ½Ñ‹Ğµ ÑĞºĞ°Ñ‡ĞºĞ¸, Ğ½Ğ¾ Ñ‚ĞµÑ€Ğ¿Ğ¸Ğ¼Ğ¾
   - 1-3: Ğ ĞµĞ·ĞºĞ¸Ğµ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹, Ğ´ĞµĞ·Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ

2. **depth_progression**: ĞšĞ°Ğº Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°
   - "gradual_increase" â€” Ğ¿Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ (Ğ¸Ğ´ĞµĞ°Ğ»)
   - "stable" â€” Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°
   - "gradual_decrease" â€” Ğ¾Ñ‚ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¾Ğ³Ğ¾ Ğº Ğ¿Ğ¾Ğ²ĞµÑ€Ñ…Ğ½Ğ¾ÑÑ‚Ğ½Ğ¾Ğ¼Ñƒ
   - "chaotic" â€” Ñ…Ğ°Ğ¾Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞºĞ°Ñ‡ĞºĞ¸ (Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°!)

3. **tone_consistency**: ĞšĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ½Ğ°
   - "consistent" â€” Ñ‚Ğ¾Ğ½ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¹
   - "gradual_shift" â€” Ğ¿Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ÑĞ¼ĞµĞ½Ğ° Ñ‚Ğ¾Ğ½Ğ°
   - "inconsistent" â€” Ñ€ĞµĞ·ĞºĞ¸Ğµ ÑĞ¼ĞµĞ½Ñ‹ (Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°!)

4. **issues**: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°
   - "depth_jump" â€” Ñ€ĞµĞ·ĞºĞ¸Ğ¹ ÑĞºĞ°Ñ‡Ğ¾Ğº Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹
   - "tone_shift" â€” Ñ€ĞµĞ·ĞºĞ°Ñ ÑĞ¼ĞµĞ½Ğ° Ñ‚Ğ¾Ğ½Ğ°
   - "missing_warmup" â€” Ğ½ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¾Ğ³Ñ€ĞµĞ²Ğ° Ğ¿ĞµÑ€ĞµĞ´ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¼ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ¼
   - "no_closure" â€” Ğ½ĞµÑ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ/Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ° Ğ¸Ğ· Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñ‹
   - "duplicate_angle" â€” Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑÑ‰Ğ¸Ğ¹ÑÑ Ñ€Ğ°ĞºÑƒÑ€Ñ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²

5. **problem_transitions**: ĞœĞ°ÑÑĞ¸Ğ² Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¾Ğ²
   - ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚: {"from": 1, "to": 2, "issue": "Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ"}

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON."""

STAGE2_USER = """ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ² ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğµ:

ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°: {program}
ĞšĞ»Ğ°ÑÑ‚ĞµÑ€: {cluster}
Ğ¢Ğ¸Ğ¿ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°: {cluster_type} (Foundation=Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹, Exploration=Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Integration=Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹)

Ğ’ĞĞŸĞ ĞĞ¡Ğ«:
{questions}

Ğ’ĞµÑ€Ğ½Ğ¸ JSON:
{{
  "flow_score": <1-10>,
  "depth_progression": "<gradual_increase|stable|gradual_decrease|chaotic>",
  "tone_consistency": "<consistent|gradual_shift|inconsistent>",
  "issues": ["issue1"] Ğ¸Ğ»Ğ¸ [],
  "problem_transitions": [
    {{"from": 1, "to": 2, "issue": "Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹"}}
  ] Ğ¸Ğ»Ğ¸ [],
  "recommendation": "<ĞºÑ€Ğ°Ñ‚ĞºĞ°Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹>"
}}"""

STAGE3_SYSTEM = """Ğ¢Ñ‹ Ğ¾Ğ¿Ñ‹Ñ‚Ğ½Ñ‹Ğ¹ Ğ¿ÑĞ¸Ñ…Ğ¾Ñ‚ĞµÑ€Ğ°Ğ¿ĞµĞ²Ñ‚ Ğ¸ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ‘Ğ•Ğ—ĞĞŸĞĞ¡ĞĞ«Ğ• Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ².

ĞŸĞ Ğ˜ĞĞ¦Ğ˜ĞŸĞ« ĞŸĞ•Ğ Ğ•Ğ¤ĞĞ ĞœĞ£Ğ›Ğ˜Ğ ĞĞ’ĞšĞ˜:

1. **Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ğ¸ ÑĞ¼Ñ‹ÑĞ»** â€” Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ñƒ Ğ¶Ğµ Ñ‚ĞµĞ¼Ñƒ
2. **Ğ£Ğ±ĞµÑ€Ğ¸ Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ** â€” Ğ½Ğ¸ĞºĞ°ĞºĞ¸Ñ… ÑÑ€Ğ»Ñ‹ĞºĞ¾Ğ² Ğ¸ Ğ¾Ñ†ĞµĞ½Ğ¾Ğº Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»Ñ
3. **Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ²Ñ‹Ğ±Ğ¾Ñ€** â€” Ğ²Ğ¼ĞµÑÑ‚Ğ¾ "Ñ‚Ñ‹ X" Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ "Ğ±Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ»Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚Ñ‹ Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒĞµÑˆÑŒ X"
4. **Ğ¡Ğ¼ÑĞ³Ñ‡Ğ¸ Ñ‚Ğ¾Ğ½** â€” Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ "Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾", "Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ°", "Ğ±Ñ‹Ğ²Ğ°ĞµÑ‚"
5. **Ğ£Ğ²Ğ°Ğ¶Ğ°Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ** â€” Ñ‡Ğ¸Ñ‚Ğ°Ñ‚ĞµĞ»ÑŒ ÑĞ°Ğ¼ Ñ€ĞµÑˆĞ°ĞµÑ‚, Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ»Ğ¸ ĞµĞ¼Ñƒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ

ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ« Ğ¢Ğ ĞĞĞ¡Ğ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ™:
- "Ğ§ÑŒĞ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ·Ğ°ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ Ñ‚ĞµĞ±Ñ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞµĞ±Ñ Ğ½ĞµÑƒĞ´Ğ°Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ¼?"
  â†’ "Ğ§ÑŒĞ¸ ÑƒÑĞ¿ĞµÑ…Ğ¸ Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ÑÑ‚ Ñƒ Ñ‚ĞµĞ±Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ°? Ğ§Ñ‚Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ñ‚Ñ‹ Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒĞµÑˆÑŒ?"

- "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ñ‚Ñ‹ Ñ‚Ğ°ĞºĞ¾Ğ¹ Ğ½ĞµÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ğ¹?"
  â†’ "Ğ’ ĞºĞ°ĞºĞ¸Ñ… ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸ÑÑ… Ñ‚Ñ‹ Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°ĞµÑˆÑŒ Ğ½ĞµÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ² ÑĞµĞ±Ğµ?"

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON."""

STAGE3_USER = """ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°:

ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°: {program}
ĞšĞ»Ğ°ÑÑ‚ĞµÑ€: {cluster}
ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: "{question}"
Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹: {issues}

Ğ’ĞµÑ€Ğ½Ğ¸ JSON:
{{
  "original": "<Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»>",
  "issues_summary": "<ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼>",
  "alternatives": [
    {{
      "text": "<Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1>",
      "approach": "<ĞºĞ°ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½>"
    }},
    {{
      "text": "<Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2>",
      "approach": "<ĞºĞ°ĞºĞ¾Ğ¹ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½Ñ‘Ğ½>"
    }}
  ],
  "recommended": 1 Ğ¸Ğ»Ğ¸ 2,
  "recommendation_reason": "<Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ¾Ñ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ğ»ÑƒÑ‡ÑˆĞµ>"
}}"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ« Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class QuestionAnalysis:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° (Ğ­Ñ‚Ğ°Ğ¿ 1)"""
    question_id: str
    program: str
    cluster: str
    cluster_type: str
    position: int
    text: str
    safety_score: int
    tone: str
    has_labels: bool
    depth_level: str
    issues: list
    needs_review: bool
    comment: str = ""


@dataclass
class ClusterAnalysis:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ° (Ğ­Ñ‚Ğ°Ğ¿ 2)"""
    cluster_id: str
    program: str
    cluster_name: str
    cluster_type: str
    question_count: int
    flow_score: int
    depth_progression: str
    tone_consistency: str
    issues: list
    problem_transitions: list
    recommendation: str = ""


@dataclass
class Reformulation:
    """ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° (Ğ­Ñ‚Ğ°Ğ¿ 3)"""
    question_id: str
    original: str
    issues_summary: str
    alternatives: list
    recommended: int
    recommendation_reason: str


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ™ ĞšĞ›ĞĞ¡Ğ¡ Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¢ĞĞ Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QuestionValidator:
    def __init__(self, dry_run: bool = False):
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.dry_run = dry_run
        self.data = None
        self.results = {
            "stage1": [],
            "stage2": [],
            "stage3": [],
            "summary": {}
        }

    def load_data(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ±Ğ°Ğ·Ñ‹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²"""
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            self.data = json.load(f)
        print(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾: {self.data['metadata']['total_programs']} Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼, "
              f"{self.data['metadata']['total_blocks']} ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ², "
              f"{self.data['metadata']['total_questions']} Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²")

    async def call_llm(self, system: str, user: str, model: str) -> dict:
        """Ğ’Ñ‹Ğ·Ğ¾Ğ² LLM Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ¾Ğ¼ JSON"""
        if self.dry_run:
            return {"dry_run": True}

        try:
            response = await self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"âŒ LLM Error: {e}")
            return {"error": str(e)}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ­Ğ¢ĞĞŸ 1: Ğ˜Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def stage1_analyze_question(self, question: dict, program: str,
                                       cluster: str, cluster_type: str,
                                       position: int, total: int) -> QuestionAnalysis:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°"""
        user_prompt = STAGE1_USER.format(
            program=program,
            cluster=cluster,
            cluster_type=cluster_type,
            position=position,
            total=total,
            question=question["text"]
        )

        result = await self.call_llm(STAGE1_SYSTEM, user_prompt, MODELS["stage1"])

        if "error" in result or "dry_run" in result:
            return QuestionAnalysis(
                question_id=question["id"],
                program=program,
                cluster=cluster,
                cluster_type=cluster_type,
                position=position,
                text=question["text"],
                safety_score=0,
                tone="unknown",
                has_labels=False,
                depth_level="unknown",
                issues=["analysis_failed"] if "error" in result else [],
                needs_review=True,
                comment=result.get("error", "dry_run")
            )

        return QuestionAnalysis(
            question_id=question["id"],
            program=program,
            cluster=cluster,
            cluster_type=cluster_type,
            position=position,
            text=question["text"],
            safety_score=result.get("safety_score", 5),
            tone=result.get("tone", "neutral"),
            has_labels=result.get("has_labels", False),
            depth_level=result.get("depth_level", "conscious"),
            issues=result.get("issues", []),
            needs_review=result.get("needs_review", False),
            comment=result.get("comment", "")
        )

    async def run_stage1(self, sample_size: Optional[int] = None):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ­Ñ‚Ğ°Ğ¿Ğ° 1 â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²ÑĞµÑ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²"""
        print("\n" + "â•" * 60)
        print("ğŸ“‹ Ğ­Ğ¢ĞĞŸ 1: Ğ˜Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²")
        print("â•" * 60)

        tasks = []
        count = 0

        for program in self.data["programs"]:
            for block in program["blocks"]:
                total_q = len(block["questions"])
                for i, question in enumerate(block["questions"], 1):
                    if sample_size and count >= sample_size:
                        break

                    tasks.append(self.stage1_analyze_question(
                        question=question,
                        program=program["name"],
                        cluster=block["name"],
                        cluster_type=block["type"],
                        position=i,
                        total=total_q
                    ))
                    count += 1

                if sample_size and count >= sample_size:
                    break
            if sample_size and count >= sample_size:
                break

        print(f"ğŸ”„ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ {len(tasks)} Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²...")

        # Ğ‘Ğ°Ñ‚Ñ‡ĞµĞ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾ 20 Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
        batch_size = 20
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i+batch_size]
            results = await asyncio.gather(*batch)
            self.results["stage1"].extend(results)
            print(f"   ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: {min(i+batch_size, len(tasks))}/{len(tasks)}")

        # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
        needs_review = [r for r in self.results["stage1"] if r.needs_review]
        with_issues = [r for r in self.results["stage1"] if r.issues]
        low_safety = [r for r in self.results["stage1"] if r.safety_score < 6]

        print(f"\nğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ­Ñ‚Ğ°Ğ¿Ğ° 1:")
        print(f"   â€¢ Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: {len(self.results['stage1'])}")
        print(f"   â€¢ Ğ¢Ñ€ĞµĞ±ÑƒÑÑ‚ Ñ€ĞµĞ²ÑŒÑ: {len(needs_review)}")
        print(f"   â€¢ Ğ¡ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸: {len(with_issues)}")
        print(f"   â€¢ ĞĞ¸Ğ·ĞºĞ¸Ğ¹ safety (<6): {len(low_safety)}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ­Ğ¢ĞĞŸ 2: ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def stage2_analyze_cluster(self, program: str, block: dict) -> ClusterAnalysis:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ°"""
        questions_text = "\n".join([
            f"{i}. {q['text']}"
            for i, q in enumerate(block["questions"], 1)
        ])

        user_prompt = STAGE2_USER.format(
            program=program,
            cluster=block["name"],
            cluster_type=block["type"],
            questions=questions_text
        )

        result = await self.call_llm(STAGE2_SYSTEM, user_prompt, MODELS["stage2"])

        if "error" in result or "dry_run" in result:
            return ClusterAnalysis(
                cluster_id=block["id"],
                program=program,
                cluster_name=block["name"],
                cluster_type=block["type"],
                question_count=len(block["questions"]),
                flow_score=0,
                depth_progression="unknown",
                tone_consistency="unknown",
                issues=["analysis_failed"] if "error" in result else [],
                problem_transitions=[],
                recommendation=result.get("error", "dry_run")
            )

        return ClusterAnalysis(
            cluster_id=block["id"],
            program=program,
            cluster_name=block["name"],
            cluster_type=block["type"],
            question_count=len(block["questions"]),
            flow_score=result.get("flow_score", 5),
            depth_progression=result.get("depth_progression", "stable"),
            tone_consistency=result.get("tone_consistency", "consistent"),
            issues=result.get("issues", []),
            problem_transitions=result.get("problem_transitions", []),
            recommendation=result.get("recommendation", "")
        )

    async def run_stage2(self, sample_size: Optional[int] = None):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ­Ñ‚Ğ°Ğ¿Ğ° 2 â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²"""
        print("\n" + "â•" * 60)
        print("ğŸ“‹ Ğ­Ğ¢ĞĞŸ 2: ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²")
        print("â•" * 60)

        tasks = []
        count = 0

        for program in self.data["programs"]:
            for block in program["blocks"]:
                if sample_size and count >= sample_size:
                    break
                tasks.append(self.stage2_analyze_cluster(program["name"], block))
                count += 1
            if sample_size and count >= sample_size:
                break

        print(f"ğŸ”„ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ {len(tasks)} ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²...")

        # Ğ‘Ğ°Ñ‚Ñ‡ĞµĞ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        batch_size = 10
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i+batch_size]
            results = await asyncio.gather(*batch)
            self.results["stage2"].extend(results)
            print(f"   ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: {min(i+batch_size, len(tasks))}/{len(tasks)}")

        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        low_flow = [r for r in self.results["stage2"] if r.flow_score < 6]
        chaotic = [r for r in self.results["stage2"] if r.depth_progression == "chaotic"]
        inconsistent = [r for r in self.results["stage2"] if r.tone_consistency == "inconsistent"]

        print(f"\nğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ­Ñ‚Ğ°Ğ¿Ğ° 2:")
        print(f"   â€¢ Ğ’ÑĞµĞ³Ğ¾ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ²: {len(self.results['stage2'])}")
        print(f"   â€¢ ĞĞ¸Ğ·ĞºĞ¸Ğ¹ flow (<6): {len(low_flow)}")
        print(f"   â€¢ Ğ¥Ğ°Ğ¾Ñ‚Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°: {len(chaotic)}")
        print(f"   â€¢ ĞĞµĞ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ½: {len(inconsistent)}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ­Ğ¢ĞĞŸ 3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def stage3_reformulate(self, analysis: QuestionAnalysis) -> Reformulation:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°"""
        user_prompt = STAGE3_USER.format(
            program=analysis.program,
            cluster=analysis.cluster,
            question=analysis.text,
            issues=", ".join(analysis.issues) if analysis.issues else "needs_review"
        )

        result = await self.call_llm(STAGE3_SYSTEM, user_prompt, MODELS["stage3"])

        if "error" in result or "dry_run" in result:
            return Reformulation(
                question_id=analysis.question_id,
                original=analysis.text,
                issues_summary="analysis_failed",
                alternatives=[],
                recommended=0,
                recommendation_reason=result.get("error", "dry_run")
            )

        return Reformulation(
            question_id=analysis.question_id,
            original=result.get("original", analysis.text),
            issues_summary=result.get("issues_summary", ""),
            alternatives=result.get("alternatives", []),
            recommended=result.get("recommended", 1),
            recommendation_reason=result.get("recommendation_reason", "")
        )

    async def run_stage3(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ­Ñ‚Ğ°Ğ¿Ğ° 3 â€” Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ…"""
        print("\n" + "â•" * 60)
        print("ğŸ“‹ Ğ­Ğ¢ĞĞŸ 3: Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº")
        print("â•" * 60)

        # ĞÑ‚Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        problem_questions = [
            q for q in self.results["stage1"]
            if q.needs_review or q.issues or q.safety_score < 6
        ]

        if not problem_questions:
            print("âœ… ĞĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸!")
            return

        print(f"ğŸ”„ Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ´Ğ»Ñ {len(problem_questions)} Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²...")

        tasks = [self.stage3_reformulate(q) for q in problem_questions]

        # Ğ‘Ğ°Ñ‚Ñ‡ĞµĞ²Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        batch_size = 10
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i+batch_size]
            results = await asyncio.gather(*batch)
            self.results["stage3"].extend(results)
            print(f"   ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ: {min(i+batch_size, len(tasks))}/{len(tasks)}")

        print(f"\nğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ­Ñ‚Ğ°Ğ¿Ğ° 3:")
        print(f"   â€¢ ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾: {len(self.results['stage3'])}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def generate_summary(self):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ²Ğ¾Ğ´ĞºĞ¸"""
        self.results["summary"] = {
            "generated_at": datetime.now().isoformat(),
            "total_questions": len(self.results["stage1"]),
            "total_clusters": len(self.results["stage2"]),
            "questions_needing_review": len([q for q in self.results["stage1"] if q.needs_review]),
            "questions_with_issues": len([q for q in self.results["stage1"] if q.issues]),
            "questions_low_safety": len([q for q in self.results["stage1"] if q.safety_score < 6]),
            "clusters_low_flow": len([c for c in self.results["stage2"] if c.flow_score < 6]),
            "clusters_chaotic": len([c for c in self.results["stage2"] if c.depth_progression == "chaotic"]),
            "reformulations_generated": len(self.results["stage3"]),
            "issue_breakdown": {}
        }

        # ĞŸĞ¾Ğ´ÑÑ‡Ñ‘Ñ‚ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
        issue_counts = {}
        for q in self.results["stage1"]:
            for issue in q.issues:
                issue_counts[issue] = issue_counts.get(issue, 0) + 1
        self.results["summary"]["issue_breakdown"] = issue_counts

    def export_json(self):
        """Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² JSON"""
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        output = {
            "summary": self.results["summary"],
            "stage1_questions": [asdict(q) for q in self.results["stage1"]],
            "stage2_clusters": [asdict(c) for c in self.results["stage2"]],
            "stage3_reformulations": [asdict(r) for r in self.results["stage3"]]
        }

        output_file = OUTPUT_DIR / f"validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ JSON ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {output_file}")
        return output_file

    def export_markdown_report(self):
        """Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ° Ğ² Markdown Ğ´Ğ»Ñ Ğ²Ñ‹Ñ‡Ğ¸Ñ‚ĞºĞ¸"""
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        md_lines = [
            "# ğŸ“‹ ĞÑ‚Ñ‡Ñ‘Ñ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Selfology",
            f"\n**Ğ”Ğ°Ñ‚Ğ°:** {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "",
            "---",
            "",
            "## ğŸ“Š Ğ¡Ğ²Ğ¾Ğ´ĞºĞ°",
            "",
            f"| ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ° | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |",
            f"|---------|----------|",
            f"| Ğ’ÑĞµĞ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² | {self.results['summary'].get('total_questions', 0)} |",
            f"| Ğ¢Ñ€ĞµĞ±ÑƒÑÑ‚ Ñ€ĞµĞ²ÑŒÑ | {self.results['summary'].get('questions_needing_review', 0)} |",
            f"| Ğ¡ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸ | {self.results['summary'].get('questions_with_issues', 0)} |",
            f"| ĞĞ¸Ğ·ĞºĞ¸Ğ¹ safety | {self.results['summary'].get('questions_low_safety', 0)} |",
            f"| ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ğ¾Ğ² Ñ Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¼ flow | {self.results['summary'].get('clusters_low_flow', 0)} |",
            f"| ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº | {self.results['summary'].get('reformulations_generated', 0)} |",
            "",
        ]

        # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
        if self.results["summary"].get("issue_breakdown"):
            md_lines.extend([
                "### Ğ¢Ğ¸Ğ¿Ñ‹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼",
                "",
            ])
            for issue, count in sorted(self.results["summary"]["issue_breakdown"].items(),
                                       key=lambda x: -x[1]):
                md_lines.append(f"- **{issue}**: {count}")
            md_lines.append("")

        # ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹
        problem_questions = [q for q in self.results["stage1"] if q.needs_review or q.issues]
        if problem_questions:
            md_lines.extend([
                "---",
                "",
                "## ğŸš¨ Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ´Ğ»Ñ Ñ€ĞµĞ²ÑŒÑ",
                "",
            ])

            for q in sorted(problem_questions, key=lambda x: x.safety_score):
                md_lines.extend([
                    f"### {q.program} â†’ {q.cluster}",
                    "",
                    f"**Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ:** {q.text}",
                    "",
                    f"- Safety: {q.safety_score}/10",
                    f"- Ğ¢Ğ¾Ğ½: {q.tone}",
                    f"- Ğ“Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°: {q.depth_level}",
                    f"- ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹: {', '.join(q.issues) if q.issues else 'needs_review'}",
                    "",
                ])
                if q.comment:
                    md_lines.append(f"> {q.comment}")
                    md_lines.append("")

        # ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
        if self.results["stage3"]:
            md_lines.extend([
                "---",
                "",
                "## âœï¸ ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸",
                "",
            ])

            for r in self.results["stage3"]:
                md_lines.extend([
                    f"### ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»",
                    f"> {r.original}",
                    "",
                    f"**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** {r.issues_summary}",
                    "",
                    "**Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ñ‹:**",
                    "",
                ])
                for i, alt in enumerate(r.alternatives, 1):
                    rec = " âœ… **Ğ Ğ•ĞšĞĞœĞ•ĞĞ”Ğ£Ğ•Ğ¢Ğ¡Ğ¯**" if i == r.recommended else ""
                    md_lines.append(f"{i}. {alt.get('text', '')}{rec}")
                    md_lines.append(f"   _{alt.get('approach', '')}_")
                    md_lines.append("")

                if r.recommendation_reason:
                    md_lines.append(f"> ğŸ’¡ {r.recommendation_reason}")
                md_lines.append("")
                md_lines.append("---")
                md_lines.append("")

        # ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€Ñ‹
        problem_clusters = [c for c in self.results["stage2"]
                          if c.flow_score < 6 or c.depth_progression == "chaotic"]
        if problem_clusters:
            md_lines.extend([
                "",
                "## ğŸ”— ĞšĞ»Ğ°ÑÑ‚ĞµÑ€Ñ‹ Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°",
                "",
            ])

            for c in sorted(problem_clusters, key=lambda x: x.flow_score):
                md_lines.extend([
                    f"### {c.program} â†’ {c.cluster_name}",
                    "",
                    f"- Flow: {c.flow_score}/10",
                    f"- Ğ“Ğ»ÑƒĞ±Ğ¸Ğ½Ğ°: {c.depth_progression}",
                    f"- Ğ¢Ğ¾Ğ½: {c.tone_consistency}",
                    "",
                ])
                if c.problem_transitions:
                    md_lines.append("**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ğµ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹:**")
                    for pt in c.problem_transitions:
                        md_lines.append(f"- Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ {pt.get('from')} â†’ {pt.get('to')}: {pt.get('issue')}")
                    md_lines.append("")
                if c.recommendation:
                    md_lines.append(f"> ğŸ’¡ {c.recommendation}")
                    md_lines.append("")

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ
        output_file = OUTPUT_DIR / f"validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(md_lines))

        print(f"ğŸ“„ Markdown Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚: {output_file}")
        return output_file

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ ĞœĞ•Ğ¢ĞĞ”
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def run(self, stages: list = [1, 2, 3], sample_size: Optional[int] = None):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸"""
        self.load_data()

        if 1 in stages:
            await self.run_stage1(sample_size)

        if 2 in stages:
            await self.run_stage2(sample_size if sample_size else None)

        if 3 in stages and self.results["stage1"]:
            await self.run_stage3()

        self.generate_summary()

        json_file = self.export_json()
        md_file = self.export_markdown_report()

        print("\n" + "â•" * 60)
        print("âœ… Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ¯ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ")
        print("â•" * 60)
        print(f"\nğŸ“ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ²: {OUTPUT_DIR}")

        return json_file, md_file


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    parser = argparse.ArgumentParser(description="AI Question Validator")
    parser.add_argument("--stage", type=int, choices=[1, 2, 3],
                        help="Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ğ¹ ÑÑ‚Ğ°Ğ¿")
    parser.add_argument("--dry-run", action="store_true",
                        help="Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ¾Ğ½ Ğ±ĞµĞ· API Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²")
    parser.add_argument("--sample", type=int,
                        help="ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² (Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ°)")

    args = parser.parse_args()

    validator = QuestionValidator(dry_run=args.dry_run)

    stages = [args.stage] if args.stage else [1, 2, 3]

    await validator.run(stages=stages, sample_size=args.sample)


if __name__ == "__main__":
    asyncio.run(main())
