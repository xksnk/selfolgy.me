"""
Coach Vector DAO - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã Qdrant –¥–ª—è ChatCoach

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è:
- –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π
- Semantic search –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ —ç–≤–æ–ª—é—Ü–∏–∏ –ª–∏—á–Ω–æ—Å—Ç–∏
- Similarity matching –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤
"""
from typing import Dict, List, Any, Optional
from qdrant_client import QdrantClient
from qdrant_client.http import models
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class CoachVectorDAO:
    """
    DAO –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ AI Coach

    –ö–æ–ª–ª–µ–∫—Ü–∏–∏:
    - personality_profiles: —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å (1536D)
    - personality_evolution: –∏—Å—Ç–æ—Ä–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π (1536D, ~132 –≤–µ–∫—Ç–æ—Ä–∞)
    - quick_match: –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ (512D)
    """

    def __init__(self, qdrant_url: str = "http://localhost:6333"):
        self.client = QdrantClient(url=qdrant_url)
        logger.info(f"‚úÖ CoachVectorDAO connected to Qdrant at {qdrant_url}")

    async def get_current_personality_vector(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¢–ï–ö–£–©–ò–ô –≤–µ–∫—Ç–æ—Ä –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        –ö–æ–ª–ª–µ–∫—Ü–∏—è: personality_profiles
        –°–∫–æ—Ä–æ—Å—Ç—å: < 10ms
        """
        try:
            result = self.client.retrieve(
                collection_name="personality_profiles",
                ids=[user_id],
                with_payload=True,
                with_vectors=True  # Fixed: with_vectors (plural) in new Qdrant API
            )

            if result and len(result) > 0:
                point = result[0]
                logger.info(f"‚úÖ Loaded personality vector for user {user_id}")

                return {
                    "user_id": user_id,
                    "vector": point.vector,
                    "traits": point.payload.get("traits"),
                    "summary": point.payload.get("summary"),
                    "updated_at": point.payload.get("updated_at")
                }

            logger.warning(f"‚ö†Ô∏è No personality vector found for user {user_id}")
            return None

        except Exception as e:
            logger.error(f"‚ùå Error loading personality vector for user {user_id}: {e}")
            return None

    async def search_similar_emotional_states(
        self,
        user_id: int,
        current_message_vector: List[float],
        limit: int = 10,
        score_threshold: float = 0.65
    ) -> List[Dict[str, Any]]:
        """
        –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏

        –ö–æ–ª–ª–µ–∫—Ü–∏—è: personality_evolution (132 –≤–µ–∫—Ç–æ—Ä–∞)
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –ø–æ–Ω—è—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã ‚Üí —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_message_vector: –≤–µ–∫—Ç–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (1536D)
            limit: –∫–æ–ª-–≤–æ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π (default: 10, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ AI Engineer review)
            score_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å 0-1 (default: 0.65 –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)

        Returns:
            List –ø–æ—Ö–æ–∂–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        try:
            # –ü–æ–∏—Å–∫ –¢–û–õ–¨–ö–û —Å—Ä–µ–¥–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≠–¢–û–ì–û –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            search_result = self.client.search(
                collection_name="personality_evolution",
                query_vector=current_message_vector,
                query_filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="user_id",
                            match=models.MatchValue(value=user_id)
                        )
                    ]
                ),
                limit=limit,
                with_payload=True,
                score_threshold=score_threshold  # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: 0.65 –≤–º–µ—Å—Ç–æ 0.5 (AI Engineer review)
            )

            similar_moments = []
            for hit in search_result:
                payload = hit.payload

                similar_moments.append({
                    "similarity_score": hit.score,
                    "snapshot_id": payload.get("snapshot_id"),
                    "created_at": payload.get("created_at"),
                    "narrative": payload.get("personality_snapshot", {}).get("narrative", ""),
                    "big_five": payload.get("personality_snapshot", {}).get("big_five", {}),
                    "trigger_question": payload.get("breakthrough_info", {}).get("trigger_question"),
                    "is_milestone": payload.get("is_milestone", False)
                })

            logger.info(f"üîç Found {len(similar_moments)} similar states for user {user_id}")
            return similar_moments

        except Exception as e:
            logger.error(f"‚ùå Error searching similar states for user {user_id}: {e}")
            return []

    async def get_personality_trajectory(
        self,
        user_id: int,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é —ç–≤–æ–ª—é—Ü–∏–∏ –ª–∏—á–Ω–æ—Å—Ç–∏

        –ö–æ–ª–ª–µ–∫—Ü–∏—è: personality_evolution
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ ‚Üí "–≤–∞—à–∞ –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å —Ä–∞—Å—Ç–µ—Ç"

        Returns:
            List –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        """
        try:
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –í–°–ï –≤–µ–∫—Ç–æ—Ä—ã —ç–≤–æ–ª—é—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            scroll_result = self.client.scroll(
                collection_name="personality_evolution",
                scroll_filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="user_id",
                            match=models.MatchValue(value=user_id)
                        )
                    ]
                ),
                limit=limit,
                with_payload=True
            )

            trajectory = []
            if scroll_result and len(scroll_result[0]) > 0:
                for point in scroll_result[0]:
                    payload = point.payload

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º created_at –∏–ª–∏ updated_at (—á—Ç–æ –µ—Å—Ç—å)
                    timestamp = payload.get("created_at") or payload.get("updated_at")

                    trajectory.append({
                        "snapshot_id": payload.get("snapshot_id"),
                        "created_at": timestamp,
                        "big_five": payload.get("personality_snapshot", {}).get("big_five", {}) or payload.get("traits", {}).get("big_five", {}),
                        "delta_magnitude": payload.get("delta_magnitude", 0),
                        "is_milestone": payload.get("is_milestone", False)
                    })

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Ç–æ–ª—å–∫–æ —Ç–µ —á—Ç–æ –∏–º–µ—é—Ç timestamp)
            trajectory = [t for t in trajectory if t["created_at"]]
            trajectory.sort(key=lambda x: x["created_at"])

            logger.info(f"üìà Loaded {len(trajectory)} evolution points for user {user_id}")
            return trajectory

        except Exception as e:
            logger.error(f"‚ùå Error loading trajectory for user {user_id}: {e}")
            return []

    async def analyze_personality_trajectory(
        self,
        user_id: int,
        window: int = 20
    ) -> Optional[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —ç–≤–æ–ª—é—Ü–∏–∏

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            window: –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç–æ—á–µ–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å

        Returns:
            Dict —Å —Ç—Ä–µ–Ω–¥–∞–º–∏ –∏ –∏–Ω—Å–∞–π—Ç–∞–º–∏

        –ü—Ä–∏–º–µ—Ä:
            {
                "trends": {
                    "openness": {"change": +0.25, "direction": "growing"},
                    "conscientiousness": {"change": -0.15, "direction": "declining"}
                },
                "insights": [
                    "–í–∞—à–∞ –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –Ω–æ–≤–æ–º—É —Ä–∞—Å—Ç–µ—Ç (+0.25)",
                    "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å–Ω–∏–∂–∞–µ—Ç—Å—è - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"
                ],
                "momentum": "positive",
                "volatility": "low"
            }
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
            trajectory = await self.get_personality_trajectory(user_id, limit=window)

            if len(trajectory) < 2:
                logger.warning(f"‚ö†Ô∏è Not enough data for trajectory analysis (need 2+, got {len(trajectory)})")
                return None

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —á–µ—Ä—Ç—É Big Five
            traits = ["openness", "conscientiousness", "extraversion", "agreeableness", "neuroticism"]
            trends = {}
            insights = []

            for trait in traits:
                # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–∏
                values = [
                    point["big_five"].get(trait, 0.5)
                    for point in trajectory
                    if point.get("big_five")
                ]

                if len(values) < 2:
                    continue

                # –í—ã—á–∏—Å–ª—è–µ–º —Ç—Ä–µ–Ω–¥
                first_value = values[0]
                last_value = values[-1]
                change = last_value - first_value

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                if abs(change) < 0.05:
                    direction = "stable"
                elif change > 0:
                    direction = "growing"
                else:
                    direction = "declining"

                trends[trait] = {
                    "change": round(change, 2),
                    "direction": direction,
                    "current_value": round(last_value, 2),
                    "volatility": round(self._calculate_volatility(values), 2)
                }

                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã –¥–ª—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
                if abs(change) >= 0.10:
                    insight = self._generate_trait_insight(trait, change, direction, last_value)
                    if insight:
                        insights.append(insight)

            # –û–±—â–∏–π momentum (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π)
            total_change = sum(t["change"] for t in trends.values())
            momentum = "positive" if total_change > 0 else "negative" if total_change < 0 else "neutral"

            # –°—Ä–µ–¥–Ω—è—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            avg_volatility = sum(t["volatility"] for t in trends.values()) / len(trends) if trends else 0
            volatility = "high" if avg_volatility > 0.15 else "low" if avg_volatility < 0.05 else "medium"

            logger.info(f"üìä Trajectory analysis: {len(insights)} insights, momentum: {momentum}")

            return {
                "trends": trends,
                "insights": insights,
                "momentum": momentum,
                "volatility": volatility,
                "data_points": len(trajectory),
                "time_span": f"{trajectory[0]['created_at'][:10]} ‚Üí {trajectory[-1]['created_at'][:10]}"
            }

        except Exception as e:
            logger.error(f"‚ùå Error analyzing trajectory for user {user_id}: {e}")
            return None

    def _calculate_volatility(self, values: List[float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)"""
        if len(values) < 2:
            return 0.0

        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5

    def _generate_trait_insight(self, trait: str, change: float, direction: str, current_value: float) -> Optional[str]:
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –∏–Ω—Å–∞–π—Ç –æ —Ç—Ä–µ–Ω–¥–µ —á–µ—Ä—Ç—ã"""

        trait_names = {
            "openness": "–æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –Ω–æ–≤–æ–º—É",
            "conscientiousness": "–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ—Å—Ç—å",
            "extraversion": "–æ–±—â–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "agreeableness": "–¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "neuroticism": "—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å"
        }

        trait_ru = trait_names.get(trait, trait)

        # üî• FIX: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º delta –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        change_percent = int(abs(change) * 100)

        # üî• FIX: –ü–æ–Ω—è—Ç–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–µ–ª–∏—á–∏–Ω—ã
        if abs(change) > 0.30:
            magnitude = "–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ"
        elif abs(change) > 0.20:
            magnitude = "–∑–∞–º–µ—Ç–Ω–æ"
        else:
            magnitude = "–Ω–µ–º–Ω–æ–≥–æ"

        if direction == "growing" and abs(change) >= 0.10:
            if trait == "openness":
                return f"–í–∞—à–∞ {trait_ru} {magnitude} —Ä–∞—Å—Ç–µ—Ç (–Ω–∞ {change_percent}%) - –≤—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç–µ—Å—å –±–æ–ª–µ–µ –≥–∏–±–∫–∏–º –∏ –æ—Ç–∫—Ä—ã—Ç—ã–º –∫ –Ω–æ–≤—ã–º –∏–¥–µ—è–º"
            elif trait == "conscientiousness":
                return f"–í–∞—à–∞ {trait_ru} {magnitude} —Ä–∞—Å—Ç–µ—Ç (–Ω–∞ {change_percent}%) - –≤—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç–µ—Å—å –±–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º"
            elif trait == "extraversion":
                return f"–í–∞—à–∞ {trait_ru} {magnitude} —Ä–∞—Å—Ç–µ—Ç (–Ω–∞ {change_percent}%) - –≤—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç–µ—Å—å –±–æ–ª–µ–µ —Å–æ—Ü–∏–∞–ª—å–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã–º"
            elif trait == "neuroticism" and change > 0.15:
                return f"–ó–∞–º–µ—á–∞—é —Ä–æ—Å—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞ {change_percent}%) - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–µ—Å—Å"

        elif direction == "declining" and abs(change) >= 0.10:
            if trait == "conscientiousness":
                return f"–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–æ—Å—Ç—å {magnitude} —Å–Ω–∏–∂–∞–µ—Ç—Å—è (–Ω–∞ {change_percent}%) - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"
            elif trait == "neuroticism" and change < -0.15:
                return f"–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å {magnitude} —É–ª—É—á—à–∞–µ—Ç—Å—è (–Ω–∞ {change_percent}%) - –æ—Ç–ª–∏—á–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞!"
            elif trait == "openness":
                return f"–û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –Ω–æ–≤–æ–º—É {magnitude} —Å–Ω–∏–∂–∞–µ—Ç—Å—è (–Ω–∞ {change_percent}%) - –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–æ–∏—Ç –¥–æ–±–∞–≤–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤?"

        return None

    async def find_similar_users(
        self,
        user_id: int,
        limit: int = 10,
        score_threshold: float = 0.75
    ) -> List[Dict[str, Any]]:
        """
        –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (similarity matching)

        –ö–æ–ª–ª–µ–∫—Ü–∏—è: personality_profiles
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: "–ª—é–¥–∏ —Å –ø–æ—Ö–æ–∂–∏–º –ø—Ä–æ—Ñ–∏–ª–µ–º –Ω–∞—Ö–æ–¥—è—Ç –ø–æ–º–æ—â—å –≤..."

        Returns:
            List –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å scores
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_user = await self.get_current_personality_vector(user_id)
            if not current_user:
                return []

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏—Ö
            search_result = self.client.search(
                collection_name="personality_profiles",
                query_vector=current_user["vector"],
                limit=limit + 1,  # +1 —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å —Å–µ–±—è
                score_threshold=score_threshold,
                with_payload=True
            )

            similar_users = []
            for hit in search_result:
                hit_user_id = hit.payload.get("user_id")

                # –ò—Å–∫–ª—é—á–∞–µ–º —Å–µ–±—è
                if hit_user_id == user_id:
                    continue

                similar_users.append({
                    "user_id": hit_user_id,
                    "similarity_score": hit.score,
                    "big_five": hit.payload.get("traits", {}).get("big_five", {}),
                    "archetype": self._determine_archetype(hit.payload.get("traits", {}))
                })

            logger.info(f"üë• Found {len(similar_users)} similar users for {user_id}")
            return similar_users

        except Exception as e:
            logger.error(f"‚ùå Error finding similar users for {user_id}: {e}")
            return []

    def _determine_archetype(self, traits: Dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞—Ä—Ö–µ—Ç–∏–ø –ª–∏—á–Ω–æ—Å—Ç–∏ –∏–∑ Big Five"""
        big_five = traits.get("big_five", {})

        o = big_five.get("openness", 0.5)
        c = big_five.get("conscientiousness", 0.5)
        e = big_five.get("extraversion", 0.5)

        if o > 0.7 and e < 0.5:
            return "–ú—É–¥—Ä—ã–π –°–æ–∑–µ—Ä—Ü–∞—Ç–µ–ª—å"
        elif o > 0.7 and e > 0.6:
            return "–í–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π –¢–≤–æ—Ä–µ—Ü"
        elif c > 0.7:
            return "–ù–∞–¥–µ–∂–Ω—ã–π –û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä"
        elif e > 0.7:
            return "–¢–µ–ø–ª—ã–π –ö–æ–º–º—É–Ω–∏–∫–∞—Ç–æ—Ä"
        else:
            return "–ì–∞—Ä–º–æ–Ω–∏—á–Ω–∞—è –õ–∏—á–Ω–æ—Å—Ç—å"

    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qdrant"""
        try:
            collections = self.client.get_collections()
            collection_names = [c.name for c in collections.collections]

            stats = {}
            for name in ["personality_profiles", "personality_evolution", "quick_match"]:
                if name in collection_names:
                    info = self.client.get_collection(name)
                    stats[name] = {
                        "points_count": info.points_count,
                        "status": info.status
                    }

            return {
                "status": "healthy",
                "collections": stats
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
