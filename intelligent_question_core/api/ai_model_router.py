#!/usr/bin/env python3
"""
AI MODEL ROUTER - –£–º–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–µ–π AI –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –∑–∞—Ç—Ä–∞—Ç—ã –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞
"""

import os
import json
from enum import Enum
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

class AnalysisTask(Enum):
    """–¢–∏–ø—ã –∑–∞–¥–∞—á –∞–Ω–∞–ª–∏–∑–∞"""
    QUESTION_CLASSIFICATION = "question_classification"    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
    ANSWER_ANALYSIS = "answer_analysis"                   # –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    PERSONALITY_BUILDING = "personality_building"         # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏
    QUESTION_CONNECTIONS = "question_connections"         # –°–≤—è–∑–∏ –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–∞–º–∏  
    SIMILARITY_DETECTION = "similarity_detection"        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    EMOTIONAL_ANALYSIS = "emotional_analysis"            # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    TEXT_EMBEDDING = "text_embedding"                    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

class AIModel(Enum):
    """–î–æ—Å—Ç—É–ø–Ω—ã–µ AI –º–æ–¥–µ–ª–∏"""
    GPT_4O_MINI = "gpt-4o-mini"                 # –ë—ã—Å—Ç—Ä—ã–π –∏ –¥–µ—à–µ–≤—ã–π
    GPT_4O = "gpt-4o"                           # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
    CLAUDE_SONNET = "claude-3-5-sonnet-20241022"   # –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
    CLAUDE_HAIKU = "claude-3-haiku-20240307"    # –ë—ã—Å—Ç—Ä—ã–π –∏ —Ç–æ—á–Ω—ã–π
    TEXT_EMBEDDING_SMALL = "text-embedding-3-small"  # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è

@dataclass
class ModelSpec:
    """–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
    name: str
    cost_per_1k_tokens: float
    speed: str  # fast/medium/slow
    quality: str  # basic/good/excellent
    best_for: List[str]

class AIModelRouter:
    """–£–º–Ω—ã–π —Ä–æ—É—Ç–µ—Ä AI –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º API –∫–ª—é—á–∏
        self.load_api_keys()
        
        # –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π
        self.models = {
            AIModel.GPT_4O_MINI: ModelSpec(
                name="GPT-4o-mini",
                cost_per_1k_tokens=0.00015,
                speed="fast", 
                quality="good",
                best_for=["batch_classification", "simple_analysis", "routing_decisions"]
            ),
            AIModel.GPT_4O: ModelSpec(
                name="GPT-4o", 
                cost_per_1k_tokens=0.005,
                speed="medium",
                quality="excellent", 
                best_for=["complex_analysis", "nuanced_understanding"]
            ),
            AIModel.CLAUDE_SONNET: ModelSpec(
                name="Claude-3.5-Sonnet",
                cost_per_1k_tokens=0.003,
                speed="medium",
                quality="excellent",
                best_for=["deep_analysis", "personality_building", "psychological_insights"]
            ),
            AIModel.CLAUDE_HAIKU: ModelSpec(
                name="Claude-3-Haiku",
                cost_per_1k_tokens=0.00025,
                speed="fast",
                quality="good", 
                best_for=["quick_classification", "pattern_detection"]
            ),
            AIModel.TEXT_EMBEDDING_SMALL: ModelSpec(
                name="text-embedding-3-small",
                cost_per_1k_tokens=0.00002,
                speed="very_fast",
                quality="specialized",
                best_for=["vectorization", "similarity_search"]
            )
        }
        
        # –ü—Ä–∞–≤–∏–ª–∞ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
        self.task_routing = {
            AnalysisTask.QUESTION_CLASSIFICATION: {
                "primary": AIModel.GPT_4O_MINI,    # –¥–µ—à–µ–≤–æ –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
                "fallback": AIModel.CLAUDE_HAIKU,
                "batch_size": 25,
                "reasoning": "–ú–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"
            },
            AnalysisTask.ANSWER_ANALYSIS: {
                "primary": AIModel.CLAUDE_SONNET,   # –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏
                "fallback": AIModel.GPT_4O,
                "batch_size": 1,
                "reasoning": "–ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏"
            },
            AnalysisTask.PERSONALITY_BUILDING: {
                "primary": AIModel.CLAUDE_SONNET,   # –ª—É—á—à–∏–π –¥–ª—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏
                "fallback": AIModel.GPT_4O,
                "batch_size": 5,
                "reasoning": "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è"
            },
            AnalysisTask.QUESTION_CONNECTIONS: {
                "primary": AIModel.GPT_4O_MINI,     # –±—ã—Å—Ç—Ä–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
                "fallback": AIModel.CLAUDE_HAIKU,
                "batch_size": 50,
                "reasoning": "–ü–æ–∏—Å–∫ —Å–≤—è–∑–µ–π - –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–∞—á–∞"
            },
            AnalysisTask.SIMILARITY_DETECTION: {
                "primary": AIModel.TEXT_EMBEDDING_SMALL,  # —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
                "fallback": AIModel.GPT_4O_MINI,
                "batch_size": 100,
                "reasoning": "Embeddings —Ç–æ—á–Ω–µ–µ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏"
            },
            AnalysisTask.EMOTIONAL_ANALYSIS: {
                "primary": AIModel.CLAUDE_SONNET,   # –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç —ç–º–æ—Ü–∏–∏
                "fallback": AIModel.GPT_4O,
                "batch_size": 10,
                "reasoning": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±—É–µ—Ç —Ç–æ–Ω–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è"
            }
        }
    
    def load_api_keys(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç API –∫–ª—é—á–∏ –∏–∑ .env —Ñ–∞–π–ª–∞"""
        self.api_keys = {}
        try:
            with open('.env', 'r') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        self.api_keys[key] = value
            print("‚úÖ API –∫–ª—é—á–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        except FileNotFoundError:
            print("‚ùå –§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    def select_optimal_model(self, task: AnalysisTask, data_size: int = 1, 
                           priority: str = "balanced") -> Dict[str, Any]:
        """–í—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–¥–∞—á–∏"""
        
        task_config = self.task_routing[task]
        selected_model = task_config["primary"]
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—ã–±–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        if priority == "cost":
            # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—É—é –¥–µ—à–µ–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –º–æ–¥–µ–ª—å
            if task in [AnalysisTask.QUESTION_CLASSIFICATION, AnalysisTask.QUESTION_CONNECTIONS]:
                selected_model = AIModel.GPT_4O_MINI
        elif priority == "quality":
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            if task in [AnalysisTask.ANSWER_ANALYSIS, AnalysisTask.PERSONALITY_BUILDING]:
                selected_model = AIModel.CLAUDE_SONNET
        
        model_spec = self.models[selected_model]
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
        estimated_tokens = self._estimate_tokens(task, data_size)
        estimated_cost = estimated_tokens * model_spec.cost_per_1k_tokens / 1000
        
        return {
            "selected_model": selected_model.value,
            "model_spec": model_spec,
            "task_config": task_config,
            "estimated_cost": estimated_cost,
            "estimated_tokens": estimated_tokens,
            "batch_size": task_config["batch_size"],
            "reasoning": task_config["reasoning"]
        }
    
    def _estimate_tokens(self, task: AnalysisTask, data_size: int) -> int:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏"""
        
        # –ë–∞–∑–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        token_estimates = {
            AnalysisTask.QUESTION_CLASSIFICATION: 300,  # –ø—Ä–æ–º–ø—Ç + –æ—Ç–≤–µ—Ç
            AnalysisTask.ANSWER_ANALYSIS: 500,         # –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
            AnalysisTask.PERSONALITY_BUILDING: 800,    # –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            AnalysisTask.QUESTION_CONNECTIONS: 200,    # –ø—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            AnalysisTask.EMOTIONAL_ANALYSIS: 400      # —Å—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        }
        
        base_tokens = token_estimates.get(task, 300)
        return base_tokens * data_size
    
    def create_cost_optimization_plan(self, total_questions: int) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç"""
        
        print("üí∞ –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç...")
        
        # –†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        strategies = {
            "aggressive_cost_saving": {
                "core_questions": 100,    # —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                "batch_classification": True,
                "primary_model": AIModel.GPT_4O_MINI,
                "estimated_cost": 0.08,
                "quality": "good_enough"
            },
            "balanced": {
                "core_questions": 300,    # —Ç—Ä–µ—Ç—å –≤—Å–µ—Ö –≤–æ–ø—Ä–æ—Å–æ–≤  
                "mixed_models": True,
                "estimated_cost": 0.25,
                "quality": "high"
            },
            "premium_quality": {
                "all_questions": total_questions,
                "best_models": True,
                "estimated_cost": 0.60,
                "quality": "excellent"
            }
        }
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        recommendation = {
            "recommended_strategy": "balanced",
            "reasoning": "–û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ü–µ–Ω–∞/–∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è MVP",
            "phased_approach": {
                "phase_1": "100 –∫–ª—é—á–µ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏",
                "phase_2": "200 –æ—Å–Ω–æ–≤–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –±–∞–∑–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π", 
                "phase_3": "393 –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"
            }
        }
        
        return {
            "strategies": strategies,
            "recommendation": recommendation
        }
    
    def generate_classification_prompts(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        
        prompts = {
            "question_classification": """
–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —ç—Ç–∏ –≤–æ–ø—Ä–æ—Å—ã –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–æ—Å–Ω–∏–∫–∞ –ø–æ —Å–∏—Å—Ç–µ–º–µ:

JOURNEY_STAGE: ENTRY/WARMING/EXPLORING/DEEPENING/BREAKTHROUGH/INTEGRATION
DEPTH_LEVEL: SURFACE/CONSCIOUS/EDGE/SHADOW/CORE  
DOMAIN: IDENTITY/EMOTIONS/RELATIONSHIPS/WORK/CREATIVITY/SPIRITUALITY/etc
ENERGY: OPENING/NEUTRAL/PROCESSING/HEAVY/HEALING

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–æ–±–∞–≤—å:
- complexity (1-5): —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏—è
- emotional_weight (1-5): —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
- insight_potential (1-5): –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –≥–ª—É–±–æ–∫–∏—Ö –∏–Ω—Å–∞–π—Ç–æ–≤
- safety_level (1-5): –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤

–í–û–ü–†–û–°–´:
{questions}

JSON –æ—Ç–≤–µ—Ç —Å analysis –º–∞—Å—Å–∏–≤–æ–º.
""",
            
            "answer_analysis": """
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å:

–í–û–ü–†–û–°: "{question}"
–û–¢–í–ï–¢: "{answer}"

–û–ø—Ä–µ–¥–µ–ª–∏:
1. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (positive/neutral/negative + intensity 1-5)
2. –£—Ä–æ–≤–µ–Ω—å –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç–∏ (1-5) 
3. –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–±–µ–≥–∞–Ω–∏—è –∏–ª–∏ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
4. –ö–ª—é—á–µ–≤—ã–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã
5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞

JSON –æ—Ç–≤–µ—Ç —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º.
""",
            
            "personality_vector_update": """
–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ–±–Ω–æ–≤–∏ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –º–æ–¥–µ–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:

–û–¢–í–ï–¢: "{answer}"
–¢–ï–ö–£–©–ò–ô –í–ï–ö–¢–û–†: {current_vector}

–û–ø—Ä–µ–¥–µ–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è (-1.0 –¥–æ +1.0):
- self_awareness, emotional_intelligence, openness, conscientiousness
- extraversion, agreeableness, neuroticism, growth_mindset
- life_satisfaction, resilience, authenticity, meaning_making

JSON —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –≤–µ–∫—Ç–æ—Ä–∞ + –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º.
""",
            
            "connection_analysis": """
–ù–∞–π–¥–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É —ç—Ç–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏:

–ë–ê–ó–û–í–´–ô –í–û–ü–†–û–°: "{base_question}"
–ö–ê–ù–î–ò–î–ê–¢–´: {candidate_questions}

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏:
1. –¢–∏–ø —Å–≤—è–∑–∏: logical_sequence/thematic_cluster/depth_progression/emotional_bridge
2. –°–∏–ª—É —Å–≤—è–∑–∏ (0.0-1.0)
3. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: bidirectional/from_base/to_base
4. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä—è–¥–æ–∫

JSON —Å –º–∞—Å—Å–∏–≤–æ–º connections.
"""
        }
        
        with open('ai_analysis_prompts.json', 'w', encoding='utf-8') as f:
            json.dump(prompts, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–∑–¥–∞–Ω—ã: ai_analysis_prompts.json")

def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Ä–æ—É—Ç–µ—Ä–∞"""
    
    print("üß† AI MODEL ROUTER")
    print("üéØ –£–º–Ω—ã–π –≤—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏")
    print("=" * 60)
    
    router = AIModelRouter()
    
    # –î–µ–º–æ: –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
    tasks_demo = [
        (AnalysisTask.QUESTION_CLASSIFICATION, 693, "cost"),
        (AnalysisTask.ANSWER_ANALYSIS, 1, "quality"),
        (AnalysisTask.PERSONALITY_BUILDING, 5, "balanced"),
        (AnalysisTask.SIMILARITY_DETECTION, 100, "cost")
    ]
    
    total_estimated_cost = 0
    
    print("\nüìä –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ú–û–î–ï–õ–Ø–ú:")
    for task, data_size, priority in tasks_demo:
        recommendation = router.select_optimal_model(task, data_size, priority)
        total_estimated_cost += recommendation["estimated_cost"]
        
        print(f"\nüéØ {task.value}:")
        print(f"  üì± –ú–æ–¥–µ–ª—å: {recommendation['selected_model']}")
        print(f"  üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: ${recommendation['estimated_cost']:.4f}")
        print(f"  üìä –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {recommendation['batch_size']}")
        print(f"  üí° –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {recommendation['reasoning']}")
    
    print(f"\nüí∞ –û–ë–©–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨ –ê–ù–ê–õ–ò–ó–ê: ${total_estimated_cost:.2f}")
    
    # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    cost_plan = router.create_cost_optimization_plan(693)
    
    print(f"\nüìã –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø:")
    print(f"üéØ {cost_plan['recommendation']['recommended_strategy']}")
    print(f"üí° {cost_plan['recommendation']['reasoning']}")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç—ã
    router.generate_classification_prompts()
    
    print(f"\n‚úÖ AI —Ä–æ—É—Ç–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

if __name__ == "__main__":
    main()