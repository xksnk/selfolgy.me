"""
New OnboardingDAO - –ß–∏—Å—Ç–∞—è –≥–∏–±—Ä–∏–¥–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

–ü—Ä–∏–Ω—Ü–∏–ø—ã:
- –ú–∏–Ω–∏–º—É–º –≤ –ë–î + –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON
- –û–¥–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- questions_metadata –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–∞—Ö
- –ù–ï–¢ –ª–∏—à–Ω–∏—Ö —Ç–∞–±–ª–∏—Ü –∏ —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–∏
"""

import logging
import json
import asyncpg
from datetime import datetime
from typing import Dict, List, Optional, Any

from .service import DatabaseService

logger = logging.getLogger(__name__)

class OnboardingDAO:
    """DAO –¥–ª—è –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞"""

    def __init__(self, db_service: DatabaseService):
        self.db = db_service

    async def create_onboarding_tables(self):
        """–°–æ–∑–¥–∞—Ç—å —á–∏—Å—Ç—ã–µ —Ç–∞–±–ª–∏—Ü—ã –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞"""

        # 1. questions_metadata - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ JSON
        questions_metadata_sql = """
        CREATE TABLE IF NOT EXISTS questions_metadata (
            id SERIAL PRIMARY KEY,
            json_id VARCHAR(50) UNIQUE NOT NULL,
            domain VARCHAR(20) NOT NULL,
            depth_level VARCHAR(15) NOT NULL,
            energy VARCHAR(15) NOT NULL,

            -- –§–ª–∞–≥–∏ "–Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É" (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–∞)
            is_flagged BOOLEAN DEFAULT false,
            flagged_by_admin VARCHAR(20),
            flag_reason TEXT,
            flagged_at TIMESTAMP,

            created_at TIMESTAMP DEFAULT NOW()
        )
        """

        # 2. onboarding_sessions - –ø—Ä–æ—Å—Ç—ã–µ —Å–µ—Å—Å–∏–∏
        sessions_sql = """
        CREATE TABLE IF NOT EXISTS onboarding_sessions (
            id SERIAL PRIMARY KEY,
            user_id INTEGER NOT NULL,

            started_at TIMESTAMP DEFAULT NOW(),
            completed_at TIMESTAMP,
            status VARCHAR(20) DEFAULT 'active',

            questions_asked INTEGER DEFAULT 0,
            questions_answered INTEGER DEFAULT 0,
            current_question_json_id VARCHAR(10),

            -- Smart Mix —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            last_strategy VARCHAR(20),
            domains_covered TEXT[],
            heavy_count INTEGER DEFAULT 0,

            session_data JSONB DEFAULT '{}'
        )
        """

        # 3. –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é user_answers –¥–ª—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        user_answers_sql = """
        CREATE TABLE IF NOT EXISTS user_answers_new (
            id SERIAL PRIMARY KEY,
            session_id INTEGER REFERENCES onboarding_sessions(id) ON DELETE CASCADE,
            question_json_id VARCHAR(10) NOT NULL,

            raw_answer TEXT NOT NULL,
            answer_length INTEGER,
            answered_at TIMESTAMP DEFAULT NOW(),

            -- –î–ª—è Phase 2 (–∞–Ω–∞–ª–∏–∑)
            analysis_status VARCHAR(20) DEFAULT 'pending'
        )
        """

        # 4. –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–æ–≤ (Phase 2)
        answer_analysis_sql = """
        CREATE TABLE IF NOT EXISTS answer_analysis (
            id SERIAL PRIMARY KEY,
            user_answer_id INTEGER REFERENCES user_answers_new(id) ON DELETE CASCADE,

            -- –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
            analysis_version VARCHAR(10) NOT NULL DEFAULT '2.0',

            -- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            psychological_insights TEXT,
            trait_scores JSONB NOT NULL DEFAULT '{}'
                CONSTRAINT valid_trait_structure CHECK (
                    trait_scores ? 'version' AND
                    trait_scores ? 'big_five' AND
                    trait_scores ? 'timestamp'
                ),
            emotional_state VARCHAR(30),
            fatigue_level FLOAT,

            -- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ä–æ—É—Ç–µ—Ä–∞
            next_question_hints JSONB DEFAULT '{}',

            -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            ai_model_used VARCHAR(30),
            processing_time_ms INTEGER,
            processed_at TIMESTAMP DEFAULT NOW(),

            -- –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è (—Å–∂–∞—Ç–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ)
            raw_ai_response JSONB,
            debug_priority SMALLINT DEFAULT 0,
            can_be_compressed BOOLEAN DEFAULT TRUE,

            -- –ö–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞
            quality_score FLOAT DEFAULT 0.0,
            confidence_score FLOAT DEFAULT 0.0,

            -- –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏
            special_situation VARCHAR(20),  -- crisis, breakthrough, resistance
            is_milestone BOOLEAN DEFAULT false
        )
        """

        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
        indexes_sql = [
            # questions_metadata –∏–Ω–¥–µ–∫—Å—ã
            "CREATE INDEX IF NOT EXISTS idx_qmeta_domain ON questions_metadata(domain)",
            "CREATE INDEX IF NOT EXISTS idx_qmeta_flagged ON questions_metadata(is_flagged) WHERE is_flagged = false",

            # onboarding_sessions –∏–Ω–¥–µ–∫—Å—ã
            "CREATE INDEX IF NOT EXISTS idx_sessions_user ON onboarding_sessions(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_sessions_active ON onboarding_sessions(user_id, status) WHERE status = 'active'",

            # user_answers_new –∏–Ω–¥–µ–∫—Å—ã
            "CREATE INDEX IF NOT EXISTS idx_answers_session ON user_answers_new(session_id)",
            "CREATE INDEX IF NOT EXISTS idx_answers_question ON user_answers_new(question_json_id)",
            "CREATE INDEX IF NOT EXISTS idx_answers_status ON user_answers_new(analysis_status)",

            # answer_analysis –∏–Ω–¥–µ–∫—Å—ã (Phase 2)
            "CREATE INDEX IF NOT EXISTS idx_analysis_answer ON answer_analysis(user_answer_id)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_version ON answer_analysis(analysis_version)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_model ON answer_analysis(ai_model_used)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_quality ON answer_analysis(quality_score)",
            "CREATE INDEX IF NOT EXISTS idx_analysis_milestone ON answer_analysis(is_milestone) WHERE is_milestone = true",
            "CREATE INDEX IF NOT EXISTS idx_analysis_situation ON answer_analysis(special_situation)"
        ]

        try:
            async with self.db.get_connection() as conn:
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
                await conn.execute(questions_metadata_sql)
                await conn.execute(sessions_sql)
                await conn.execute(user_answers_sql)
                await conn.execute(answer_analysis_sql)  # üÜï Phase 2 table

                # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
                for index_sql in indexes_sql:
                    await conn.execute(index_sql)

                logger.info("‚úÖ New onboarding tables created")

        except Exception as e:
            logger.error(f"‚ùå Error creating onboarding tables: {e}")
            raise

    async def get_active_session(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –≥–ª–æ–±–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π

        Returns:
            Session data + total_answers_lifetime –∏–∑ user_stats
        """

        try:
            async with self.db.get_connection() as conn:
                row = await conn.fetchrow("""
                    SELECT
                        os.id, os.user_id, os.started_at, os.status,
                        os.questions_asked, os.questions_answered,
                        os.current_question_json_id,
                        os.last_strategy, os.domains_covered,
                        os.heavy_count, os.session_data,
                        COALESCE(us.total_answers_lifetime, 0) as total_answers_lifetime
                    FROM onboarding_sessions os
                    LEFT JOIN user_stats us ON us.user_id = os.user_id
                    WHERE os.user_id = $1 AND os.status = 'active'
                    ORDER BY os.started_at DESC
                    LIMIT 1
                """, user_id)

                if row:
                    return dict(row)
                return None

        except Exception as e:
            logger.error(f"‚ùå Error getting active session for user {user_id}: {e}")
            return None

    async def get_session_by_id(self, session_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–µ—Å—Å–∏—é –ø–æ ID

        Returns:
            Session data
        """

        try:
            async with self.db.get_connection() as conn:
                row = await conn.fetchrow("""
                    SELECT
                        id, user_id, started_at, status,
                        questions_asked, questions_answered,
                        current_question_json_id,
                        last_strategy, domains_covered,
                        heavy_count, session_data
                    FROM onboarding_sessions
                    WHERE id = $1
                """, session_id)

                if row:
                    return dict(row)
                return None

        except Exception as e:
            logger.error(f"‚ùå Error getting session {session_id}: {e}")
            return None

    async def start_session(self, user_id: int) -> int:
        """–ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é (–∑–∞–∫—Ä—ã–≤–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–∫—Ç–∏–≤–Ω—ã–µ)"""

        try:
            async with self.db.get_connection() as conn:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ª—é–±—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                await conn.execute("""
                    UPDATE onboarding_sessions
                    SET status = 'abandoned', completed_at = NOW()
                    WHERE user_id = $1 AND status = 'active'
                """, user_id)

                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
                session_id = await conn.fetchval("""
                    INSERT INTO onboarding_sessions (user_id, status)
                    VALUES ($1, 'active')
                    RETURNING id
                """, user_id)

                logger.info(f"üöÄ Started new session {session_id} for user {user_id}")
                return session_id

        except Exception as e:
            logger.error(f"‚ùå Error starting session for user {user_id}: {e}")
            raise

    async def save_user_answer(self, session_id: int, question_json_id: str, answer: str) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        NOTE: total_answers_lifetime –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Ç—Ä–∏–≥–≥–µ—Ä update_lifetime_answers_trigger
        """

        try:
            async with self.db.get_connection() as conn:
                answer_id = await conn.fetchval("""
                    INSERT INTO user_answers_new (session_id, question_json_id, raw_answer, answer_length)
                    VALUES ($1, $2, $3, $4)
                    RETURNING id
                """, session_id, question_json_id, answer, len(answer))

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—Ç–≤–µ—Ç–æ–≤ –¢–û–õ–¨–ö–û –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
                # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ total_answers_lifetime –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                await conn.execute("""
                    UPDATE onboarding_sessions
                    SET questions_answered = questions_answered + 1
                    WHERE id = $1
                """, session_id)

                logger.info(f"üí¨ Saved answer {answer_id} for session {session_id}")
                return answer_id

        except Exception as e:
            logger.error(f"‚ùå Error saving answer for session {session_id}: {e}")
            raise

    async def increment_questions_asked(self, session_id: int):
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç —Å—á–µ—Ç—á–∏–∫–∞ –∑–∞–¥–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE onboarding_sessions
                    SET questions_asked = questions_asked + 1
                    WHERE id = $1
                """, session_id)

                logger.debug(f"‚úÖ Incremented questions_asked for session {session_id}")

        except Exception as e:
            logger.error(f"‚ùå Error incrementing questions_asked for session {session_id}: {e}")
            raise

    async def update_current_question(self, session_id: int, question_json_id: str):
        """–û–±–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ —Å–µ—Å—Å–∏–∏"""

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE onboarding_sessions
                    SET current_question_json_id = $2
                    WHERE id = $1
                """, session_id, question_json_id)

                logger.debug(f"‚úÖ Updated current question to {question_json_id} for session {session_id}")

        except Exception as e:
            logger.error(f"‚ùå Error updating current question for session {session_id}: {e}")
            raise

    async def complete_session(self, session_id: int):
        """
        –ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ—Å—Å–∏—é –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        """
        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE onboarding_sessions
                    SET status = 'completed', completed_at = NOW()
                    WHERE id = $1
                """, session_id)

                logger.info(f"‚úÖ Session {session_id} completed")

        except Exception as e:
            logger.error(f"‚ùå Error completing session {session_id}: {e}")
            raise

    async def auto_approve_question(self, json_id: str, domain: str, depth: str, energy: str):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–¥–æ–±—Ä–∏—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO questions_metadata (json_id, domain, depth_level, energy, is_flagged)
                    VALUES ($1, $2, $3, $4, false)
                    ON CONFLICT (json_id) DO NOTHING
                """, json_id, domain, depth, energy)

                logger.info(f"‚úÖ Question {json_id} auto-approved")

        except Exception as e:
            logger.error(f"‚ùå Error auto-approving question {json_id}: {e}")

    async def flag_question_for_admin(self, json_id: str, admin_id: str, reason: str):
        """–ü–æ–º–µ—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É (—Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω)"""

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO questions_metadata (json_id, domain, depth_level, energy, is_flagged, flagged_by_admin, flag_reason, flagged_at)
                    SELECT $1, 'UNKNOWN', 'UNKNOWN', 'UNKNOWN', true, $2, $3, NOW()
                    WHERE NOT EXISTS (SELECT 1 FROM questions_metadata WHERE json_id = $1)

                    UNION ALL

                    UPDATE questions_metadata
                    SET is_flagged = true, flagged_by_admin = $2, flag_reason = $3, flagged_at = NOW()
                    WHERE json_id = $1
                """, json_id, admin_id, reason)

                logger.info(f"üöß Question {json_id} flagged by admin {admin_id}")

        except Exception as e:
            logger.error(f"‚ùå Error flagging question {json_id}: {e}")
            raise

    async def get_unflagged_questions(self, domain: str = None) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–µ json_id –¥–ª—è —Ä–æ—É—Ç–µ—Ä–∞"""

        try:
            async with self.db.get_connection() as conn:
                if domain:
                    json_ids = await conn.fetch("""
                        SELECT json_id FROM questions_metadata
                        WHERE is_flagged = false AND domain = $1
                    """, domain)
                else:
                    json_ids = await conn.fetch("""
                        SELECT json_id FROM questions_metadata
                        WHERE is_flagged = false
                    """)

                return [row['json_id'] for row in json_ids]

        except Exception as e:
            logger.error(f"‚ùå Error getting unflagged questions: {e}")
            return []  # Fallback - –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫

    async def get_flagged_question_ids(self) -> set:
        """
        –ü–æ–ª—É—á–∏—Ç—å set ID –≤–æ–ø—Ä–æ—Å–æ–≤, –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö —Ñ–ª–∞–≥–æ–º (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)

        Returns:
            Set JSON IDs –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        """
        try:
            async with self.db.get_connection() as conn:
                rows = await conn.fetch("""
                    SELECT json_id FROM questions_metadata
                    WHERE is_flagged = true
                """)

                flagged_ids = {row['json_id'] for row in rows}
                logger.debug(f"üö© Found {len(flagged_ids)} flagged questions")
                return flagged_ids

        except Exception as e:
            logger.error(f"‚ùå Error getting flagged questions: {e}")
            return set()  # Fallback - –ø—É—Å—Ç–æ–π set

    async def flag_question(self, question_id: str, reason: str, admin_id: int) -> bool:
        """
        –ü–æ–º–µ—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É (—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î)

        Args:
            question_id: JSON ID –≤–æ–ø—Ä–æ—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, q_172)
            reason: –ü—Ä–∏—á–∏–Ω–∞ –ø–æ–º–µ—Ç–∫–∏
            admin_id: Telegram ID –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO questions_metadata
                        (json_id, is_flagged, flag_reason, flagged_at, flagged_by_admin)
                    VALUES ($1, true, $2, NOW(), $3)
                    ON CONFLICT (json_id)
                    DO UPDATE SET
                        is_flagged = true,
                        flag_reason = $2,
                        flagged_at = NOW(),
                        flagged_by_admin = $3
                """, question_id, reason, str(admin_id))

                logger.info(f"‚úÖ Flagged question {question_id} in database")
                return True

        except Exception as e:
            logger.error(f"‚ùå Error flagging question {question_id}: {e}")
            return False

    async def unflag_question(self, question_id: str) -> bool:
        """
        –°–Ω—è—Ç—å —Ñ–ª–∞–≥ —Å –≤–æ–ø—Ä–æ—Å–∞

        Args:
            question_id: JSON ID –≤–æ–ø—Ä–æ—Å–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE questions_metadata
                    SET is_flagged = false,
                        flag_reason = NULL,
                        flagged_at = NULL,
                        flagged_by_admin = NULL
                    WHERE json_id = $1
                """, question_id)

                logger.info(f"‚úÖ Unflagged question {question_id}")
                return True

        except Exception as e:
            logger.error(f"‚ùå Error unflagging question {question_id}: {e}")
            return False

    async def get_session_analysis_insights(self, session_id: int) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ —Å–µ—Å—Å–∏–∏ –¥–ª—è —É–º–Ω–æ–≥–æ —Ä–æ—É—Ç–∏–Ω–≥–∞

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ —Å insights –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            async with self.db.get_connection() as conn:
                rows = await conn.fetch("""
                    SELECT
                        ua.question_json_id,
                        ua.raw_answer,
                        aa.emotional_state,
                        aa.quality_score,
                        aa.confidence_score,
                        aa.special_situation,
                        aa.next_question_hints,
                        qm.domain
                    FROM user_answers_new ua
                    LEFT JOIN answer_analysis aa ON aa.user_answer_id = ua.id
                    LEFT JOIN questions_metadata qm ON qm.json_id = ua.question_json_id
                    WHERE ua.session_id = $1
                    ORDER BY ua.answered_at ASC
                """, session_id)

                insights = []
                for row in rows:
                    insights.append({
                        'question_id': row['question_json_id'],
                        'answer': row['raw_answer'],
                        'emotional_state': row['emotional_state'],
                        'quality_score': row['quality_score'] or 0.0,
                        'confidence_score': row['confidence_score'] or 0.0,
                        'special_situation': row['special_situation'],
                        'next_question_hints': row['next_question_hints'] or {},
                        'domain': row['domain']
                    })

                logger.debug(f"üìä Retrieved {len(insights)} analysis insights for session {session_id}")
                return insights

        except Exception as e:
            logger.error(f"‚ùå Error getting session analysis insights for session {session_id}: {e}")
            return []

    async def save_analysis_result(
        self,
        user_answer_id: int,
        analysis_result: Dict[str, Any]
    ) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞ –≤ –ë–î

        Args:
            user_answer_id: ID –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            analysis_result: –ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ AnswerAnalyzer

        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
        """

        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            processing_meta = analysis_result.get("processing_metadata", {})
            quality_meta = analysis_result.get("quality_metadata", {})
            psychological = analysis_result.get("psychological_analysis", {})
            traits = analysis_result.get("personality_traits", {})
            router_rec = analysis_result.get("router_recommendations", {})

            async with self.db.get_connection() as conn:
                analysis_id = await conn.fetchval("""
                    INSERT INTO answer_analysis (
                        user_answer_id, analysis_version, psychological_insights,
                        trait_scores, emotional_state, fatigue_level,
                        next_question_hints, ai_model_used, processing_time_ms,
                        raw_ai_response, debug_priority, quality_score,
                        confidence_score, special_situation, is_milestone
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
                    RETURNING id
                """,
                    user_answer_id,
                    analysis_result.get("analysis_version", "2.0"),
                    json.dumps(psychological.get("insights", {}), ensure_ascii=False),
                    json.dumps(traits, ensure_ascii=False),
                    psychological.get("emotional_assessment", {}).get("primary", "neutral"),
                    quality_meta.get("fatigue_indicators", 0.0),
                    json.dumps(router_rec, ensure_ascii=False),
                    processing_meta.get("model_used", "unknown"),
                    processing_meta.get("processing_time_ms", 0),
                    json.dumps(analysis_result, ensure_ascii=False),  # üî• FIX: –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–ï–°–¨ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–µ —Ç–æ–ª—å–∫–æ debug_info!
                    1 if processing_meta.get("special_situation") else 0,
                    quality_meta.get("overall_reliability", 0.0),
                    quality_meta.get("data_completeness", 0.0),
                    processing_meta.get("special_situation"),
                    processing_meta.get("special_situation") == "breakthrough"
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
                await conn.execute("""
                    UPDATE user_answers_new
                    SET analysis_status = 'analyzed'
                    WHERE id = $1
                """, user_answer_id)

                logger.info(f"üíæ Analysis saved with ID {analysis_id} for answer {user_answer_id}")
                return analysis_id

        except Exception as e:
            logger.error(f"‚ùå Error saving analysis for answer {user_answer_id}: {e}")
            raise

    async def get_user_total_answers(self, user_id: int) -> int:
        """
        –ü–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è

        Returns:
            –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ (–∏–∑ —Ç–∞–±–ª–∏—Ü—ã user_stats)
        """

        try:
            async with self.db.get_connection() as conn:
                total = await conn.fetchval("""
                    SELECT COALESCE(total_answers_lifetime, 0)
                    FROM user_stats
                    WHERE user_id = $1
                """, user_id)

                return total if total is not None else 0

        except Exception as e:
            logger.error(f"‚ùå Error getting total answers for user {user_id}: {e}")
            return 0

    async def get_user_answered_questions(self, user_id: int) -> List[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –æ—Ç–≤–µ—Ç–∏–ª (–∏–∑ –≤—Å–µ—Ö —Å–µ—Å—Å–∏–π)

        –í–ö–õ–Æ–ß–ê–ï–¢:
        - –û–±—ã—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–∑ user_answers_new
        - –°–∏—Å—Ç–µ–º–Ω—ã–π –≤–æ–ø—Ä–æ—Å system_context_story –∏–∑ context_stories

        Returns:
            –°–ø–∏—Å–æ–∫ question_json_id
        """
        try:
            async with self.db.get_connection() as conn:
                rows = await conn.fetch("""
                    SELECT DISTINCT ua.question_json_id
                    FROM selfology.user_answers_new ua
                    JOIN selfology.onboarding_sessions s ON ua.session_id = s.id
                    WHERE s.user_id = $1

                    UNION

                    SELECT 'system_context_story' as question_json_id
                    FROM selfology.user_context_stories cs
                    WHERE cs.user_id = $1
                      AND cs.story_type = 'onboarding_context'

                    ORDER BY question_json_id
                """, user_id)

                result = [row['question_json_id'] for row in rows]
                logger.info(f"‚úÖ DEBUG: get_user_answered_questions returned {len(result)} questions, includes system_context_story: {'system_context_story' in result}")
                return result

        except Exception as e:
            logger.error(f"‚ùå Error getting answered questions for user {user_id}: {e}")
            return []

    async def get_user_stats(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            {
                'user_id': int,
                'total_answers_lifetime': int,
                'first_answer_at': datetime,
                'updated_at': datetime
            }
        """

        try:
            async with self.db.get_connection() as conn:
                row = await conn.fetchrow("""
                    SELECT user_id, total_answers_lifetime, first_answer_at, updated_at
                    FROM user_stats
                    WHERE user_id = $1
                """, user_id)

                if row:
                    return dict(row)
                return None

        except Exception as e:
            logger.error(f"‚ùå Error getting user stats for user {user_id}: {e}")
            return None

    async def update_vectorization_status(
        self,
        analysis_id: int,
        status: str,
        error: Optional[str] = None
    ) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è analysis

        Args:
            analysis_id: ID –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
            status: –°—Ç–∞—Ç—É—Å (success, failed, skipped)
            error: –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        """

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE answer_analysis
                    SET vectorization_status = $2,
                        vectorization_error = $3,
                        vectorization_completed_at = NOW()
                    WHERE id = $1
                """, analysis_id, status, error)

                logger.debug(f"‚úÖ Updated vectorization status to '{status}' for analysis {analysis_id}")

        except Exception as e:
            logger.error(f"‚ùå Error updating vectorization status for analysis {analysis_id}: {e}")
            raise

    async def update_dp_update_status(
        self,
        analysis_id: int,
        status: str,
        error: Optional[str] = None
    ) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Digital Personality –¥–ª—è analysis

        Args:
            analysis_id: ID –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
            status: –°—Ç–∞—Ç—É—Å (success, failed, skipped)
            error: –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        """

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE answer_analysis
                    SET dp_update_status = $2,
                        dp_update_error = $3,
                        dp_update_completed_at = NOW()
                    WHERE id = $1
                """, analysis_id, status, error)

                logger.debug(f"‚úÖ Updated DP status to '{status}' for analysis {analysis_id}")

        except Exception as e:
            logger.error(f"‚ùå Error updating DP status for analysis {analysis_id}: {e}")
            raise

    async def mark_background_task_completed(
        self,
        analysis_id: int,
        duration_ms: int,
        success: bool = True
    ) -> None:
        """
        –ü–æ–º–µ—Ç–∏—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ background task –¥–ª—è analysis

        Args:
            analysis_id: ID –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
            duration_ms: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            success: True –µ—Å–ª–∏ task –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ
        """

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE answer_analysis
                    SET background_task_completed = $2,
                        background_task_duration_ms = $3
                    WHERE id = $1
                """, analysis_id, success, duration_ms)

                logger.debug(f"‚úÖ Marked background task completed for analysis {analysis_id} ({duration_ms}ms)")

        except Exception as e:
            logger.error(f"‚ùå Error marking background task completed for analysis {analysis_id}: {e}")
            raise

    async def increment_retry_count(
        self,
        analysis_id: int
    ) -> None:
        """
        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç —Å—á–µ—Ç—á–∏–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è analysis

        Args:
            analysis_id: ID –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
        """

        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE answer_analysis
                    SET retry_count = retry_count + 1,
                        last_retry_at = NOW()
                    WHERE id = $1
                """, analysis_id)

                logger.debug(f"‚úÖ Incremented retry count for analysis {analysis_id}")

        except Exception as e:
            logger.error(f"‚ùå Error incrementing retry count for analysis {analysis_id}: {e}")

    async def get_session_answers(self, session_id: int) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Å–µ—Å—Å–∏–∏ (–¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏)

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–æ–≤
        """
        try:
            async with self.db.get_connection() as conn:
                rows = await conn.fetch("""
                    SELECT
                        ua.id,
                        ua.question_json_id,
                        ua.raw_answer,
                        ua.answered_at,
                        qm.domain,
                        qm.depth_level,
                        qm.energy
                    FROM user_answers_new ua
                    LEFT JOIN questions_metadata qm ON qm.json_id = ua.question_json_id
                    WHERE ua.session_id = $1
                    ORDER BY ua.answered_at ASC
                """, session_id)

                answers = []
                for row in rows:
                    answers.append({
                        'answer_id': row['id'],
                        'question_id': row['question_json_id'],
                        'answer': row['raw_answer'],
                        'answered_at': row['answered_at'].isoformat() if row['answered_at'] else None,
                        'domain': row['domain'],
                        'depth_level': row['depth_level'],
                        'energy': row['energy']
                    })

                logger.debug(f"üìö Retrieved {len(answers)} answers for session {session_id}")
                return answers

        except Exception as e:
            logger.error(f"‚ùå Error getting session answers for session {session_id}: {e}")
            return []

    # ============================================================================
    # CONTEXT STORIES API - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–º–∏ —Ä–∞—Å—Å–∫–∞–∑–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    # ============================================================================

    async def save_context_story(
        self,
        user_id: int,
        session_id: Optional[int],
        story_text: str,
        story_type: str = 'onboarding_intro',
        metadata: Optional[Dict[str, Any]] = None
    ) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            session_id: ID —Å–µ—Å—Å–∏–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å None –¥–ª—è –≤–Ω–µ—Å–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏–π)
            story_text: –¢–µ–∫—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏
            story_type: –¢–∏–ø –∏—Å—Ç–æ—Ä–∏–∏ (onboarding_intro, crisis_context, goal_setting, etc.)
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (tags, sentiment, etc.)

        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∏—Å—Ç–æ—Ä–∏–∏
        """
        try:
            async with self.db.get_connection() as conn:
                story_id = await conn.fetchval("""
                    INSERT INTO user_context_stories (
                        user_id, session_id, story_text,
                        story_type, metadata
                    ) VALUES ($1, $2, $3, $4, $5)
                    RETURNING id
                """,
                    user_id,
                    session_id,
                    story_text,
                    story_type,
                    json.dumps(metadata or {}, ensure_ascii=False)
                )

                logger.info(f"üìñ Saved context story {story_id} for user {user_id} (type: {story_type})")
                return story_id

        except Exception as e:
            logger.error(f"‚ùå Error saving context story for user {user_id}: {e}")
            raise

    async def save_context_story_analysis(
        self,
        context_story_id: int,
        analysis_result: Dict[str, Any]
    ) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å AI –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏

        –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É answer_analysis, –Ω–æ –≤–º–µ—Å—Ç–æ user_answer_id
        –∏—Å–ø–æ–ª—å–∑—É–µ—Ç context_story_id

        Args:
            context_story_id: ID –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ AnswerAnalyzer

        Returns:
            ID —Å–æ–∑–¥–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            processing_meta = analysis_result.get("processing_metadata", {})
            quality_meta = analysis_result.get("quality_metadata", {})
            psychological = analysis_result.get("psychological_analysis", {})
            traits = analysis_result.get("personality_traits", {})
            router_rec = analysis_result.get("router_recommendations", {})

            async with self.db.get_connection() as conn:
                analysis_id = await conn.fetchval("""
                    INSERT INTO answer_analysis (
                        context_story_id, analysis_version, psychological_insights,
                        trait_scores, emotional_state, fatigue_level,
                        next_question_hints, ai_model_used, processing_time_ms,
                        raw_ai_response, debug_priority, quality_score,
                        confidence_score, special_situation, is_milestone
                    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15)
                    RETURNING id
                """,
                    context_story_id,
                    analysis_result.get("analysis_version", "2.0"),
                    json.dumps(psychological.get("insights", {}), ensure_ascii=False),
                    json.dumps(traits, ensure_ascii=False),
                    psychological.get("emotional_assessment", {}).get("primary", "neutral"),
                    quality_meta.get("fatigue_indicators", 0.0),
                    json.dumps(router_rec, ensure_ascii=False),
                    processing_meta.get("model_used", "unknown"),
                    processing_meta.get("processing_time_ms", 0),
                    json.dumps(analysis_result, ensure_ascii=False),
                    1 if processing_meta.get("special_situation") else 0,
                    quality_meta.get("overall_reliability", 0.0),
                    quality_meta.get("data_completeness", 0.0),
                    processing_meta.get("special_situation"),
                    processing_meta.get("special_situation") == "breakthrough"
                )

                logger.info(f"üíæ Saved context story analysis {analysis_id} for story {context_story_id}")
                return analysis_id

        except Exception as e:
            logger.error(f"‚ùå Error saving context story analysis for story {context_story_id}: {e}")
            raise

    async def get_user_context_stories(
        self,
        user_id: int,
        story_type: Optional[str] = None,
        limit: int = 10,
        include_analysis: bool = True
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            story_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∏—Å—Ç–æ—Ä–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            include_analysis: –í–∫–ª—é—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—Ä–∏–π —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        """
        try:
            async with self.db.get_connection() as conn:
                if include_analysis:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—É—é view –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–π —Å –∞–Ω–∞–ª–∏–∑–æ–º
                    if story_type:
                        rows = await conn.fetch("""
                            SELECT * FROM context_stories_with_analysis
                            WHERE user_id = $1 AND story_type = $2
                            ORDER BY created_at DESC
                            LIMIT $3
                        """, user_id, story_type, limit)
                    else:
                        rows = await conn.fetch("""
                            SELECT * FROM context_stories_with_analysis
                            WHERE user_id = $1
                            ORDER BY created_at DESC
                            LIMIT $2
                        """, user_id, limit)
                else:
                    # –¢–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–π
                    if story_type:
                        rows = await conn.fetch("""
                            SELECT id, user_id, session_id, story_text, story_type,
                                   story_source, created_at, metadata
                            FROM user_context_stories
                            WHERE user_id = $1 AND story_type = $2 AND is_active = true
                            ORDER BY created_at DESC
                            LIMIT $3
                        """, user_id, story_type, limit)
                    else:
                        rows = await conn.fetch("""
                            SELECT id, user_id, session_id, story_text, story_type,
                                   story_source, created_at, metadata
                            FROM user_context_stories
                            WHERE user_id = $1 AND is_active = true
                            ORDER BY created_at DESC
                            LIMIT $2
                        """, user_id, limit)

                stories = [dict(row) for row in rows]
                logger.debug(f"üìö Retrieved {len(stories)} context stories for user {user_id}")
                return stories

        except Exception as e:
            logger.error(f"‚ùå Error getting context stories for user {user_id}: {e}")
            return []

    async def search_context_stories(
        self,
        user_id: int,
        search_query: str,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∏—Å—Ç–æ—Ä–∏—è–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            search_query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏–π —Å relevance score
        """
        try:
            async with self.db.get_connection() as conn:
                rows = await conn.fetch("""
                    SELECT * FROM search_user_context_stories($1, $2, $3)
                """, user_id, search_query, limit)

                results = []
                for row in rows:
                    results.append({
                        'story_id': row['story_id'],
                        'story_text': row['story_text'],
                        'story_type': row['story_type'],
                        'created_at': row['created_at'].isoformat() if row['created_at'] else None,
                        'relevance': float(row['relevance'])
                    })

                logger.debug(f"üîç Found {len(results)} stories for query '{search_query}' (user {user_id})")
                return results

        except Exception as e:
            logger.error(f"‚ùå Error searching context stories for user {user_id}: {e}")
            return []

    async def deactivate_context_story(self, story_id: int) -> None:
        """
        –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å (–º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ) –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏

        Args:
            story_id: ID –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏
        """
        try:
            async with self.db.get_connection() as conn:
                await conn.execute("""
                    UPDATE user_context_stories
                    SET is_active = false, updated_at = NOW()
                    WHERE id = $1
                """, story_id)

                logger.info(f"üóëÔ∏è Deactivated context story {story_id}")

        except Exception as e:
            logger.error(f"‚ùå Error deactivating context story {story_id}: {e}")
            raise

    async def get_session_context_story(self, session_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å–µ—Å—Å–∏–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏

        Returns:
            –î–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–ª–∏ None
        """
        try:
            async with self.db.get_connection() as conn:
                row = await conn.fetchrow("""
                    SELECT * FROM context_stories_with_analysis
                    WHERE session_id = $1
                    ORDER BY created_at DESC
                    LIMIT 1
                """, session_id)

                if row:
                    return dict(row)
                return None

        except Exception as e:
            logger.error(f"‚ùå Error getting context story for session {session_id}: {e}")
            return None
