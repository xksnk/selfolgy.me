"""
Embedding Creator - –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è Qdrant

üß¨ –ü–†–ò–ù–¶–ò–ü: –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ embeddings –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á
üìä –ê–†–•–ò–¢–ï–ö–¢–£–†–ê: –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏
‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨: –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Ü–µ–ª–∏
üîç –ü–û–ò–°–ö: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ª–∏—á–Ω–æ—Å—Ç–µ–π
"""

import logging
import json
import asyncio
import hashlib
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import numpy as np

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å Qdrant
try:
    from qdrant_client import QdrantClient
    from qdrant_client.http.models import Distance, VectorParams, PointStruct
    QDRANT_AVAILABLE = True
except ImportError:
    logger.warning("‚ö†Ô∏è qdrant-client not installed, embeddings will be disabled")
    QDRANT_AVAILABLE = False

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI
try:
    from openai import AsyncOpenAI
    from openai import RateLimitError, APIError, APITimeoutError, APIConnectionError
    OPENAI_AVAILABLE = True
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("‚ö†Ô∏è openai not installed, embeddings will be disabled")
    OPENAI_AVAILABLE = False

# Retry –º–µ—Ö–∞–Ω–∏–∑–º
try:
    from tenacity import (
        retry,
        stop_after_attempt,
        wait_exponential,
        retry_if_exception_type,
        before_sleep_log
    )
    TENACITY_AVAILABLE = True
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("‚ö†Ô∏è tenacity not installed, retry mechanism disabled")
    TENACITY_AVAILABLE = False

import os
from .analysis_config import AnalysisConfig

logger = logging.getLogger(__name__)

class EmbeddingCreator:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –ª–∏—á–Ω–æ—Å—Ç–∏ –≤ Qdrant

    –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - Full personality (3072D) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
    - Standard profile (1536D) - –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    - Quick match (512D) - –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
    - Domain facets (256D √ó 5) - –∞—Å–ø–µ–∫—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è creator"""

        self.config = AnalysisConfig()

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è embeddings (–∏–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞)
        self.embedding_configs = {
            "full_personality": {
                "model": "text-embedding-3-large",
                "dimensions": 3072,
                "use_case": "deep_matching",
                "cost_per_1k": 0.00013,
                "collection": "personality_evolution"
            },

            "standard_personality": {
                "model": "text-embedding-3-small",
                "dimensions": 1536,
                "use_case": "daily_operations",
                "cost_per_1k": 0.00002,
                "collection": "personality_profiles"
            },

            "quick_match": {
                "model": "text-embedding-3-small",
                "dimensions": 512,
                "use_case": "real_time_search",
                "cost_per_1k": 0.00002,
                "collection": "quick_match"
            }
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ embeddings
        self.embedding_stats = {
            "vectors_created": 0,
            "vectors_updated": 0,
            "total_cost": 0.0,
            "avg_creation_time_ms": 0,
            "api_calls_success": 0,
            "api_calls_failed": 0,
            "total_tokens_used": 0,
            "cache_hits": 0,
            "cache_misses": 0
        }

        # Semantic cache –¥–ª—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        self._embedding_cache = {}  # {text_hash: {"embedding": [...], "created_at": datetime}}
        self._cache_ttl_hours = 24  # Cache TTL

        # OpenAI client
        self.openai_client = None
        if OPENAI_AVAILABLE:
            try:
                api_key = os.getenv("OPENAI_API_KEY")
                if not api_key:
                    logger.error("‚ùå OPENAI_API_KEY not found in environment")
                    raise ValueError("OPENAI_API_KEY is required for embeddings")

                self.openai_client = AsyncOpenAI(
                    api_key=api_key,
                    timeout=30.0,  # 30 seconds timeout
                    max_retries=0  # We handle retries ourselves with tenacity
                )
                logger.info("‚úÖ OpenAI AsyncClient initialized for embeddings")
            except Exception as e:
                logger.error(f"‚ùå Failed to initialize OpenAI client: {e}")
                self.openai_client = None
        else:
            logger.warning("‚ö†Ô∏è OpenAI client not available - embeddings will use mock")

        # –ö–æ–Ω–Ω–µ–∫—Ü–∏—è –∫ Qdrant
        self.qdrant_client = None
        if QDRANT_AVAILABLE:
            try:
                # –ü–æ–ª—É—á–∞–µ–º URL –∏–∑ environment
                qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")

                # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º URL
                if "qdrant:6333" in qdrant_url:
                    qdrant_url = "http://localhost:6333"
                    logger.info(f"üîß Adjusted Qdrant URL for local run: {qdrant_url}")

                self.qdrant_client = QdrantClient(url=qdrant_url)
                logger.info(f"üìà Connected to Qdrant at {qdrant_url}")
            except Exception as e:
                logger.error(f"‚ùå Failed to connect to Qdrant: {e}")
                self.qdrant_client = None
        else:
            logger.warning("‚ö†Ô∏è Qdrant client not available - embeddings disabled")

        logger.info("üìà EmbeddingCreator initialized with real OpenAI API integration")

    async def create_personality_vector(
        self,
        user_id: int,
        analysis_result: Dict[str, Any],
        is_update: bool = False
    ) -> bool:
        """
        –°–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞
            is_update: True –µ—Å–ª–∏ —ç—Ç–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è

        Returns:
            True –µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä—ã —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã/–æ–±–Ω–æ–≤–ª–µ–Ω—ã
        """

        try:
            logger.info(f"üìà Creating personality vectors for user {user_id}")

            # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º personality summary –¥–ª—è vectorization
            summary_data = analysis_result.get("personality_summary", {})

            if not summary_data:
                logger.error(f"‚ùå No personality summary in analysis result for user {user_id}")
                logger.error(f"üìã Available keys in analysis_result: {list(analysis_result.keys())}")
                logger.error(f"üîç analysis_result structure: {json.dumps({k: type(v).__name__ for k, v in analysis_result.items()}, indent=2)}")
                return False

            # 2. –°–æ–∑–¥–∞–µ–º embeddings —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π
            embeddings = await self._create_multi_level_embeddings(summary_data, user_id)

            if not embeddings:
                logger.error(f"‚ùå Failed to create embeddings for user {user_id}")
                return False

            # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            if is_update:
                success = await self._update_existing_vectors(user_id, embeddings, analysis_result)
            else:
                success = await self._create_new_vectors(user_id, embeddings, analysis_result)

            if success:
                self.embedding_stats["vectors_created" if not is_update else "vectors_updated"] += 1
                logger.info(f"‚úÖ Personality vectors {'updated' if is_update else 'created'} for user {user_id}")

            return success

        except Exception as e:
            logger.error(f"‚ùå Error creating personality vector for user {user_id}: {e}")
            return False

    async def _create_multi_level_embeddings(
        self,
        summary_data: Dict[str, str],
        user_id: int
    ) -> Optional[Dict[str, Any]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ embeddings —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏

        Returns:
            Dict —Å embeddings –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π
        """

        try:
            embeddings = {}

            # 1. Standard embedding –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è (1536D)
            if "narrative" in summary_data:
                standard_embedding = await self._create_openai_embedding(
                    summary_data["narrative"],
                    model="text-embedding-3-small",
                    dimensions=1536
                )
                if standard_embedding:
                    embeddings["standard"] = standard_embedding

            # 2. Quick match embedding –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ (512D)
            if "nano" in summary_data:
                quick_embedding = await self._create_openai_embedding(
                    summary_data["embedding_prompt"] if "embedding_prompt" in summary_data else summary_data["nano"],
                    model="text-embedding-3-small",
                    dimensions=512  # –°–∂–∞—Ç—ã–π —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã API
                )
                if quick_embedding:
                    embeddings["quick"] = quick_embedding

            # 3. Full embedding –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (3072D) - —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤
            if self._should_create_full_embedding(user_id, summary_data):
                full_embedding = await self._create_openai_embedding(
                    summary_data["narrative"] + " " + summary_data.get("structured", ""),
                    model="text-embedding-3-large",
                    dimensions=3072
                )
                if full_embedding:
                    embeddings["full"] = full_embedding

            logger.info(f"üìä Created {len(embeddings)} embedding levels")
            return embeddings if embeddings else None

        except Exception as e:
            logger.error(f"‚ùå Error creating multi-level embeddings: {e}")
            return None

    def _get_cache_key(self, text: str, dimensions: int) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∏ dimensions"""
        # –í–ê–ñ–ù–û: –∫—ç—à –¥–æ–ª–∂–µ–Ω —É—á–∏—Ç—ã–≤–∞—Ç—å dimensions, —Ç.–∫. –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
        combined = f"{text}_{dimensions}"
        return hashlib.sha256(combined.encode('utf-8')).hexdigest()

    def _get_cached_embedding(self, text: str, dimensions: int) -> Optional[List[float]]:
        """–ü–æ–ª—É—á–∏—Ç—å embedding –∏–∑ –∫—ç—à–∞ –µ—Å–ª–∏ –µ—Å—Ç—å"""
        cache_key = self._get_cache_key(text, dimensions)

        if cache_key in self._embedding_cache:
            cached = self._embedding_cache[cache_key]
            created_at = cached["created_at"]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            hours_passed = (datetime.now() - created_at).total_seconds() / 3600
            if hours_passed < self._cache_ttl_hours:
                self.embedding_stats["cache_hits"] += 1
                logger.debug(f"‚úÖ Cache hit for text (dimensions={dimensions}, hash: {cache_key[:8]}...)")
                return cached["embedding"]
            else:
                # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à
                del self._embedding_cache[cache_key]

        self.embedding_stats["cache_misses"] += 1
        return None

    def _cache_embedding(self, text: str, embedding: List[float], dimensions: int):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å embedding –≤ –∫—ç—à"""
        cache_key = self._get_cache_key(text, dimensions)
        self._embedding_cache[cache_key] = {
            "embedding": embedding,
            "created_at": datetime.now()
        }
        logger.debug(f"üíæ Cached embedding (dimensions={dimensions}, hash: {cache_key[:8]}...)")

    async def _create_openai_embedding(
        self,
        text: str,
        model: str = "text-embedding-3-small",
        dimensions: int = 1536
    ) -> Optional[List[float]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ embedding —á–µ—Ä–µ–∑ OpenAI API —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
            model: –ú–æ–¥–µ–ª—å OpenAI (text-embedding-3-small –∏–ª–∏ text-embedding-3-large)
            dimensions: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞

        Returns:
            List[float] —Å –≤–µ–∫—Ç–æ—Ä–æ–º –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not text or not text.strip():
            logger.warning("‚ö†Ô∏è Empty text provided for embedding, skipping")
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ (OpenAI limit: 8191 tokens, ~32K characters)
        if len(text) > 30000:
            logger.warning(f"‚ö†Ô∏è Text too long ({len(text)} chars), truncating to 30000")
            text = text[:30000]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (—É—á–∏—Ç—ã–≤–∞–µ–º dimensions!)
        cached = self._get_cached_embedding(text, dimensions)
        if cached:
            return cached

        # –ï—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º mock
        if not self.openai_client:
            logger.warning("‚ö†Ô∏è OpenAI client not available, using mock embedding")
            return await self._create_mock_embedding(text, dimensions)

        # –í—ã–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π API —Å retry
        try:
            embedding = await self._call_openai_api_with_retry(text, model, dimensions)

            if embedding:
                # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å —É—á–µ—Ç–æ–º dimensions!)
                self._cache_embedding(text, embedding, dimensions)

            return embedding

        except Exception as e:
            logger.error(f"‚ùå Failed to create embedding after all retries: {e}")
            self.embedding_stats["api_calls_failed"] += 1

            # Fallback –Ω–∞ mock –≤ —Å–ª—É—á–∞–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏
            logger.warning("‚ö†Ô∏è Falling back to mock embedding due to API failure")
            return await self._create_mock_embedding(text, dimensions)

    async def _call_openai_api_with_retry(
        self,
        text: str,
        model: str,
        dimensions: int
    ) -> Optional[List[float]]:
        """
        –í—ã–∑–æ–≤ OpenAI API —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º —á–µ—Ä–µ–∑ tenacity

        Retry strategy:
        - 3 –ø–æ–ø—ã—Ç–∫–∏
        - Exponential backoff: 1s, 2s, 4s
        - Retry –Ω–∞ RateLimitError, APIError, Timeout
        """

        if not TENACITY_AVAILABLE:
            # –ï—Å–ª–∏ tenacity –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ - –ø—Ä–æ—Å—Ç–æ–π –≤—ã–∑–æ–≤ –±–µ–∑ retry
            return await self._call_openai_api(text, model, dimensions)

        # –°–æ–∑–¥–∞–µ–º retry decorator
        @retry(
            stop=stop_after_attempt(3),
            wait=wait_exponential(multiplier=1, min=1, max=10),
            retry=retry_if_exception_type((RateLimitError, APIError, APITimeoutError, APIConnectionError)),
            before_sleep=before_sleep_log(logger, logging.WARNING),
            reraise=True
        )
        async def _retry_wrapper():
            return await self._call_openai_api(text, model, dimensions)

        try:
            return await _retry_wrapper()
        except Exception as e:
            logger.error(f"‚ùå All retry attempts exhausted: {e}")
            return None

    async def _call_openai_api(
        self,
        text: str,
        model: str,
        dimensions: int
    ) -> Optional[List[float]]:
        """
        –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ OpenAI Embeddings API
        """

        start_time = datetime.now()

        try:
            logger.debug(f"üîÑ Calling OpenAI API: model={model}, dimensions={dimensions}, text_length={len(text)}")

            # –í—ã–∑—ã–≤–∞–µ–º OpenAI API
            response = await self.openai_client.embeddings.create(
                model=model,
                input=text,
                dimensions=dimensions
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º embedding
            embedding = response.data[0].embedding

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            elapsed_ms = (datetime.now() - start_time).total_seconds() * 1000

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ: 1 token ‚âà 4 characters)
            estimated_tokens = len(text) // 4

            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
            cost_config = self.embedding_configs.get("standard_personality")
            if model == "text-embedding-3-large":
                cost_config = self.embedding_configs.get("full_personality")

            cost_per_1k = cost_config.get("cost_per_1k", 0.00002)
            cost = (estimated_tokens / 1000) * cost_per_1k

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.embedding_stats["api_calls_success"] += 1
            self.embedding_stats["total_cost"] += cost
            self.embedding_stats["total_tokens_used"] += estimated_tokens

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
            total_calls = self.embedding_stats["api_calls_success"]
            current_avg = self.embedding_stats["avg_creation_time_ms"]
            self.embedding_stats["avg_creation_time_ms"] = (
                (current_avg * (total_calls - 1) + elapsed_ms) / total_calls
            )

            logger.info(
                f"‚úÖ OpenAI embedding created: {dimensions}D, "
                f"{elapsed_ms:.0f}ms, "
                f"~{estimated_tokens} tokens, "
                f"${cost:.6f}"
            )

            return embedding

        except RateLimitError as e:
            logger.warning(f"‚ö†Ô∏è OpenAI Rate Limit hit: {e}")
            raise  # –ü—Ä–æ–±—Ä–æ—Å–∏–º –¥–ª—è retry

        except APITimeoutError as e:
            logger.warning(f"‚ö†Ô∏è OpenAI API Timeout: {e}")
            raise  # –ü—Ä–æ–±—Ä–æ—Å–∏–º –¥–ª—è retry

        except APIConnectionError as e:
            logger.warning(f"‚ö†Ô∏è OpenAI Connection Error: {e}")
            raise  # –ü—Ä–æ–±—Ä–æ—Å–∏–º –¥–ª—è retry

        except APIError as e:
            logger.error(f"‚ùå OpenAI API Error: {e}")
            raise  # –ü—Ä–æ–±—Ä–æ—Å–∏–º –¥–ª—è retry

        except Exception as e:
            logger.error(f"‚ùå Unexpected error calling OpenAI API: {e}")
            self.embedding_stats["api_calls_failed"] += 1
            return None

    async def _create_mock_embedding(self, text: str, dimensions: int) -> List[float]:
        """
        FALLBACK: –°–æ–∑–¥–∞–Ω–∏–µ mock embedding (—Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
        """
        logger.debug(f"üé≠ Creating mock embedding: {dimensions}D")

        # –°–∏–º—É–ª—è—Ü–∏—è API call
        await asyncio.sleep(0.05)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞
        # (—á—Ç–æ–±—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–∞–≤–∞–ª –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä)
        seed = hash(text) % (2**32)
        np.random.seed(seed)
        mock_embedding = np.random.random(dimensions).tolist()

        return mock_embedding

    def _should_create_full_embedding(self, user_id: int, summary_data: Dict[str, str]) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω—É–∂–µ–Ω –ª–∏ full embedding (3072D)"""

        # Full embedding –¥–ª—è:
        return any([
            "breakthrough" in summary_data.get("structured", ""),
            "deep_dive" in summary_data.get("narrative", ""),
            user_id % 10 == 0,  # –ö–∞–∂–¥—ã–π 10–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            len(summary_data.get("narrative", "")) > 500  # –î–ª–∏–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        ])

    async def _create_new_vectors(
        self,
        user_id: int,
        embeddings: Dict[str, List[float]],
        analysis_result: Dict[str, Any]
    ) -> bool:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        try:
            current_time = datetime.now().isoformat()

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
            base_payload = {
                "user_id": user_id,
                "created_at": current_time,
                "analysis_version": "2.0",
                "traits": analysis_result["personality_traits"],
                "processing_metadata": analysis_result["processing_metadata"],
                "quality_score": analysis_result["quality_metadata"]["overall_reliability"]
            }

            # 1. Standard profile –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            if "standard" in embeddings:
                await self._store_vector_in_qdrant(
                    collection="personality_profiles",
                    point_id=user_id,
                    vector=embeddings["standard"],
                    payload={
                        **base_payload,
                        "personality_summary": analysis_result["personality_summary"],
                        "vector_type": "standard_profile",
                        "last_updated": current_time
                    }
                )

            # 2. Quick match –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            if "quick" in embeddings:
                await self._store_vector_in_qdrant(
                    collection="quick_match",
                    point_id=user_id,
                    vector=embeddings["quick"],
                    payload={
                        **base_payload,
                        "nano_summary": analysis_result["personality_summary"]["nano"],
                        "vector_type": "quick_match",
                        "archetype": self._extract_archetype(analysis_result)
                    }
                )

            # 3. Full embedding –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ (–µ—Å–ª–∏ —Å–æ–∑–¥–∞–Ω)
            if "full" in embeddings:
                # ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å integer –∏–ª–∏ UUID - –∏—Å–ø–æ–ª—å–∑—É–µ–º timestamp –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                evolution_id = int(datetime.now().timestamp() * 1000)  # milliseconds
                await self._store_vector_in_qdrant(
                    collection="personality_evolution",
                    point_id=evolution_id,
                    vector=embeddings["full"],
                    payload={
                        **base_payload,
                        "user_id": user_id,  # –í–∞–∂–Ω–æ! ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                        "snapshot_id": evolution_id,
                        "full_narrative": analysis_result["personality_summary"]["narrative"],
                        "vector_type": "evolution_snapshot",
                        "is_milestone": analysis_result["processing_metadata"].get("special_situation") == "breakthrough"
                    }
                )

            return True

        except Exception as e:
            logger.error(f"‚ùå Error creating new vectors for user {user_id}: {e}")
            return False

    async def _update_existing_vectors(
        self,
        user_id: int,
        embeddings: Dict[str, List[float]],
        analysis_result: Dict[str, Any]
    ) -> bool:
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏
        """

        try:
            logger.info(f"üîÑ Updating existing vectors for user {user_id}")

            # 1. –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
            current_profile = await self._get_current_profile(user_id)

            # 2. –í—ã—á–∏—Å–ª—è–µ–º –¥–µ–ª—å—Ç—É –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if current_profile:
                delta = self._calculate_personality_delta(current_profile, analysis_result)
                logger.info(f"üìä Personality delta magnitude: {delta.get('magnitude', 0):.3f}")
            else:
                delta = {"magnitude": 1.0, "significant_changes": [], "first_profile": True}

            # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            if delta["magnitude"] > 0.3:
                # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ breakthrough
                await self._save_breakthrough_moment(user_id, current_profile, analysis_result, embeddings)
                update_strategy = "breakthrough_merge"
            elif delta["magnitude"] > 0.1:
                # –°—Ä–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ
                update_strategy = "adaptive_merge"
            else:
                # –ú–∞–ª—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è - –ø—Ä–æ—Å—Ç–æ–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
                update_strategy = "weighted_average"

            # 4. –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            success = await self._apply_update_strategy(
                user_id, embeddings, analysis_result, current_profile, update_strategy, delta
            )

            return success

        except Exception as e:
            logger.error(f"‚ùå Error updating vectors for user {user_id}: {e}")
            return False

    def _calculate_personality_delta(self, current_profile: Dict, new_analysis: Dict) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ª–∏—á–Ω–æ—Å—Ç–∏"""

        try:
            current_traits = current_profile.get("traits", {}).get("big_five", {})
            new_traits = new_analysis.get("personality_traits", {}).get("big_five", {})

            if not current_traits or not new_traits:
                return {"magnitude": 1.0, "first_profile": True}

            # –°—á–∏—Ç–∞–µ–º –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏ —á–µ—Ä—Ç
            trait_differences = []
            significant_changes = []

            for trait in self.config.BIG_FIVE_TRAITS:
                # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è - –º–æ–≥—É—Ç –±—ã—Ç—å float –∏–ª–∏ dict —Å "score"
                old_raw = current_traits.get(trait, 0.5)
                new_raw = new_traits.get(trait, 0.5)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º score –µ—Å–ª–∏ —ç—Ç–æ dict
                old_value = old_raw.get("score", 0.5) if isinstance(old_raw, dict) else old_raw
                new_value = new_raw.get("score", 0.5) if isinstance(new_raw, dict) else new_raw

                diff = abs(new_value - old_value)

                trait_differences.append(diff)

                # –ó–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–±–æ–ª—å—à–µ 0.1)
                if diff > 0.1:
                    direction = "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ" if new_value > old_value else "—Å–Ω–∏–∂–µ–Ω–∏–µ"
                    significant_changes.append({
                        "trait": trait,
                        "change": diff,
                        "direction": direction,
                        "old_value": old_value,
                        "new_value": new_value
                    })

            magnitude = np.sqrt(sum(d**2 for d in trait_differences)) / len(trait_differences)

            return {
                "magnitude": magnitude,
                "significant_changes": significant_changes,
                "trait_differences": trait_differences,
                "is_breakthrough": magnitude > 0.3,
                "is_evolution": 0.1 < magnitude <= 0.3,
                "is_minor_update": magnitude <= 0.1
            }

        except Exception as e:
            logger.error(f"‚ùå Error calculating personality delta: {e}")
            return {"magnitude": 0.0, "error": str(e)}

    async def _save_breakthrough_moment(
        self,
        user_id: int,
        current_profile: Optional[Dict],
        analysis_result: Dict[str, Any],
        embeddings: Dict[str, List[float]]
    ) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–º–µ–Ω—Ç –ø—Ä–æ—Ä—ã–≤–∞ –≤ personality_evolution –∫–æ–ª–ª–µ–∫—Ü–∏—é

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_profile: –¢–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å (–¥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            embeddings: –°–æ–∑–¥–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
        """
        try:
            logger.info(f"üåü Saving breakthrough moment for user {user_id}")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º timestamp –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è snapshot
            breakthrough_id = int(datetime.now().timestamp() * 1000)  # milliseconds

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –≤–µ–∫—Ç–æ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è breakthrough
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º standard –≤–µ–∫—Ç–æ—Ä (1536D) –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–≤–æ–ª—é—Ü–∏–∏ –ª–∏—á–Ω–æ—Å—Ç–∏
            vector_to_save = embeddings.get("standard")

            if not vector_to_save:
                logger.warning(f"‚ö†Ô∏è No standard (1536D) vector available - cannot save breakthrough moment")
                return False

            # –§–æ—Ä–º–∏—Ä—É–µ–º payload —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ—Ä—ã–≤–µ
            payload = {
                "user_id": user_id,
                "created_at": datetime.now().isoformat(),
                "snapshot_id": breakthrough_id,
                "vector_type": "breakthrough_snapshot",
                "is_milestone": True,

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ä—ã–≤–µ
                "breakthrough_info": {
                    "magnitude": analysis_result.get("personality_traits", {}).get("magnitude", 0.3),
                    "significant_changes": analysis_result.get("personality_traits", {}).get("significant_changes", []),
                    "trigger_question": analysis_result.get("processing_metadata", {}).get("question_number"),
                    "trigger_domain": analysis_result.get("processing_metadata", {}).get("question_domain")
                },

                # Snapshot –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–∞ –º–æ–º–µ–Ω—Ç –ø—Ä–æ—Ä—ã–≤–∞
                "personality_snapshot": {
                    "big_five": analysis_result.get("personality_traits", {}).get("big_five", {}),
                    "dynamic_traits": analysis_result.get("personality_traits", {}).get("dynamic_traits", {}),
                    "narrative": analysis_result.get("personality_summary", {}).get("narrative", "")
                },

                # –ü—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                "previous_state": current_profile.get("traits", {}).get("big_five", {}) if current_profile else None
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Qdrant
            success = await self._store_vector_in_qdrant(
                collection="personality_evolution",
                point_id=breakthrough_id,
                vector=vector_to_save,
                payload=payload
            )

            if success:
                logger.info(f"‚úÖ Breakthrough moment saved with ID {breakthrough_id}")
            else:
                logger.error(f"‚ùå Failed to save breakthrough moment")

            return success

        except Exception as e:
            logger.error(f"‚ùå Error saving breakthrough moment for user {user_id}: {e}")
            return False

    async def _apply_update_strategy(
        self,
        user_id: int,
        embeddings: Dict[str, List[float]],
        analysis_result: Dict[str, Any],
        current_profile: Optional[Dict],
        strategy: str,
        delta: Dict[str, Any]
    ) -> bool:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤"""

        try:
            current_time = datetime.now().isoformat()

            if strategy == "weighted_average":
                # –ü—Ä–æ—Å—Ç–æ–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –º–∞–ª—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
                if current_profile and "standard" in embeddings:
                    # –°–º–µ—à–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –∏ –Ω–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä—ã (80% —Å—Ç–∞—Ä—ã–π, 20% –Ω–æ–≤—ã–π)
                    old_vector = current_profile.get("vector", [])
                    new_vector = embeddings["standard"]

                    if len(old_vector) == len(new_vector):
                        merged_vector = [
                            0.8 * old + 0.2 * new
                            for old, new in zip(old_vector, new_vector)
                        ]
                        embeddings["standard"] = merged_vector
                        logger.info(f"üîÑ Applied weighted average update")

            elif strategy == "adaptive_merge":
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ —Å —É—á–µ—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                confidence = analysis_result["quality_metadata"]["overall_reliability"]
                merge_weight = min(0.5, confidence * 0.6)  # –ú–∞–∫—Å–∏–º—É–º 50% –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ–≥–æ

                logger.info(f"üéØ Applied adaptive merge with weight {merge_weight:.2f}")

            elif strategy == "breakthrough_merge":
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–º–µ–Ω—Ç –ø—Ä–æ—Ä—ã–≤–∞
                logger.info(f"üåü Applied breakthrough merge - milestone saved")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
            success = await self._save_updated_vectors(
                user_id, embeddings, analysis_result, current_time, strategy, delta
            )

            return success

        except Exception as e:
            logger.error(f"‚ùå Error applying update strategy {strategy}: {e}")
            return False

    async def _save_updated_vectors(
        self,
        user_id: int,
        embeddings: Dict[str, List[float]],
        analysis_result: Dict[str, Any],
        timestamp: str,
        strategy: str,
        delta: Dict[str, Any]
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ Qdrant"""

        try:
            # –û–±—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            base_payload = {
                "user_id": user_id,
                "updated_at": timestamp,
                "update_strategy": strategy,
                "personality_delta": delta,
                "analysis_version": "2.0",
                "traits": analysis_result["personality_traits"],
                "summary": analysis_result["personality_summary"],
                "quality_score": analysis_result["quality_metadata"]["overall_reliability"]
            }

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –≤–µ–∫—Ç–æ—Ä–∞
            updates_successful = []

            # Standard profile
            if "standard" in embeddings:
                success = await self._store_vector_in_qdrant(
                    collection="personality_profiles",
                    point_id=user_id,
                    vector=embeddings["standard"],
                    payload={**base_payload, "vector_type": "current_profile"}
                )
                updates_successful.append(success)

            # Quick match
            if "quick" in embeddings:
                success = await self._store_vector_in_qdrant(
                    collection="quick_match",
                    point_id=user_id,
                    vector=embeddings["quick"],
                    payload={
                        **base_payload,
                        "vector_type": "quick_search",
                        "archetype": self._extract_archetype(analysis_result),
                        "primary_domain": analysis_result["processing_metadata"]["question_domain"]
                    }
                )
                updates_successful.append(success)

            # Evolution snapshot (–≤—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π)
            if "standard" in embeddings:
                # ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å integer –∏–ª–∏ UUID - –∏—Å–ø–æ–ª—å–∑—É–µ–º timestamp –∫–∞–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                evolution_id = int(datetime.now().timestamp() * 1000)  # milliseconds
                success = await self._store_vector_in_qdrant(
                    collection="personality_evolution",
                    point_id=evolution_id,
                    vector=embeddings["standard"],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º standard –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
                    payload={
                        **base_payload,
                        "user_id": user_id,  # –í–∞–∂–Ω–æ! ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
                        "snapshot_id": evolution_id,
                        "vector_type": "evolution_point",
                        "delta_magnitude": delta["magnitude"],
                        "significant_changes": delta["significant_changes"]
                    }
                )
                updates_successful.append(success)

            return all(updates_successful)

        except Exception as e:
            logger.error(f"‚ùå Error saving updated vectors: {e}")
            return False

    async def _store_vector_in_qdrant(
        self,
        collection: str,
        point_id: Any,
        vector: List[float],
        payload: Dict[str, Any]
    ) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –≤ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        """

        try:
            if not self.qdrant_client:
                logger.error(f"‚ùå Qdrant client not available - cannot store vector")
                return False

            # –†–µ–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant
            self.qdrant_client.upsert(
                collection_name=collection,
                points=[
                    PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                ]
            )

            logger.info(f"üíæ Vector stored in {collection} (ID: {point_id}, dims: {len(vector)})")
            return True

        except Exception as e:
            logger.error(f"‚ùå Error storing vector in {collection}: {e}")
            return False

    async def _get_current_profile(self, user_id: int) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ Qdrant"""

        try:
            # MOCK –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ:
            # result = await self.qdrant_client.retrieve(
            #     collection_name="personality_profiles",
            #     ids=[user_id]
            # )
            # return result[0].payload if result else None

            # –°–∏–º—É–ª—è—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            return None

        except Exception as e:
            logger.error(f"‚ùå Error getting current profile for user {user_id}: {e}")
            return None

    async def search_similar_personalities(
        self,
        user_id: int,
        limit: int = 10,
        similarity_threshold: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ª–∏—á–Ω–æ—Å—Ç–µ–π

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º —Å—Ö–æ–∂–µ—Å—Ç–∏
        """

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_profile = await self._get_current_profile(user_id)

            if not user_profile:
                logger.warning(f"‚ö†Ô∏è No profile found for user {user_id}")
                return []

            # MOCK –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Qdrant:
            # search_result = await self.qdrant_client.search(
            #     collection_name="quick_match",
            #     query_vector=user_profile["vector"],
            #     limit=limit,
            #     score_threshold=similarity_threshold
            # )

            # –°–∏–º—É–ª—è—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            mock_results = [
                {
                    "user_id": f"user_{i}",
                    "similarity_score": 0.85 - i * 0.05,
                    "archetype": "–ü–æ—Ö–æ–∂–∏–π –¢–∏–ø",
                    "shared_traits": ["openness", "creativity"],
                    "explanation": f"–°—Ö–æ–∂–µ—Å—Ç—å –≤ —Ç–≤–æ—Ä—á–µ—Å–∫–æ–º –ø–æ–¥—Ö–æ–¥–µ –∏ –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç–∏ –Ω–æ–≤–æ–º—É"
                }
                for i in range(min(3, limit))  # –ú–æ–∫ 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            ]

            logger.info(f"üîç Found {len(mock_results)} similar personalities for user {user_id}")
            return mock_results

        except Exception as e:
            logger.error(f"‚ùå Error searching similar personalities: {e}")
            return []

    async def setup_qdrant_collections(self) -> bool:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–π Qdrant –¥–ª—è –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        """

        if not self.qdrant_client:
            logger.error("‚ùå Qdrant client not initialized - cannot create collections")
            return False

        try:
            logger.info("üèóÔ∏è Setting up Qdrant collections...")

            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–µ–Ω–∞ –∏–∑ embedding_configs
            collections_config = [
                {
                    "name": "quick_match",  # self.embedding_configs["quick_match"]["collection"]
                    "size": 512,
                    "distance": Distance.COSINE,
                    "description": "Quick matching and filtering"
                },
                {
                    "name": "personality_profiles",  # self.embedding_configs["standard_personality"]["collection"]
                    "size": 1536,
                    "distance": Distance.COSINE,
                    "description": "Main personality profiles"
                },
                {
                    "name": "personality_evolution",
                    "size": 1536,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º standard –≤–µ–∫—Ç–æ—Ä –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–≤–æ–ª—é—Ü–∏–∏
                    "distance": Distance.COSINE,
                    "description": "Personality evolution tracking and breakthrough moments"
                }
            ]

            created_count = 0
            for config in collections_config:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                    existing_collections = self.qdrant_client.get_collections()
                    collection_names = [c.name for c in existing_collections.collections]

                    if config["name"] in collection_names:
                        logger.info(f"‚úÖ Collection '{config['name']}' already exists")
                        created_count += 1
                        continue

                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
                    self.qdrant_client.create_collection(
                        collection_name=config["name"],
                        vectors_config=VectorParams(
                            size=config["size"],
                            distance=config["distance"]
                        )
                    )
                    logger.info(f"‚úÖ Created collection '{config['name']}' ({config['description']})")
                    created_count += 1

                except Exception as e:
                    logger.error(f"‚ùå Failed to create collection '{config['name']}': {e}")
                    # –ù–ï –ø–æ–¥–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É - –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–ª—å—à–µ
                    raise

            success = created_count == len(collections_config)
            if success:
                logger.info(f"üéâ Successfully initialized {created_count} Qdrant collections")
            else:
                logger.warning(f"‚ö†Ô∏è Only {created_count}/{len(collections_config)} collections created")

            return success

        except Exception as e:
            logger.error(f"‚ùå Error setting up Qdrant collections: {e}")
            return False

    def _extract_archetype(self, analysis_result: Dict[str, Any]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ä—Ö–µ—Ç–∏–ø–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞"""

        summary = analysis_result.get("personality_summary", {})
        structured = summary.get("structured", "")

        # –ò—â–µ–º –∞—Ä—Ö–µ—Ç–∏–ø –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–æ—Ñ–∏–ª–µ
        if "archetype" in structured:
            try:
                structured_data = json.loads(structured)
                return structured_data.get("archetype", "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –¢–∏–ø")
            except:
                pass

        # Fallback –∏–∑ traits
        traits = analysis_result.get("personality_traits", {}).get("big_five", {})
        if traits:
            # –ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞—Ä—Ö–µ—Ç–∏–ø–∞
            if traits.get("openness", 0) > 0.7:
                return "–¢–≤–æ—Ä—á–µ—Å–∫–∏–π –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å"
            elif traits.get("conscientiousness", 0) > 0.7:
                return "–û—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã–π –î–µ—è—Ç–µ–ª—å"
            elif traits.get("extraversion", 0) > 0.7:
                return "–°–æ—Ü–∏–∞–ª—å–Ω—ã–π –ö–æ–º–º—É–Ω–∏–∫–∞—Ç–æ—Ä"
            elif traits.get("agreeableness", 0) > 0.7:
                return "–≠–º–ø–∞—Ç–∏—á–Ω—ã–π –ü–æ–º–æ—â–Ω–∏–∫"
            else:
                return "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –õ–∏—á–Ω–æ—Å—Ç—å"

        return "–†–∞–∑–≤–∏–≤–∞—é—â–∞—è—Å—è –õ–∏—á–Ω–æ—Å—Ç—å"

    async def get_embedding_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤"""

        total_calls = self.embedding_stats["api_calls_success"] + self.embedding_stats["api_calls_failed"]

        return {
            **self.embedding_stats,
            "collections_status": await self._get_collections_status(),
            "cost_per_vector": (
                self.embedding_stats["total_cost"] / max(1, self.embedding_stats["vectors_created"])
            ),
            "efficiency_metrics": {
                "success_rate": (
                    self.embedding_stats["api_calls_success"] / max(1, total_calls)
                ) * 100,
                "cache_hit_rate": (
                    self.embedding_stats["cache_hits"] /
                    max(1, self.embedding_stats["cache_hits"] + self.embedding_stats["cache_misses"])
                ) * 100,
                "avg_cost_per_call": (
                    self.embedding_stats["total_cost"] / max(1, self.embedding_stats["api_calls_success"])
                ),
                "total_api_calls": total_calls
            }
        }

    async def _get_collections_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∫–æ–ª–ª–µ–∫—Ü–∏–π Qdrant"""

        # MOCK –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
        return {
            "personality_profiles": {"count": 0, "size": "1536D"},
            "quick_match": {"count": 0, "size": "512D"},
            "personality_evolution": {"count": 0, "size": "1536D"}
        }
