"""
AI Model Router - –£–º–Ω—ã–π –≤—ã–±–æ—Ä AI –º–æ–¥–µ–ª–∏

üß† –ü–†–ò–ù–¶–ò–ü: "–í—ã–±–∏—Ä–∞–µ–º AI –∫–∞–∫ –≤—ã–±–∏—Ä–∞–µ–º –ø—Å–∏—Ö–æ–ª–æ–≥–∞ - –ø–æ–¥ –∑–∞–¥–∞—á—É –∏ –º–æ–º–µ–Ω—Ç"
üí∞ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–ø–ª–∞–Ω: Claude 10%, GPT-4o 75%, Mini 15%)  
üéØ –ê–î–ê–ü–¢–ò–í–ù–û–°–¢–¨: –ú–∞—Ç—Ä–∏—Ü–∞ "–ì–ª—É–±–∏–Ω–∞ √ó –í–∞–∂–Ω–æ—Å—Ç—å √ó –ö–æ–Ω—Ç–µ–∫—Å—Ç"
"""

import logging
from typing import Dict, Any, Optional, Tuple
from datetime import datetime
import asyncio

from .analysis_config import AnalysisConfig

logger = logging.getLogger(__name__)

class AIModelRouter:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä AI –º–æ–¥–µ–ª–µ–π
    
    –í—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - –°–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞
    - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏ –º–æ–º–µ–Ω—Ç–∞  
    - –ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–µ—Å—Å–∏–∏
    - –ë—é–¥–∂–µ—Ç–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–æ—É—Ç–µ—Ä–∞"""
        self.config = AnalysisConfig()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.usage_stats = {
            "claude-3.5-sonnet": {"requests": 0, "total_cost": 0.0, "avg_quality": 0.0},
            "gpt-4o": {"requests": 0, "total_cost": 0.0, "avg_quality": 0.0},
            "gpt-4o-mini": {"requests": 0, "total_cost": 0.0, "avg_quality": 0.0}
        }
        
        # –î–Ω–µ–≤–Ω–æ–π –±—é–¥–∂–µ—Ç tracker
        self.daily_spending = 0.0
        self.daily_budget = self.config.COST_CONTROL["daily_budget_per_user_usd"]
        
        logger.info("ü§ñ AIModelRouter initialized with smart selection matrix")
    
    async def select_model_for_analysis(
        self, 
        question_metadata: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Tuple[str, Dict[str, Any]]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
        
        Args:
            question_metadata: –ü–æ–ª–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ (17 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–µ—Å—Å–∏–∏
            
        Returns:
            Tuple[model_name, model_config] 
        """
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—é–¥–∂–µ—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            budget_constraint = self._check_budget_constraints()
            
            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞
            if recommended_model := self._get_metadata_recommendation(question_metadata):
                if self._can_afford_model(recommended_model, budget_constraint):
                    logger.info(f"üéØ Using metadata recommendation: {recommended_model}")
                    return self._get_model_config(recommended_model, "metadata_recommended")
            
            # 3. –°—á–∏—Ç–∞–µ–º –æ—Ü–µ–Ω–∫—É –≤–∞–∂–Ω–æ—Å—Ç–∏ –º–æ–º–µ–Ω—Ç–∞
            moment_score = self._calculate_moment_score(question_metadata, context)
            
            # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –¥–ª—è Claude
            if self._should_use_claude(question_metadata, context, moment_score, budget_constraint):
                logger.info(f"üß† Selecting Claude for critical moment (score: {moment_score:.2f})")
                return self._get_model_config("claude-3.5-sonnet", "critical_analysis")
            
            # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è GPT-4o  
            if self._should_use_gpt4o(question_metadata, context, moment_score):
                logger.info(f"üé≠ Selecting GPT-4o for standard analysis (score: {moment_score:.2f})")
                return self._get_model_config("gpt-4o", "standard_analysis")
            
            # 6. Fallback –Ω–∞ GPT-4o-mini
            logger.info(f"‚ö° Selecting GPT-4o-mini for simple task (score: {moment_score:.2f})")
            return self._get_model_config("gpt-4o-mini", "simple_classification")
            
        except Exception as e:
            logger.error(f"‚ùå Error in model selection: {e}")
            # Emergency fallback
            return self._get_model_config("gpt-4o-mini", "error_fallback")
    
    def _calculate_moment_score(self, question_metadata: Dict, context: Dict) -> float:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –º–æ–º–µ–Ω—Ç–∞ –ø–æ –º–∞—Ç—Ä–∏—Ü–µ "–ì–ª—É–±–∏–Ω–∞ √ó –í–∞–∂–Ω–æ—Å—Ç—å √ó –ö–æ–Ω—Ç–µ–∫—Å—Ç"
        
        Returns:
            –û—Ü–µ–Ω–∫–∞ –æ—Ç 0 –¥–æ 5 (—á–µ–º –≤—ã—à–µ, —Ç–µ–º –≤–∞–∂–Ω–µ–µ –º–æ–º–µ–Ω—Ç)
        """
        
        psychology = question_metadata.get("psychology", {})
        classification = question_metadata.get("classification", {})
        
        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–∫–∞–∂–¥—ã–π –æ—Ç 0 –¥–æ 1)
        emotional_weight = psychology.get("emotional_weight", 1) / 5.0  
        insight_potential = psychology.get("insight_potential", 1) / 5.0
        complexity = psychology.get("complexity", 1) / 5.0
        safety_level = psychology.get("safety_level", 5) / 5.0
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        trust_level = context.get("trust_level", 0.5) 
        question_number = context.get("question_number", 1)
        engagement = context.get("engagement_level", 0.5)
        
        # –§–æ—Ä–º—É–ª–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ (—Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É)
        base_score = (
            emotional_weight * 0.25 +      # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
            insight_potential * 0.25 +     # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –ø—Ä–æ—Ä—ã–≤–∞  
            trust_level * 0.20 +           # –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è
            complexity * 0.15 +            # –°–ª–æ–∂–Ω–æ—Å—Ç—å
            (1.0 - safety_level) * 0.15   # –î–µ–ª–∏–∫–∞—Ç–Ω–æ—Å—Ç—å —Ç–µ–º—ã (–∏–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)
        )
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –±–æ–Ω—É—Å—ã
        context_bonus = 0.0
        
        # –í–µ—Ö–∏ –ø—É—Ç–∏ (25, 50, 75, 100 –≤–æ–ø—Ä–æ—Å–æ–≤)
        if question_number in [25, 50, 75, 100]:
            context_bonus += 0.5
            
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ—Ä—ã–≤–∞
        if context.get("is_breakthrough", False):
            context_bonus += 1.0
            
        # –í—ã—Å–æ–∫–æ–µ –≤–æ–≤–ª–µ—á–µ–Ω–∏–µ
        if engagement > 0.8:
            context_bonus += 0.3
            
        # –î–µ–ª–∏–∫–∞—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
        if classification.get("domain") in ["SPIRITUALITY", "IDENTITY", "EMOTIONS"]:
            context_bonus += 0.2
            
        # –ì–ª—É–±–æ–∫–∏–µ —É—Ä–æ–≤–Ω–∏
        if classification.get("depth_level") in ["SHADOW", "CORE"]:
            context_bonus += 0.4
        
        final_score = min(5.0, (base_score * 5.0) + context_bonus)  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —à–∫–∞–ª–µ 0-5
        
        logger.debug(f"üìä Moment score: {final_score:.2f} (base: {base_score:.2f}, bonus: {context_bonus:.2f})")
        return final_score
    
    def _should_use_claude(
        self, 
        question_metadata: Dict, 
        context: Dict, 
        moment_score: float,
        budget_constraint: str
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω—É–∂–µ–Ω –ª–∏ Claude –¥–ª—è —ç—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –ë—é–¥–∂–µ—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        if budget_constraint == "emergency":
            return False
        elif budget_constraint == "restricted" and moment_score < 4.5:
            return False
        
        # –ü—Ä—è–º—ã–µ —É–∫–∞–∑–∞–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Claude
        thresholds = self.config.COMPLEXITY_THRESHOLDS["use_claude_if"]
        
        return any([
            moment_score >= thresholds["complexity_score"],
            context.get("is_breakthrough", False),
            question_metadata["classification"]["depth_level"] in thresholds["depth_level"],
            question_metadata["classification"]["domain"] in thresholds["domain"],
            question_metadata["classification"]["energy_dynamic"] in thresholds["energy_dynamic"],
            self._detect_crisis_indicators(context.get("user_answer", "")),
            context.get("question_number", 0) in [25, 50, 75, 100]  # –í–∞–∂–Ω—ã–µ –≤–µ—Ö–∏
        ])
    
    def _should_use_gpt4o(self, question_metadata: Dict, context: Dict, moment_score: float) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ GPT-4o"""
        
        thresholds = self.config.COMPLEXITY_THRESHOLDS["use_gpt4_if"]
        
        return (
            moment_score >= thresholds["complexity_score"] and
            (context.get("answer_length", 0) >= thresholds["answer_length"] or
             context.get("user_engagement", 0) >= thresholds["user_engagement"])
        )
    
    def _get_metadata_recommendation(self, question_metadata: Dict) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞"""
        
        return question_metadata.get("processing_hints", {}).get("recommended_model")
    
    def _check_budget_constraints(self) -> str:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±—é–¥–∂–µ—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        
        Returns:
            "normal" | "restricted" | "emergency"
        """
        
        budget_used_percent = (self.daily_spending / self.daily_budget) * 100
        
        if budget_used_percent >= 95:
            return "emergency"
        elif budget_used_percent >= 80: 
            return "restricted"
        else:
            return "normal"
    
    def _can_afford_model(self, model: str, budget_constraint: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–∂–µ–º –ª–∏ –ø–æ–∑–≤–æ–ª–∏—Ç—å —Å–µ–±–µ —ç—Ç—É –º–æ–¥–µ–ª—å"""
        
        if budget_constraint == "normal":
            return True
        elif budget_constraint == "restricted":
            return model != "claude-3.5-sonnet"  # –¢–æ–ª—å–∫–æ GPT –º–æ–¥–µ–ª–∏
        else:  # emergency
            return model == "gpt-4o-mini"  # –¢–æ–ª—å–∫–æ —Å–∞–º–∞—è –¥–µ—à–µ–≤–∞—è
    
    def _get_model_config(self, model_name: str, usage_type: str) -> Tuple[str, Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            usage_type: –¢–∏–ø –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            
        Returns:
            Tuple[model_name, config]
        """
        
        base_config = self.config.AI_MODEL_SETTINGS[model_name].copy()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–¥ —Ç–∏–ø –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        if usage_type == "critical_analysis":
            base_config["temperature"] = 0.1  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            base_config["max_tokens"] = 1000
            
        elif usage_type == "standard_analysis":  
            base_config["temperature"] = 0.3  # –ë–∞–ª–∞–Ω—Å
            base_config["max_tokens"] = 600
            
        elif usage_type == "simple_classification":
            base_config["temperature"] = 0.2  # –ù–∏–∑–∫–∞—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            base_config["max_tokens"] = 300
            
        elif usage_type == "error_fallback":
            base_config["temperature"] = 0.4  # –í—ã—Å–æ–∫–∞—è –¥–ª—è creativity –≤ –∫—Ä–∏–∑–∏—Å–µ
            base_config["max_tokens"] = 200
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        base_config.update({
            "selected_for": usage_type,
            "selected_at": datetime.now().isoformat(),
            "budget_mode": self._check_budget_constraints()
        })
        
        return model_name, base_config
    
    def _detect_crisis_indicators(self, user_answer: str) -> bool:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∫—Ä–∏–∑–∏—Å–Ω—ã–µ —Å–ª–æ–≤–∞ –≤ –æ—Ç–≤–µ—Ç–µ"""
        
        crisis_keywords = self.config.SAFETY_RULES["crisis_keywords"]
        answer_lower = user_answer.lower()
        
        return any(keyword in answer_lower for keyword in crisis_keywords)
    
    async def get_fallback_model(self, primary_model: str, error: Exception) -> Tuple[str, Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å fallback –º–æ–¥–µ–ª—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        Args:
            primary_model: –ú–æ–¥–µ–ª—å –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
            error: –¢–∏–ø –æ—à–∏–±–∫–∏
            
        Returns:
            Fallback –º–æ–¥–µ–ª—å –∏ –∫–æ–Ω—Ñ–∏–≥
        """
        
        fallback_chain = {
            "claude-3.5-sonnet": {
                "fallback": "gpt-4o",
                "enrichment": "add_extra_context"
            },
            "gpt-4o": {
                "fallback": "gpt-4o-mini", 
                "enrichment": "simplified_analysis"
            },
            "gpt-4o-mini": {
                "fallback": "rule_based",
                "enrichment": "basic_only"
            }
        }
        
        if primary_model in fallback_chain:
            fallback_info = fallback_chain[primary_model]
            fallback_model = fallback_info["fallback"]
            
            logger.warning(f"‚ö†Ô∏è Fallback: {primary_model} ‚Üí {fallback_model} (error: {type(error).__name__})")
            
            if fallback_model == "rule_based":
                return await self._get_rule_based_config()
            else:
                return self._get_model_config(fallback_model, "fallback")
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
        logger.error(f"‚ùå No fallback available for {primary_model}")
        return await self._get_rule_based_config()
    
    async def _get_rule_based_config(self) -> Tuple[str, Dict[str, Any]]:
        """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ AI –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π"""
        
        return "rule_based", {
            "approach": "simple_heuristics",
            "capabilities": ["emotion_keywords", "length_analysis", "basic_classification"],
            "quality_level": "basic",
            "cost": 0.0
        }
    
    def track_usage(self, model: str, cost: float, quality_score: float, response_time_ms: int):
        """
        –û—Ç—Å–ª–µ–¥–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            model: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            cost: –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞  
            quality_score: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (0-1)
            response_time_ms: –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
        """
        
        if model in self.usage_stats:
            stats = self.usage_stats[model]
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            old_requests = stats["requests"]
            stats["requests"] += 1
            stats["total_cost"] += cost
            
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–∞
            if old_requests > 0:
                stats["avg_quality"] = (
                    (stats["avg_quality"] * old_requests + quality_score) / 
                    (old_requests + 1)
                )
            else:
                stats["avg_quality"] = quality_score
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–Ω–µ–≤–Ω–æ–π –±—é–¥–∂–µ—Ç
            self.daily_spending += cost
            
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è cost tracking
            logger.info(
                f"üí∞ Model usage: {model}, cost: ${cost:.4f}, "
                f"quality: {quality_score:.2f}, time: {response_time_ms}ms"
            )
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –±—é–¥–∂–µ—Ç–µ
            budget_used = (self.daily_spending / self.daily_budget) * 100
            if budget_used > 80:
                logger.warning(f"üí∏ Budget alert: {budget_used:.1f}% used today")
    
    def get_usage_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π"""
        
        total_requests = sum(stats["requests"] for stats in self.usage_stats.values())
        total_cost = sum(stats["total_cost"] for stats in self.usage_stats.values())
        
        if total_requests == 0:
            return {"message": "No requests processed yet"}
        
        report = {
            "total_requests": total_requests,
            "total_cost": total_cost,
            "average_cost_per_request": total_cost / total_requests if total_requests > 0 else 0,
            "daily_budget_used_percent": (self.daily_spending / self.daily_budget) * 100,
            
            "model_distribution": {},
            "quality_scores": {},
            "cost_efficiency": {}
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–æ–¥–µ–ª—è–º
        for model, stats in self.usage_stats.items():
            if stats["requests"] > 0:
                percent = (stats["requests"] / total_requests) * 100
                cost_per_request = stats["total_cost"] / stats["requests"]
                
                report["model_distribution"][model] = f"{percent:.1f}%"
                report["quality_scores"][model] = f"{stats['avg_quality']:.2f}/1.0"
                report["cost_efficiency"][model] = f"${cost_per_request:.4f}/request"
        
        return report
    
    async def optimize_routing_strategy(self):
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–æ—É—Ç–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        """
        
        report = self.get_usage_report()
        
        # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        optimizations = []
        
        for model, stats in self.usage_stats.items():
            if stats["requests"] >= 10:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                target_percent = self.config.AI_MODEL_SETTINGS[model]["usage_target_percent"]
                actual_percent = (stats["requests"] / sum(s["requests"] for s in self.usage_stats.values())) * 100
                
                if abs(actual_percent - target_percent) > 5:  # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –±–æ–ª—å—à–µ 5%
                    optimizations.append({
                        "model": model,
                        "target_percent": target_percent,
                        "actual_percent": actual_percent,
                        "suggestion": "adjust_thresholds"
                    })
        
        if optimizations:
            logger.info(f"üìà Model usage optimization suggestions: {optimizations}")
        
        return optimizations