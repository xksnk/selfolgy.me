"""
Attachment Style Classifier - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–æ–≤ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏

üéØ –¶–ï–õ–¨: –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
üìö –û–°–ù–û–í–ê: Bowlby, Ainsworth, Bartholomew & Horowitz
üî¨ –¢–ò–ü–´: Secure, Anxious, Avoidant, Disorganized
‚ö†Ô∏è –¢–û–ß–ù–û–°–¢–¨: Target 84% (—Ç—Ä–µ–±—É–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö)
"""

import re
import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class AttachmentAssessment:
    """–û—Ü–µ–Ω–∫–∞ —Ç–∏–ø–∞ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏"""
    primary_style: str  # secure, anxious, avoidant, disorganized
    confidence: float  # 0.0 - 1.0
    style_scores: Dict[str, float]  # Scores for each style
    evidence: List[str]  # Supporting evidence from text
    anxiety_dimension: float  # -1.0 (low) to 1.0 (high)
    avoidance_dimension: float  # -1.0 (low) to 1.0 (high)
    timestamp: str


class AttachmentStyleClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–æ–≤ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏

    –î–≤—É–º–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å (Brennan, Clark, Shaver):
    - Anxiety: —Å—Ç—Ä–∞—Ö –æ—Ç–≤–µ—Ä–∂–µ–Ω–∏—è, –Ω—É–∂–¥–∞ –≤ –±–ª–∏–∑–æ—Å—Ç–∏
    - Avoidance: –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç –æ—Ç –±–ª–∏–∑–æ—Å—Ç–∏, —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å

    4 —Ç–∏–ø–∞ (Bartholomew & Horowitz):
    - SECURE: Low Anxiety, Low Avoidance
    - ANXIOUS (Preoccupied): High Anxiety, Low Avoidance
    - AVOIDANT (Dismissive): Low Anxiety, High Avoidance
    - DISORGANIZED (Fearful): High Anxiety, High Avoidance
    """

    # === –ò–ù–î–ò–ö–ê–¢–û–†–´ –¢–†–ï–í–û–ì–ò –ü–†–ò–í–Ø–ó–ê–ù–ù–û–°–¢–ò (Anxiety) ===
    ANXIETY_INDICATORS = {
        "fear_of_abandonment": {
            "patterns": [
                r"\b–±–æ—é—Å—å,?\s+—á—Ç–æ\s+(?:–±—Ä–æ—Å—è—Ç|—É–π–¥—É—Ç|–æ—Å—Ç–∞–≤—è—Ç)\b",
                r"\b—Å—Ç—Ä–∞—à–Ω–æ\s+(?:–ø–æ—Ç–µ—Ä—è—Ç—å|–æ—Å—Ç–∞—Ç—å—Å—è\s+–æ–¥–Ω–æ–º—É)\b",
                r"\b–Ω–µ\s+–º–æ–≥—É\s+–±–µ–∑\s+(?:–Ω–µ–≥–æ|–Ω–µ—ë|–Ω–∏—Ö)\b",
                r"\b—á—Ç–æ\s+–µ—Å–ª–∏\s+(?:—É–π–¥—ë—Ç|–±—Ä–æ—Å–∏—Ç|—Ä–∞–∑–ª—é–±–∏—Ç)\b"
            ],
            "weight": 0.3
        },
        "need_for_reassurance": {
            "patterns": [
                r"\b(?:–ª—é–±–∏—à—å|–ª—é–±–∏—Ç)\s+(?:–ª–∏|–º–µ–Ω—è)\b",
                r"\b–Ω–µ\s+(?:—Ä–∞–∑–æ–Ω—Ä–∞–≤–∏–ª–∞—Å—å?|–Ω–∞–¥–æ–µ–ª–∞?)\b",
                r"\b—Ç–æ—á–Ω–æ\s+(?:–≤—Å—ë\s+—Ö–æ—Ä–æ—à–æ|–Ω–µ\s+–∑–ª–∏—à—å—Å—è)\b",
                r"\b–ø–æ—á–µ–º—É\s+(?:–Ω–µ\s+)?(?:–Ω–∞–ø–∏—Å–∞–ª|–ø–æ–∑–≤–æ–Ω–∏–ª|–æ—Ç–≤–µ—Ç–∏–ª)\b"
            ],
            "weight": 0.25
        },
        "jealousy_possessiveness": {
            "patterns": [
                r"\b—Ä–µ–≤–Ω—É—é\b",
                r"\b—Å\s+–∫–µ–º\s+(?:–±—ã–ª|–±—ã–ª–∞|–æ–±—â–∞–ª—Å—è)\b",
                r"\b–ø–æ—á–µ–º—É\s+(?:—É–ª—ã–±–∞–ª—Å—è|—Å–º–æ—Ç—Ä–µ–ª)\s+–Ω–∞\b",
                r"\b–Ω–µ\s+–Ω—Ä–∞–≤–∏—Ç—Å—è,?\s+–∫–æ–≥–¥–∞\s+(?:–æ–±—â–∞–µ—Ç—Å—è|—Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–µ—Ç)\b"
            ],
            "weight": 0.2
        },
        "hypervigilance": {
            "patterns": [
                r"\b–∑–∞–º–µ—Ç–∏–ª–∞?,?\s+—á—Ç–æ\s+(?:–∏–∑–º–µ–Ω–∏–ª—Å—è|–æ—Ç–¥–∞–ª–∏–ª—Å—è)\b",
                r"\b—á—É–≤—Å—Ç–≤—É—é,?\s+—á—Ç–æ\s+(?:—á—Ç–æ-—Ç–æ\s+–Ω–µ\s+—Ç–∞–∫|—Å–∫—Ä—ã–≤–∞–µ—Ç)\b",
                r"\b–ø–æ—Å—Ç–æ—è–Ω–Ω–æ\s+(?:–¥—É–º–∞—é|–ø–µ—Ä–µ–∂–∏–≤–∞—é)\b",
                r"\b–Ω–µ\s+–º–æ–≥—É\s+—É—Å–ø–æ–∫–æ–∏—Ç—å—Å—è\b"
            ],
            "weight": 0.15
        },
        "merger_wishes": {
            "patterns": [
                r"\b—Ö–æ—á—É\s+–±—ã—Ç—å\s+(?:–≤—Å–µ–≥–¥–∞\s+)?(?:—Ä—è–¥–æ–º|–≤–º–µ—Å—Ç–µ)\b",
                r"\b–Ω–µ\s+–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é\s+(?:–∂–∏–∑–Ω–∏|—Å–µ–±—è)\s+–±–µ–∑\b",
                r"\b–º—ã\s+(?:–∫–∞–∫\s+)?–æ–¥–Ω–æ\s+—Ü–µ–ª–æ–µ\b"
            ],
            "weight": 0.1
        }
    }

    # === –ò–ù–î–ò–ö–ê–¢–û–†–´ –ò–ó–ë–ï–ì–ê–ù–ò–Ø (Avoidance) ===
    AVOIDANCE_INDICATORS = {
        "discomfort_with_closeness": {
            "patterns": [
                r"\b—Å–ª–∏—à–∫–æ–º\s+(?:–±–ª–∏–∑–∫–æ|–Ω–∞–≤—è–∑—á–∏–≤–æ|–º–Ω–æ–≥–æ)\b",
                r"\b–Ω—É–∂–Ω–æ\s+(?:–ª–∏—á–Ω–æ–µ\s+)?–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ\b",
                r"\b–¥—É—à–∏—Ç\b",
                r"\b–Ω–µ\s+–ª—é–±–ª—é,?\s+–∫–æ–≥–¥–∞\s+(?:–ª–µ–∑—É—Ç|–ø—Ä–∏—Å—Ç–∞—é—Ç)\b"
            ],
            "weight": 0.3
        },
        "self_sufficiency": {
            "patterns": [
                r"\b—Å–ø—Ä–∞–≤–ª—é—Å—å\s+—Å–∞–º[–∞–∏]?\b",
                r"\b–Ω–µ\s+–Ω—É–∂–¥–∞—é—Å—å\s+–≤\b",
                r"\b–ª—É—á—à–µ\s+(?:–æ–¥–∏–Ω|–æ–¥–Ω–∞)\b",
                r"\b–Ω–∏–∫–æ–º—É\s+–Ω–µ\s+(?:–Ω—É–∂–µ–Ω|–¥–æ–ª–∂–µ–Ω)\b"
            ],
            "weight": 0.25
        },
        "emotional_distance": {
            "patterns": [
                r"\b–Ω–µ\s+–ª—é–±–ª—é\s+(?:–≥–æ–≤–æ—Ä–∏—Ç—å\s+–æ\s+)?—á—É–≤—Å—Ç–≤–∞—Ö\b",
                r"\b–∑–∞—á–µ–º\s+(?:—ç—Ç–æ\s+)?–æ–±—Å—É–∂–¥–∞—Ç—å\b",
                r"\b–Ω–µ\s+–≤–∏–∂—É\s+—Å–º—ã—Å–ª–∞\s+–≤\b",
                r"\b(?:—ç–º–æ—Ü–∏–∏|—á—É–≤—Å—Ç–≤–∞)\s+(?:–º–µ—à–∞—é—Ç|–ª–∏—à–Ω–µ–µ)\b"
            ],
            "weight": 0.2
        },
        "commitment_fear": {
            "patterns": [
                r"\b–Ω–µ\s+–≥–æ—Ç–æ–≤[–∞—ã]?\s+–∫\s+(?:—Å–µ—Ä—å—ë–∑–Ω—ã–º|–æ—Ç–Ω–æ—à–µ–Ω–∏—è–º)\b",
                r"\b–Ω–µ\s+—Ö–æ—á—É\s+(?:–ø—Ä–∏–≤—è–∑—ã–≤–∞—Ç—å—Å—è|–æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤)\b",
                r"\b—Å–≤–æ–±–æ–¥–∞\s+–≤–∞–∂–Ω–µ–µ\b",
                r"\b–Ω–µ\s+–ª—é–±–ª—é\s+(?:–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å|–æ–±–µ—â–∞—Ç—å)\b"
            ],
            "weight": 0.15
        },
        "independence_emphasis": {
            "patterns": [
                r"\b—Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç(?:—å|–∏)\b",
                r"\b—Å–≤–æ—è\s+–∂–∏–∑–Ω—å\b",
                r"\b–Ω–µ\s+—Ö–æ—á—É\s+–∑–∞–≤–∏—Å–µ—Ç—å\b",
                r"\b–∫–∞–∂–¥—ã–π\s+—Å–∞–º\s+–∑–∞\s+—Å–µ–±—è\b"
            ],
            "weight": 0.1
        }
    }

    # === –ò–ù–î–ò–ö–ê–¢–û–†–´ –ù–ê–î–Å–ñ–ù–û–ô –ü–†–ò–í–Ø–ó–ê–ù–ù–û–°–¢–ò (Secure) ===
    SECURE_INDICATORS = {
        "comfort_with_intimacy": {
            "patterns": [
                r"\b–ª—é–±–ª—é\s+(?:–±—ã—Ç—å\s+)?(?:–±–ª–∏–∑–∫–æ|—Ä—è–¥–æ–º)\b",
                r"\b—á—É–≤—Å—Ç–≤—É—é\s+—Å–µ–±—è\s+(?:–∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ|—Å–ø–æ–∫–æ–π–Ω–æ)\b",
                r"\b–¥–æ–≤–µ—Ä—è—é\b",
                r"\b–º–æ–∂–µ–º\s+(?:–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å|–æ–±—Å—É–¥–∏—Ç—å)\b"
            ],
            "weight": 0.3
        },
        "healthy_boundaries": {
            "patterns": [
                r"\b—É–≤–∞–∂–∞—é\s+(?:–µ–≥–æ|–µ—ë|–∏—Ö)\s+(?:–≥—Ä–∞–Ω–∏—Ü—ã|–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ)\b",
                r"\b–∫–∞–∂–¥–æ–º—É\s+–Ω—É–∂–Ω–æ\s+(?:–≤—Ä–µ–º—è|–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ)\b",
                r"\b–±–∞–ª–∞–Ω—Å\b"
            ],
            "weight": 0.25
        },
        "emotional_availability": {
            "patterns": [
                r"\b–≥–æ—Ç–æ–≤[–∞—ã]?\s+(?:–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å|–ø–æ–º–æ—á—å|–≤—ã—Å–ª—É—à–∞—Ç—å)\b",
                r"\b–º–æ–≥—É\s+(?:–ø–æ–¥–µ–ª–∏—Ç—å—Å—è|—Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å)\b",
                r"\b–æ—Ç–∫—Ä—ã—Ç[–∞—ã]?\b"
            ],
            "weight": 0.2
        },
        "relationship_security": {
            "patterns": [
                r"\b—É–≤–µ—Ä–µ–Ω[–∞—ã]?\s+–≤\s+(?:–Ω–∞—Å|–æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö|–Ω—ë–º|–Ω–µ–π)\b",
                r"\b–∑–Ω–∞—é,?\s+—á—Ç–æ\s+(?:–ª—é–±–∏—Ç|–ø–æ–¥–¥–µ—Ä–∂–∏—Ç|–±—É–¥–µ—Ç\s+—Ä—è–¥–æ–º)\b",
                r"\b—Å—Ç–∞–±–∏–ª—å–Ω(?:—ã–µ|–æ—Å—Ç—å)\b"
            ],
            "weight": 0.15
        },
        "conflict_resolution": {
            "patterns": [
                r"\b–º–æ–∂–µ–º\s+(?:—Ä–µ—à–∏—Ç—å|–æ–±—Å—É–¥–∏—Ç—å|–¥–æ–≥–æ–≤–æ—Ä–∏—Ç—å—Å—è)\b",
                r"\b–∫–æ–º–ø—Ä–æ–º–∏—Å—Å\b",
                r"\b–≤–∞–∂–Ω–æ\s+(?:—Å–ª—ã—à–∞—Ç—å|–ø–æ–Ω–∏–º–∞—Ç—å)\s+–¥—Ä—É–≥\s+–¥—Ä—É–≥–∞\b"
            ],
            "weight": 0.1
        }
    }

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
        # –ò—Å—Ç–æ—Ä–∏—è –æ—Ü–µ–Ω–æ–∫ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
        self.assessment_history: Dict[int, List[AttachmentAssessment]] = {}
        logger.info("‚úÖ AttachmentStyleClassifier initialized")

    def assess(
        self,
        user_id: int,
        text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AttachmentAssessment:
        """
        –û—Ü–µ–Ω–∏—Ç—å —Ç–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç

        Returns:
            AttachmentAssessment —Å —Ç–∏–ø–æ–º –∏ scores
        """
        text_lower = text.lower()

        # 1. –í—ã—á–∏—Å–ª—è–µ–º dimensions
        anxiety_score, anxiety_evidence = self._calculate_dimension(text_lower, self.ANXIETY_INDICATORS)
        avoidance_score, avoidance_evidence = self._calculate_dimension(text_lower, self.AVOIDANCE_INDICATORS)
        secure_score, secure_evidence = self._calculate_dimension(text_lower, self.SECURE_INDICATORS)

        # 2. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –Ω–∞ secure indicators
        if secure_score > 0.3:
            anxiety_score -= secure_score * 0.5
            avoidance_score -= secure_score * 0.5

        # 3. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ [-1, 1]
        anxiety_dim = max(-1.0, min(1.0, anxiety_score))
        avoidance_dim = max(-1.0, min(1.0, avoidance_score))

        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º style scores
        style_scores = self._calculate_style_scores(anxiety_dim, avoidance_dim, secure_score)

        # 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º primary style
        primary_style = max(style_scores.items(), key=lambda x: x[1])[0]
        confidence = style_scores[primary_style]

        # 6. –°–æ–±–∏—Ä–∞–µ–º evidence
        all_evidence = anxiety_evidence + avoidance_evidence + secure_evidence

        # 7. –£—á–∏—Ç—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é (EMA smoothing)
        if user_id in self.assessment_history and len(self.assessment_history[user_id]) > 0:
            prev = self.assessment_history[user_id][-1]
            alpha = 0.4  # –í–µ—Å –Ω–æ–≤–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è
            for style in style_scores:
                style_scores[style] = alpha * style_scores[style] + (1 - alpha) * prev.style_scores.get(style, 0.5)

            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º primary style –ø–æ—Å–ª–µ smoothing
            primary_style = max(style_scores.items(), key=lambda x: x[1])[0]
            confidence = style_scores[primary_style]

        # 8. –°–æ–∑–¥–∞—ë–º assessment
        assessment = AttachmentAssessment(
            primary_style=primary_style,
            confidence=round(confidence, 3),
            style_scores={k: round(v, 3) for k, v in style_scores.items()},
            evidence=all_evidence[:5],  # Top 5 evidence
            anxiety_dimension=round(anxiety_dim, 3),
            avoidance_dimension=round(avoidance_dim, 3),
            timestamp=datetime.now().isoformat()
        )

        # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        if user_id not in self.assessment_history:
            self.assessment_history[user_id] = []
        self.assessment_history[user_id].append(assessment)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(self.assessment_history[user_id]) > 50:
            self.assessment_history[user_id] = self.assessment_history[user_id][-50:]

        logger.debug(f"Attachment assessment for user {user_id}: {primary_style} ({confidence:.2f})")

        return assessment

    def _calculate_dimension(
        self,
        text: str,
        indicators: Dict
    ) -> Tuple[float, List[str]]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å score –¥–ª—è dimension"""
        total_score = 0.0
        evidence = []

        for indicator_name, indicator_data in indicators.items():
            for pattern in indicator_data["patterns"]:
                if re.search(pattern, text, re.IGNORECASE):
                    total_score += indicator_data["weight"]
                    evidence.append(indicator_name)
                    break

        return total_score, evidence

    def _calculate_style_scores(
        self,
        anxiety: float,
        avoidance: float,
        secure: float
    ) -> Dict[str, float]:
        """
        –í—ã—á–∏—Å–ª–∏—Ç—å scores –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–∏–ª—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏

        Quadrant model:
        - Secure: Low Anxiety, Low Avoidance
        - Anxious: High Anxiety, Low Avoidance
        - Avoidant: Low Anxiety, High Avoidance
        - Disorganized: High Anxiety, High Avoidance
        """
        scores = {}

        # Secure: –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ—Å—Ç—å –æ–±–æ–∏–º dimensions + secure indicators
        scores["secure"] = max(0.1, (1 - abs(anxiety)) * (1 - abs(avoidance)) * 0.5 + secure * 0.5)

        # Anxious: high anxiety, low avoidance
        scores["anxious"] = max(0.1, (anxiety + 1) / 2 * (1 - (avoidance + 1) / 2))

        # Avoidant: low anxiety, high avoidance
        scores["avoidant"] = max(0.1, (1 - (anxiety + 1) / 2) * (avoidance + 1) / 2)

        # Disorganized: high both
        scores["disorganized"] = max(0.1, (anxiety + 1) / 2 * (avoidance + 1) / 2)

        # Normalize to sum to 1
        total = sum(scores.values())
        if total > 0:
            scores = {k: v / total for k, v in scores.items()}

        return scores

    def get_current_style(self, user_id: int) -> Tuple[str, float]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π —Ç–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏

        Returns:
            (style, confidence)
        """
        if user_id not in self.assessment_history or len(self.assessment_history[user_id]) == 0:
            return "unknown", 0.0

        latest = self.assessment_history[user_id][-1]
        return latest.primary_style, latest.confidence

    def get_style_description(self, style: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏"""
        descriptions = {
            "secure": "–ù–∞–¥—ë–∂–Ω–∞—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å: –∫–æ–º—Ñ–æ—Ä—Ç —Å –±–ª–∏–∑–æ—Å—Ç—å—é –∏ –∞–≤—Ç–æ–Ω–æ–º–∏–µ–π, –¥–æ–≤–µ—Ä–∏–µ –∫ —Å–µ–±–µ –∏ –¥—Ä—É–≥–∏–º",
            "anxious": "–¢—Ä–µ–≤–æ–∂–Ω–∞—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å: —Å—Ç—Ä–∞—Ö –æ—Ç–≤–µ—Ä–∂–µ–Ω–∏—è, –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å –≤ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏, —Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ —Å–ª–∏—è–Ω–∏—é",
            "avoidant": "–ò–∑–±–µ–≥–∞—é—â–∞—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å: –¥–∏—Å–∫–æ–º—Ñ–æ—Ä—Ç —Å –±–ª–∏–∑–æ—Å—Ç—å—é, —Ü–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è",
            "disorganized": "–î–µ–∑–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å: —Å–º–µ—à–µ–Ω–∏–µ —Ç—Ä–µ–≤–æ–≥–∏ –∏ –∏–∑–±–µ–≥–∞–Ω–∏—è, —Å—Ç—Ä–∞—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π –∏ –∂–µ–ª–∞–Ω–∏–µ –±–ª–∏–∑–æ—Å—Ç–∏"
        }
        return descriptions.get(style, "–¢–∏–ø –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω")

    def format_for_storage(self, assessment: AttachmentAssessment) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î"""
        return {
            "primary_style": assessment.primary_style,
            "confidence": assessment.confidence,
            "style_scores": assessment.style_scores,
            "evidence": assessment.evidence,
            "anxiety_dimension": assessment.anxiety_dimension,
            "avoidance_dimension": assessment.avoidance_dimension,
            "timestamp": assessment.timestamp
        }


# Singleton instance
_attachment_classifier = None


def get_attachment_classifier() -> AttachmentStyleClassifier:
    """–ü–æ–ª—É—á–∏—Ç—å singleton —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞"""
    global _attachment_classifier
    if _attachment_classifier is None:
        _attachment_classifier = AttachmentStyleClassifier()
    return _attachment_classifier


# === –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï ===
if __name__ == "__main__":
    classifier = AttachmentStyleClassifier()

    test_texts = [
        # Secure
        ("–õ—é–±–ª—é –±—ã—Ç—å —Ä—è–¥–æ–º —Å –±–ª–∏–∑–∫–∏–º–∏, –Ω–æ —É–≤–∞–∂–∞—é –∏—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ. –î–æ–≤–µ—Ä—è—é –ø–∞—Ä—Ç–Ω—ë—Ä—É, –∑–Ω–∞—é —á—Ç–æ –æ–Ω –º–µ–Ω—è –ª—é–±–∏—Ç. –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã, –º–æ–∂–µ–º —Å–ø–æ–∫–æ–π–Ω–æ –æ–±—Å—É–¥–∏—Ç—å.", "secure"),

        # Anxious
        ("–ë–æ—é—Å—å, —á—Ç–æ –æ–Ω –º–µ–Ω—è –±—Ä–æ—Å–∏—Ç. –ü–æ—Å—Ç–æ—è–Ω–Ω–æ –¥—É–º–∞—é, –ª—é–±–∏—Ç –ª–∏ –æ–Ω –º–µ–Ω—è. –†–µ–≤–Ω—É—é –∫–æ–≥–¥–∞ –æ–Ω –æ–±—â–∞–µ—Ç—Å—è —Å –¥—Ä—É–≥–∏–º–∏. –ù–µ –º–æ–≥—É –±–µ–∑ –Ω–µ–≥–æ, –º—ã –∫–∞–∫ –æ–¥–Ω–æ —Ü–µ–ª–æ–µ.", "anxious"),

        # Avoidant
        ("–õ—É—á—à–µ –æ–¥–Ω–∞. –ù–µ –ª—é–±–ª—é –∫–æ–≥–¥–∞ –ª–µ–∑—É—Ç –≤ –¥—É—à—É, –∑–∞—á–µ–º —ç—Ç–æ –æ–±—Å—É–∂–¥–∞—Ç—å? –°–ø—Ä–∞–≤–ª—é—Å—å —Å–∞–º–∞, –Ω–µ –Ω—É–∂–¥–∞—é—Å—å –≤ –ø–æ–º–æ—â–∏. –°–≤–æ–±–æ–¥–∞ –≤–∞–∂–Ω–µ–µ –≤—Å–µ–≥–æ.", "avoidant"),

        # Disorganized
        ("–ë–æ—é—Å—å –æ—Å—Ç–∞—Ç—å—Å—è –æ–¥–Ω–∞, –Ω–æ –∫–æ–≥–¥–∞ –æ–Ω —Ä—è–¥–æ–º - –¥—É—à–∏—Ç. –•–æ—á—É –±–ª–∏–∑–æ—Å—Ç–∏, –Ω–æ –Ω–µ –º–æ–≥—É –¥–æ–≤–µ—Ä–∏—Ç—å—Å—è. –û–Ω —Ç–æ—á–Ω–æ –º–µ–Ω—è –±—Ä–æ—Å–∏—Ç, –Ω–æ –±–µ–∑ –Ω–µ–≥–æ –Ω–µ –º–æ–≥—É.", "disorganized")
    ]

    print("üíú ATTACHMENT STYLE CLASSIFIER TEST\n" + "=" * 50)

    user_id = 456

    for text, expected in test_texts:
        print(f"\nüìù Expected: {expected}")
        print(f"   Text: {text[:60]}...")

        assessment = classifier.assess(user_id, text)

        emoji = "‚úÖ" if assessment.primary_style == expected else "‚ö†Ô∏è"
        print(f"   {emoji} Result: {assessment.primary_style} ({assessment.confidence:.2f})")
        print(f"   Scores: {assessment.style_scores}")
        print(f"   Dimensions: Anx={assessment.anxiety_dimension:.2f}, Avoid={assessment.avoidance_dimension:.2f}")
        if assessment.evidence:
            print(f"   Evidence: {', '.join(assessment.evidence[:3])}")

    print("\n" + "=" * 50)
    style, conf = classifier.get_current_style(user_id)
    print(f"üìä Final style: {style} ({conf:.2f})")
    print(f"   {classifier.get_style_description(style)}")
    print("‚úÖ Test completed!")
