"""
OnboardingOrchestrator - –ì–ª–∞–≤–Ω—ã–π –¥–∏—Ä–∏–∂–µ—Ä –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞

–ß–∏—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–µ–∑ —Å–ª–æ–µ–≤ –∏ –∫–æ—Å—Ç—ã–ª–µ–π:
- –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å intelligent_question_core
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
- –ü—Ä–æ—Å—Ç—ã–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

–ê–†–•–ò–¢–ï–ö–¢–£–†–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø (October 2025):
- Task Registry –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è background tasks
- Proper error handling –≤ async tasks
- Graceful shutdown —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è tasks
- Immutable data –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è race conditions
- Observability –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á
"""

import logging
import sys
import asyncio
from pathlib import Path
from typing import Dict, Optional, Any, List, Set
from datetime import datetime
from copy import deepcopy

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ Question Core
sys.path.append(str(Path(__file__).parent.parent.parent.parent / "intelligent_question_core"))

from intelligent_question_core.api.core_api import SelfologyQuestionCore
from .question_router import QuestionRouter
from .program_router import ProgramRouter
from .session_reporter import SessionReportGenerator

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏–∑–∞ (Phase 2)
sys.path.append(str(Path(__file__).parent.parent.parent))
from analysis import AnswerAnalyzer, EmbeddingCreator, PersonalityExtractor

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º FatigueDetector (Phase 3)
from .fatigue_detector import FatigueDetector

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Database (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö)
sys.path.append(str(Path(__file__).parent.parent.parent))
from database import DatabaseService, OnboardingDAO, DigitalPersonalityDAO

logger = logging.getLogger(__name__)

class OnboardingOrchestrator:
    """
    –ì–ª–∞–≤–Ω—ã–π —É–ø—Ä–∞–≤–ª—è—é—â–∏–π —Å–∏—Å—Ç–µ–º–æ–π –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞

    –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:
    - –ù–∞—á–∞–ª–æ/–∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
    - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –º–µ–∂–¥—É QuestionRouter, SessionManager, FatigueDetector
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ background tasks —Å proper lifecycle
    - Graceful shutdown –∏ observability
    - –ü—Ä–æ—Å—Ç—ã–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è controller
    """

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º core API (—É–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É)
        core_file_path = str(Path(__file__).parent.parent.parent.parent / "intelligent_question_core" / "data" / "selfology_intelligent_core.json")
        self.question_core = SelfologyQuestionCore(core_file_path)
        logger.info("üß† Question Core initialized")

        # üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º QuestionRouter —Å —É–º–Ω—ã–º –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º
        self.question_router = QuestionRouter(self.question_core)
        logger.info("üéØ QuestionRouter with Smart Mix algorithm initialized")

        # üî¨ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏–∑–∞ (Phase 2)
        self.answer_analyzer = AnswerAnalyzer()
        self.embedding_creator = EmbeddingCreator()
        self.personality_extractor = PersonalityExtractor()
        logger.info("üî¨ Analysis system (AnswerAnalyzer + EmbeddingCreator + PersonalityExtractor) initialized")

        # Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        self._vector_storage_setup = False

        # üò¥ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä —É—Å—Ç–∞–ª–æ—Å—Ç–∏ (Phase 3)
        self.fatigue_detector = FatigueDetector()
        logger.info("üò¥ FatigueDetector initialized - caring for users")

        # üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ –æ —Å–µ—Å—Å–∏—è—Ö
        self.session_reporter = None  # –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DAO
        logger.info("üìä SessionReportGenerator will be initialized after DAO")

        # üóÑÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Database –¥–ª—è –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ (–ö–†–ò–¢–ò–ß–ù–û)
        self.db_service = None
        self.onboarding_dao = None
        self.personality_dao = None

        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.session_manager = None     # –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –≤ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–¥–∞—á–∞—Ö

        # üì¶ ProgramRouter –¥–ª—è –±–ª–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–≥—Ä–∞–º–º (Phase 4)
        self.program_router = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ DB

        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π (–∑–∞–º–µ–Ω–∏–º –Ω–∞ SessionManager)
        self.active_sessions = {}       # {user_id: session_data}

        # ‚úÖ TASK REGISTRY - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤—Å–µ background tasks
        self._background_tasks: Set[asyncio.Task] = set()
        self._shutdown_event = asyncio.Event()

        logger.info("üéØ OnboardingOrchestrator initialized with Task Registry")

    async def start_onboarding(self, user_id: int) -> Dict[str, Any]:
        """
        –ù–∞—á–∞—Ç—å –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        try:
            logger.info(f"üöÄ Starting onboarding for user {user_id}")

            # üóÑÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Database –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
            if not self.db_service:
                from os import environ
                self.db_service = DatabaseService(
                    host=environ.get("DB_HOST", "localhost"),
                    port=int(environ.get("DB_PORT", 5432)),
                    user=environ.get("DB_USER", "n8n"),
                    password=environ.get("DB_PASSWORD", "sS67wM+1zMBRFHAW4kj9HwFl5J6+veo7Nirx0/I+oiU="),
                    database=environ.get("DB_NAME", "n8n")
                )
                await self.db_service.initialize()
                self.onboarding_dao = OnboardingDAO(self.db_service)
                self.personality_dao = DigitalPersonalityDAO(self.db_service)
                await self.onboarding_dao.create_onboarding_tables()

                # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º DAO –≤ QuestionRouter –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ flagged –≤–æ–ø—Ä–æ—Å–æ–≤
                self.question_router.onboarding_dao = self.onboarding_dao

                # üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º SessionReportGenerator –ø–æ—Å–ª–µ DAO
                if not self.session_reporter:
                    self.session_reporter = SessionReportGenerator(self.onboarding_dao)
                    logger.info("üìä SessionReportGenerator initialized")

                # üì¶ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ProgramRouter –¥–ª—è –±–ª–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (Phase 4)
                if not self.program_router and self.db_service and self.db_service.pool:
                    self.program_router = ProgramRouter(db_pool=self.db_service.pool)
                    logger.info("üì¶ ProgramRouter initialized for block-based programs")

                logger.info("üóÑÔ∏è Database connection established for onboarding")

            # üîÑ Retry pending answers for this user (if any)
            await self._retry_pending_answers(user_id)

            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º vector storage –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
            if not self._vector_storage_setup:
                await self._setup_vector_storage()
                self._vector_storage_setup = True

            # üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º QuestionRouter –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–µ—Ä–≤–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            first_question = await self.question_router.select_first_question(user_id)

            if not first_question:
                raise Exception("QuestionRouter could not select first question")

            # üóÑÔ∏è –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –≤ –ë–î (–≤–º–µ—Å—Ç–æ –ø–∞–º—è—Ç–∏)
            session_id = await self.onboarding_dao.start_session(user_id)
            logger.info(f"üóÑÔ∏è Created database session {session_id} for user {user_id}")

            # ‚úÖ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º current_question_json_id —Å—Ä–∞–∑—É –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–µ—Å—Å–∏–∏
            await self.onboarding_dao.update_current_question(session_id, first_question["id"])
            await self.onboarding_dao.increment_questions_asked(session_id)
            logger.info(f"üìù Set initial question {first_question['id']} for session {session_id}")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (–ø–∞–º—è—Ç—å + –ë–î)
            session_data = {
                "user_id": user_id,
                "session_id": session_id,
                "started_at": datetime.now(),
                "question_history": [],
                "answer_history": [],
                "current_question": first_question,
                "router_events": []  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Ä–æ—É—Ç–µ—Ä–∞
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ—Å—Å–∏—é (–ø–∞–º—è—Ç—å –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ + –ë–î –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω—Å—Ç–≤–∞)
            self.active_sessions[user_id] = session_data

            question = first_question

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¢–ï–ö–£–©–ï–ô —Å–µ—Å—Å–∏–∏ –∏ –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            session_db = await self.onboarding_dao.get_active_session(user_id)
            questions_in_session = session_db.get("questions_answered", 0)
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –†–ï–ê–õ–¨–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            total_lifetime = await self.onboarding_dao.get_user_total_answers(user_id)
            MAX_QUESTIONS_PER_SESSION = 20

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è controller
            return {
                "status": "started",
                "question": {
                    "id": question["id"],
                    "text": question["text"],
                    "domain": question["classification"]["domain"],
                    "depth": question["classification"]["depth_level"],
                    "energy": question["classification"]["energy_dynamic"]
                },
                "session_info": {
                    "question_number": questions_in_session + 1,  # –°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ –¢–ï–ö–£–©–ï–ô —Å–µ—Å—Å–∏–∏
                    "total_questions": MAX_QUESTIONS_PER_SESSION,
                    "total_lifetime": total_lifetime,  # –í—Å–µ–≥–æ –ø—Ä–æ–π–¥–µ–Ω–æ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è
                    "session_started": datetime.now().isoformat()
                }
            }

        except Exception as e:
            logger.error(f"‚ùå Failed to start onboarding for user {user_id}: {e}")
            raise

    def get_session(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø–∞–º—è—Ç–∏

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–µ—Å—Å–∏–∏ –∏–ª–∏ None –µ—Å–ª–∏ —Å–µ—Å—Å–∏–∏ –Ω–µ—Ç
        """
        session = self.active_sessions.get(user_id)
        if session:
            logger.debug(f"üìñ Retrieved active session for user {user_id}")
        else:
            logger.warning(f"‚ö†Ô∏è No active session found for user {user_id}")
        return session

    async def restore_session_from_db(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–µ—Å—Å–∏—é –∏–∑ –ë–î –≤ –ø–∞–º—è—Ç—å (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Ä–µ—Å—Ç–∞—Ä—Ç–∞ –±–æ—Ç–∞)

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏ –∏–ª–∏ None
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ DAO
            if not self.onboarding_dao:
                logger.error("‚ùå Cannot restore session: onboarding_dao not initialized")
                return None

            # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é –∏–∑ –ë–î
            session_db = await self.onboarding_dao.get_active_session(user_id)

            if not session_db or session_db.get('status') != 'active':
                logger.warning(f"‚ö†Ô∏è No active session in DB for user {user_id}")
                return None

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º current_question –∏–∑ question core
            current_question_id = session_db.get('current_question_json_id')
            current_question = None

            if current_question_id:
                current_question = self.question_core.get_question(current_question_id)
                if not current_question:
                    logger.error(f"‚ùå Could not load question {current_question_id} from core")

            # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ –ë–î
            question_history = []
            answer_history = []

            session_id = session_db['id']
            db_answers = await self.onboarding_dao.get_session_answers(session_id)

            for db_answer in db_answers:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ question core
                question_data = self.question_core.get_question(db_answer['question_id'])

                if question_data:
                    question_history.append(question_data)
                    answer_history.append({
                        "answer": db_answer['answer'],
                        "question_id": db_answer['question_id'],
                        "answer_id": db_answer['answer_id'],
                        "timestamp": db_answer['answered_at']
                    })
                else:
                    logger.warning(f"‚ö†Ô∏è Could not load question {db_answer['question_id']} from core during restore")

            logger.info(f"üìö Restored {len(question_history)} questions from DB for user {user_id}")

            # –°–æ–∑–¥–∞—ë–º session —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ –ø–∞–º—è—Ç–∏
            session = {
                "user_id": user_id,
                "session_id": session_db['id'],
                "current_question": current_question,
                "answer_history": answer_history,  # ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ –ë–î
                "question_history": question_history,  # ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ –ë–î
                "router_events": []  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã —Ä–æ—É—Ç–µ—Ä–∞ (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∑–∞–Ω–æ–≤–æ)
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç–∏
            self.active_sessions[user_id] = session

            logger.info(f"üîÑ [SESSION RESTORE] Restored session for user {user_id} from DB (session_id={session_db['id']}, question={current_question_id}, history_size={len(question_history)})")

            return session

        except Exception as e:
            logger.error(f"‚ùå Failed to restore session from DB for user {user_id}: {e}")
            import traceback
            traceback.print_exc()
            return None

    async def get_next_question(self, user_id: int, session_data: Dict) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            session_data: –î–∞–Ω–Ω—ã–µ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏

        Returns:
            Dict —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        """
        try:
            logger.info(f"üîÑ Getting next question for user {user_id}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è
            if user_id not in self.active_sessions:
                logger.error(f"‚ùå No active session for user {user_id}")
                return {
                    "status": "error",
                    "message": "No active onboarding session"
                }

            session = self.active_sessions[user_id]

            # üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º QuestionRouter —Å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º "–£–º–Ω—ã–π –ú–∏–∫—Å"
            history = []
            question_history = session.get("question_history") or []
            answer_history = session.get("answer_history") or []
            for i in range(len(question_history)):
                if i < len(answer_history):
                    history.append({
                        "question": question_history[i],
                        "answer": answer_history[i]
                    })

            # ‚ú® –ü–µ—Ä–µ–¥–∞–µ–º session_id –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ AI insights
            session_id = session.get("session_id")
            next_question = await self.question_router.select_next_question(user_id, history, session_id)

            # üìä –°–æ–±–∏—Ä–∞–µ–º —Å–æ–±—ã—Ç–∏—è —Ä–æ—É—Ç–µ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            if self.question_router.last_events:
                session.setdefault("router_events", []).extend(self.question_router.last_events)
                logger.debug(f"üìä Collected {len(self.question_router.last_events)} router events")

            if not next_question:
                return {
                    "status": "completed",
                    "message": "Smart Mix algorithm completed onboarding"
                }

            # ‚úÖ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç questions_asked –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
            session_id = session["session_id"]
            await self.onboarding_dao.increment_questions_asked(session_id)
            logger.debug(f"üìä Incremented questions_asked for session {session_id} (next question)")

            # ‚úÖ –û–±–Ω–æ–≤–ª—è–µ–º current_question_json_id
            await self.onboarding_dao.update_current_question(session_id, next_question["id"])
            logger.debug(f"üìù Updated current_question to {next_question['id']} for session {session_id}")

            question = next_question

            # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º current_question –≤ —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é
            session["current_question"] = next_question
            logger.debug(f"üìù Updated session current_question to {next_question['id']}")

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¢–ï–ö–£–©–ï–ô —Å–µ—Å—Å–∏–∏ –∏ –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
            session_id = session["session_id"]
            session_db = await self.onboarding_dao.get_active_session(user_id)
            questions_in_session = session_db.get("questions_answered", 0)
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –†–ï–ê–õ–¨–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            total_lifetime = await self.onboarding_dao.get_user_total_answers(user_id)
            MAX_QUESTIONS_PER_SESSION = 20

            return {
                "status": "continue",
                "question": {
                    "id": question["id"],
                    "text": question["text"],
                    "domain": question["classification"]["domain"],
                    "depth": question["classification"]["depth_level"],
                    "energy": question["classification"]["energy_dynamic"]
                },
                "session_info": {
                    "question_number": questions_in_session + 1,  # –°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ –¢–ï–ö–£–©–ï–ô —Å–µ—Å—Å–∏–∏
                    "total_questions": MAX_QUESTIONS_PER_SESSION,
                    "total_lifetime": total_lifetime  # –í—Å–µ–≥–æ –ø—Ä–æ–π–¥–µ–Ω–æ –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è
                }
            }

        except Exception as e:
            logger.error(f"‚ùå Failed to get next question for user {user_id}: {e}")
            raise

    async def process_user_answer(self, user_id: int, question_id: str, answer: str) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            question_id: ID –≤–æ–ø—Ä–æ—Å–∞
            answer: –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        try:
            logger.info(f"üí¨ Processing answer from user {user_id} for question {question_id}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é
            if user_id not in self.active_sessions:
                logger.error(f"‚ùå No active session for user {user_id}")
                return {
                    "status": "error",
                    "message": "No active session"
                }

            session = self.active_sessions[user_id]

            # üöÄ –î–í–£–•–§–ê–ó–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (—Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É)

            # === –§–ê–ó–ê 1: INSTANT (<500ms) ===
            instant_start = datetime.now()

            # 1.1 –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î (–∫—Ä–∏—Ç–∏—á–Ω–æ - –Ω–µ —Ç–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ)
            session_id = session.get("session_id")
            answer_id = None
            is_context_story = (question_id == "system_context_story")

            if session_id and self.onboarding_dao:
                if is_context_story:
                    # –°–∏—Å—Ç–µ–º–Ω—ã–π –≤–æ–ø—Ä–æ—Å - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
                    answer_id = await self.onboarding_dao.save_context_story(
                        user_id=user_id,
                        session_id=session_id,
                        story_text=answer,
                        story_type="onboarding_context",
                        metadata={"source": "onboarding", "answered_at": datetime.now().isoformat()}
                    )
                    logger.info(f"üíô Context story saved to database with ID {answer_id}")
                else:
                    # –û–±—ã—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç
                    answer_id = await self.onboarding_dao.save_user_answer(session_id, question_id, answer)
                    logger.info(f"üóÑÔ∏è Answer saved to database with ID {answer_id}")
            else:
                logger.warning("‚ö†Ô∏è Database not available - answer saved only in memory")

            # 1.2 –ë—ã—Å—Ç—Ä–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å–µ—Å—Å–∏–∏
            current_question = session.get("current_question")
            if current_question:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if "question_history" not in session or session["question_history"] is None:
                    session["question_history"] = []
                if "answer_history" not in session or session["answer_history"] is None:
                    session["answer_history"] = []

                session["question_history"].append(current_question)
                session["answer_history"].append({
                    "answer": answer,
                    "question_id": question_id,
                    "answer_id": answer_id,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–≤—è–∑–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º
                    "timestamp": datetime.now().isoformat()
                })

                logger.info(f"üìù Answer saved in session: user={user_id}, question={question_id}, answer_length={len(answer)}")

            # 1.3 –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞ (Mock –ø–æ–∫–∞ —á—Ç–æ)
            quick_insight = self._get_quick_insight(answer)

            # 1.4 –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            instant_time = (datetime.now() - instant_start).total_seconds() * 1000
            logger.info(f"‚ö° Instant phase completed in {instant_time:.0f}ms")

            instant_response = {
                "status": "processed",
                "answer_id": f"temp_{user_id}_{question_id}_{datetime.now().timestamp()}",
                "quick_insight": quick_insight,
                "processing_phase": "instant_complete",
                "next_action": "continue",
                "deep_analysis_status": "processing"
            }

            # ‚úÖ 1.5 –°–æ–∑–¥–∞–µ–º immutable –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è background task
            # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç race conditions —Å shared session state
            immutable_session = deepcopy(session)
            immutable_question = deepcopy(current_question)

            # ‚úÖ 1.6 –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Task Registry
            task = self._create_background_task(
                self._deep_analysis_pipeline(
                    user_id,
                    question_id,
                    answer,
                    immutable_question,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º immutable –∫–æ–ø–∏—é
                    immutable_session,   # –ò—Å–ø–æ–ª—å–∑—É–µ–º immutable –∫–æ–ø–∏—é
                    answer_id,
                    is_context_story=is_context_story  # –ü–µ—Ä–µ–¥–∞–µ–º —Ñ–ª–∞–≥ —Ç–∏–ø–∞ –æ—Ç–≤–µ—Ç–∞
                ),
                name=f"deep_analysis_{user_id}_{question_id}"
            )

            logger.info(f"üî¨ Background analysis task created: {task.get_name()} (total active: {len(self._background_tasks)})")

            return instant_response

        except Exception as e:
            logger.error(f"‚ùå Failed to process answer from user {user_id}: {e}")
            raise

    def _create_background_task(self, coro, name: str = None) -> asyncio.Task:
        """
        –°–æ–∑–¥–∞—Ç—å background task —Å proper error handling –∏ registry tracking

        –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û–ï –†–ï–®–ï–ù–ò–ï:
        - Task –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ registry –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è garbage collection
        - Automatic cleanup –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —á–µ—Ä–µ–∑ done callback
        - Exception handling —Å –ø–æ–ª–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ graceful shutdown

        Args:
            coro: –ö–æ—Ä—É—Ç–∏–Ω–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            name: –ò–º—è –∑–∞–¥–∞—á–∏ –¥–ª—è observability

        Returns:
            asyncio.Task —Å registered cleanup
        """
        task = asyncio.create_task(coro, name=name)
        self._background_tasks.add(task)

        # ‚úÖ Cleanup callback - —É–¥–∞–ª—è–µ—Ç task –∏–∑ registry –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        def task_done_callback(t: asyncio.Task):
            self._background_tasks.discard(t)

            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ª—é–±—ã–µ exceptions –∏–∑ background task
            if t.exception():
                exc = t.exception()
                task_name = t.get_name() or "unnamed_task"
                logger.error(
                    f"‚ùå Background task '{task_name}' failed with exception: {exc}",
                    exc_info=exc
                )
            else:
                task_name = t.get_name() or "unnamed_task"
                logger.debug(f"‚úÖ Background task '{task_name}' completed successfully")

        task.add_done_callback(task_done_callback)
        return task

    async def should_continue_session(self, user_id: int, session_data: Dict) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–æ–ª–∂–Ω–∞ –ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å—Å—è —Å–µ—Å—Å–∏—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            session_data: –î–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏

        Returns:
            True –µ—Å–ª–∏ —Å–µ—Å—Å–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å—Å—è
        """
        try:
            # üò¥ –£–ú–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –£–°–¢–ê–õ–û–°–¢–ò (Phase 3)

            # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
            if user_id not in self.active_sessions:
                return False

            session = self.active_sessions[user_id]
            history = session.get("answer_history", [])

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è FatigueDetector
            user_context = self._prepare_analysis_context(user_id, session, "")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å—Ç–∞–ª–æ—Å—Ç—å
            fatigue_analysis = self.fatigue_detector.analyze_fatigue_level(user_context, history)

            # –†–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —É—Å—Ç–∞–ª–æ—Å—Ç–∏
            fatigue_level = fatigue_analysis["fatigue_level"]

            if fatigue_level == "high_fatigue":
                # –í—ã—Å–æ–∫–∞—è —É—Å—Ç–∞–ª–æ—Å—Ç—å - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å
                logger.info(f"üò¥ High fatigue detected for user {user_id} - suggesting end session")
                session["fatigue_recommendation"] = "end_session"
                session["fatigue_analysis"] = fatigue_analysis
                return False

            elif fatigue_level == "medium_fatigue":
                # –°—Ä–µ–¥–Ω—è—è —É—Å—Ç–∞–ª–æ—Å—Ç—å - –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø–∞—É–∑—É, –Ω–æ –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
                logger.info(f"üòê Medium fatigue detected for user {user_id} - offering pause")
                session["fatigue_recommendation"] = "offer_pause"
                session["fatigue_analysis"] = fatigue_analysis
                return True  # –ù–æ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –ø–∞—É–∑—ã

            else:
                # –≠–Ω–µ—Ä–≥–∏—è –µ—Å—Ç—å - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                logger.info(f"‚ö° User {user_id} energized - continuing session")
                session["fatigue_recommendation"] = "continue"
                return True

        except Exception as e:
            logger.error(f"‚ùå Failed to check session continuation for user {user_id}: {e}")
            return False

    async def complete_onboarding(self, user_id: int) -> Dict[str, Any]:
        """
        –ó–∞–≤–µ—Ä—à–∏—Ç—å –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
        """
        try:
            logger.info(f"üéâ Completing onboarding for user {user_id}")

            # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –∏–∑ –ë–î –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            session_db = await self.onboarding_dao.get_active_session(user_id)
            questions_answered = session_db.get("questions_answered", 0) if session_db else 0

            logger.info(f"üìä User {user_id} answered {questions_answered} questions")

            # üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏
            report_data = None
            telegram_digest = None
            if self.session_reporter and user_id in self.active_sessions:
                try:
                    session_data = self.active_sessions[user_id]
                    session_id = session_db.get("id") if session_db else None

                    if session_id:
                        logger.info(f"üìä Generating session report for user {user_id}, session {session_id}")

                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
                        report_data = await self.session_reporter.generate_session_report(
                            session_id=session_id,
                            user_id=user_id,
                            session_data=session_data
                        )

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª—ã
                        file_paths = await self.session_reporter.save_report_files(
                            report=report_data,
                            user_id=user_id,
                            session_id=session_id
                        )
                        logger.info(f"üìÑ Report saved to: {file_paths.get('markdown')}")

                        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –¥–ª—è Telegram
                        telegram_digest = self.session_reporter.format_telegram_digest(report_data)

                except Exception as e:
                    logger.error(f"‚ùå Failed to generate session report: {e}")
                    import traceback
                    traceback.print_exc()

            # –í Phase 2 –¥–æ–±–∞–≤–∏–º —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è

            result = {
                "status": "completed",
                "completion_time": datetime.now().isoformat(),
                "questions_answered": questions_answered,  # ‚úÖ –ë–µ—Ä—ë–º –∏–∑ –ë–î
                "summary": "Onboarding completed successfully",
                "next_steps": [
                    "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω",
                    "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã",
                    "–ú–æ–∂–µ—Ç–µ –Ω–∞—á–∏–Ω–∞—Ç—å —á–∞—Ç —Å AI –∫–æ—É—á–µ–º"
                ]
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω
            if telegram_digest:
                result["report_digest"] = telegram_digest

            return result

        except Exception as e:
            logger.error(f"‚ùå Failed to complete onboarding for user {user_id}: {e}")
            raise

    async def record_skipped_question(self, user_id: int, question_id: str) -> None:
        """
        –ó–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–∫—Ç –ø—Ä–æ–ø—É—Å–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–µ—Å—Å–∏–∏

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            question_id: ID –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
        """
        try:
            if user_id not in self.active_sessions:
                logger.warning(f"‚ö†Ô∏è No active session for user {user_id} to record skip")
                return

            session = self.active_sessions[user_id]
            current_question = session.get("current_question")

            if current_question:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if "question_history" not in session or session["question_history"] is None:
                    session["question_history"] = []
                if "answer_history" not in session or session["answer_history"] is None:
                    session["answer_history"] = []

                # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
                session["question_history"].append(current_question)

                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –æ –ø—Ä–æ–ø—É—Å–∫–µ (–±–µ–∑ answer_id, —Ç.–∫. –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞)
                session["answer_history"].append({
                    "answer": None,  # –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞
                    "question_id": question_id,
                    "answer_id": None,
                    "timestamp": datetime.now().isoformat(),
                    "skipped": True  # ‚úÖ –§–ª–∞–≥ –ø—Ä–æ–ø—É—Å–∫–∞ –¥–ª—è FatigueDetector
                })

                logger.info(f"‚è≠Ô∏è Recorded skip for user {user_id}, question {question_id}")

        except Exception as e:
            logger.error(f"‚ùå Failed to record skip for user {user_id}: {e}")

    async def flag_question_for_review(self, user_id: int, question_id: str, reason: str = "") -> bool:
        """
        –ü–æ–º–µ—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å –Ω–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—É (–¢–û–õ–¨–ö–û –¥–ª—è –∞–¥–º–∏–Ω–∞)

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–¥–º–∏–Ω)
            question_id: ID –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–º–µ—Ç–∫–∏
            reason: –ü—Ä–∏—á–∏–Ω–∞ –ø–æ–º–µ—Ç–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            True –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–º–µ—á–µ–Ω —É—Å–ø–µ—à–Ω–æ
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω (–±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ Phase 3)
            # if not self._is_admin(user_id):
            #     logger.warning(f"üö´ Non-admin user {user_id} tried to flag question {question_id}")
            #     return False

            logger.info(f"üöß Admin {user_id} flagging question {question_id} for review. Reason: {reason}")

            # –ü–æ–∫–∞ —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ª–æ–≥–∏, –≤ Phase 1 Task 1.5 –¥–æ–±–∞–≤–∏–º –≤ –ë–î
            logger.info(f"üè∑Ô∏è Question {question_id} flagged by admin {user_id}")

            # –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç:
            # await self.question_dao.flag_question(question_id, user_id, reason)

            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to flag question {question_id} by user {user_id}: {e}")
            return False

    def _is_admin(self, user_id: int) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–æ–º

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            True –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω
        """
        # –í CLAUDE.md —É–∫–∞–∑–∞–Ω ADMIN_USER_ID, –Ω–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–¥–µ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
        # –ü–æ–∫–∞ —á—Ç–æ –∑–∞–≥–ª—É—à–∫–∞
        ADMIN_USER_ID = "98005572"  # –¢–≤–æ–π ID –∏–∑ –ª–æ–≥–æ–≤
        return str(user_id) == ADMIN_USER_ID

    def _get_quick_insight(self, answer: str) -> str:
        """–ë—ã—Å—Ç—Ä—ã–π –∏–Ω—Å–∞–π—Ç –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ —Ñ–∏–¥–±–µ–∫–∞"""

        answer_lower = answer.lower()

        # –ü—Ä–æ—Å—Ç–∞—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        if any(word in answer_lower for word in ["—Ä–∞–¥", "—Å—á–∞—Å—Ç–ª–∏–≤", "—Ö–æ—Ä–æ—à–æ", "–æ—Ç–ª–∏—á–Ω–æ"]):
            return "–í–∏–∂—É –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –Ω–∞—Å—Ç—Ä–æ–π ‚ú®"
        elif any(word in answer_lower for word in ["–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "–¥—É–º–∞—é", "—Ä–∞–∑–º—ã—à–ª—è—é"]):
            return "–ß—É–≤—Å—Ç–≤—É—é –≥–ª—É–±–∏–Ω—É —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π ü§î"
        elif any(word in answer_lower for word in ["—Å–ª–æ–∂–Ω–æ", "—Ç—è–∂–µ–ª–æ", "—Ç—Ä—É–¥–Ω–æ"]):
            return "–ü–æ–Ω–∏–º–∞—é, —á—Ç–æ —Ç–µ–º–∞ –Ω–µ–ø—Ä–æ—Å—Ç–∞—è üíô"
        elif len(answer) > 100:
            return "–¶–µ–Ω—é –≤–∞—à—É –æ—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å üôè"
        else:
            return "–ü—Ä–∏–Ω–∏–º–∞—é –≤–∞—à –æ—Ç–≤–µ—Ç ‚úÖ"

    async def _deep_analysis_pipeline(
        self,
        user_id: int,
        question_id: str,
        answer: str,
        question_data: Dict[str, Any],
        session: Dict[str, Any],
        answer_id: Optional[int] = None,
        is_context_story: bool = False
    ):
        """
        === –§–ê–ó–ê 2: DEEP ANALYSIS (2-10 —Å–µ–∫—É–Ω–¥ –≤ —Ñ–æ–Ω–µ) ===

        –ü–æ–ª–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û–ï –†–ï–®–ï–ù–ò–ï:
        - –ü—Ä–∏–Ω–∏–º–∞–µ—Ç immutable –∫–æ–ø–∏–∏ session –∏ question_data
        - –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç race conditions
        - –ü–æ–ª–Ω–æ–µ exception handling —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        - Graceful handling –µ—Å–ª–∏ shutdown –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        - ‚úÖ –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–ï –°–¢–ê–¢–£–°–û–í –û–ë–†–ê–ë–û–¢–ö–ò (Oct 2025)
        """

        analysis_id = None
        vectorization_success = False
        dp_update_success = False

        try:
            deep_start = datetime.now()
            logger.info(f"üî¨ Starting deep analysis pipeline for user {user_id}")

            # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if question_data is None:
                logger.error(f"‚ùå question_data is None for user {user_id}, question {question_id}")
                raise ValueError("question_data cannot be None")

            if session is None:
                logger.error(f"‚ùå session is None for user {user_id}")
                raise ValueError("session cannot be None")

            # 2.1 –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_context = self._prepare_analysis_context(user_id, session, answer, answer_id)

            # 2.2 üß† –ì–õ–ê–í–ù–´–ô –ê–ù–ê–õ–ò–ó —á–µ—Ä–µ–∑ AnswerAnalyzer
            analysis_result = await self.answer_analyzer.analyze_answer(
                question_data=question_data,
                user_answer=answer,
                user_context=analysis_context
            )

            # 2.3 üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ –ë–î (—Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ —Å—Ç–∞—Ç—É—Å–∞–º–∏ pending)
            session_id = session.get("session_id")
            if session_id and self.onboarding_dao:
                # –ü–æ–ª—É—á–∞–µ–º answer_id –∏–∑ –ë–î –¥–ª—è —Å–≤—è–∑–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º
                answer_id = analysis_context.get("answer_id")
                if answer_id:
                    if is_context_story:
                        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ save_context_story_analysis
                        analysis_id = await self.onboarding_dao.save_context_story_analysis(answer_id, analysis_result)
                        logger.info(f"üíô Context story analysis saved to DB with ID {analysis_id}")
                    else:
                        # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç - —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ—Ä–µ–∑ save_analysis_result
                        analysis_id = await self.onboarding_dao.save_analysis_result(answer_id, analysis_result)
                        logger.info(f"üíæ Analysis saved to DB with ID {analysis_id}")
                else:
                    logger.warning("‚ö†Ô∏è No answer_id found - cannot save analysis")
            else:
                logger.warning("‚ö†Ô∏è Database not available - analysis not saved")

            # 2.3.5 üß¨ –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –¶–ò–§–†–û–í–û–ô –õ–ò–ß–ù–û–°–¢–ò
            try:
                # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–∏—á–Ω–æ—Å—Ç—å
                existing_personality = None
                if self.personality_dao:
                    existing_personality = await self.personality_dao.get_personality(user_id)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ—Ç–≤–µ—Ç–∞
                extracted_personality = await self.personality_extractor.extract_from_answer(
                    question_text=question_data.get("text", ""),
                    user_answer=answer,
                    question_metadata=question_data.get("classification", {}),
                    existing_personality=existing_personality
                )

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ª–∏—á–Ω–æ—Å—Ç—å—é
                if existing_personality:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é
                    merged = self.personality_extractor.merge_extractions(
                        existing_personality,
                        extracted_personality
                    )
                    await self.personality_dao.update_personality(user_id, merged, merge=True)
                    logger.info(f"üß¨ Updated digital personality for user {user_id}")
                else:
                    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é
                    await self.personality_dao.create_personality(user_id, extracted_personality)
                    logger.info(f"üß¨ Created digital personality for user {user_id}")

                # ‚úÖ –û—Ç–º–µ—á–∞–µ–º —É—Å–ø–µ—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è DP
                dp_update_success = True
                if analysis_id and self.onboarding_dao:
                    await self.onboarding_dao.update_dp_update_status(analysis_id, "success")

            except Exception as e:
                logger.error(f"‚ùå Failed to extract/update personality for user {user_id}: {e}")
                # ‚úÖ –û—Ç–º–µ—á–∞–µ–º –æ—à–∏–±–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è DP
                if analysis_id and self.onboarding_dao:
                    await self.onboarding_dao.update_dp_update_status(
                        analysis_id,
                        "failed",
                        str(e)[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—à–∏–±–∫–∏
                    )

            # 2.4 üìà –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ Qdrant
            try:
                answer_history = session.get("answer_history") or []
                vector_success = await self.embedding_creator.create_personality_vector(
                    user_id=user_id,
                    analysis_result=analysis_result,
                    is_update=(len(answer_history) > 1)  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç
                )

                # ‚úÖ –û—Ç–º–µ—á–∞–µ–º —É—Å–ø–µ—Ö/–Ω–µ—É–¥–∞—á—É –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                if analysis_id and self.onboarding_dao:
                    if vector_success:
                        vectorization_success = True
                        await self.onboarding_dao.update_vectorization_status(analysis_id, "success")
                    else:
                        await self.onboarding_dao.update_vectorization_status(
                            analysis_id,
                            "failed",
                            "create_personality_vector returned False"
                        )

            except Exception as e:
                logger.error(f"‚ùå Failed to create vectors for user {user_id}: {e}")
                # ‚úÖ –û—Ç–º–µ—á–∞–µ–º –æ—à–∏–±–∫—É –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
                if analysis_id and self.onboarding_dao:
                    await self.onboarding_dao.update_vectorization_status(
                        analysis_id,
                        "failed",
                        str(e)[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—à–∏–±–∫–∏
                    )

            # 2.5 –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –¥–ª—è —Ä–æ—É—Ç–µ—Ä–∞
            # –í–ê–ñ–ù–û: –ù–ï –æ–±–Ω–æ–≤–ª—è–µ–º shared session –Ω–∞–ø—Ä—è–º—É—é (—ç—Ç–æ immutable –∫–æ–ø–∏—è)
            # –†–µ–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç —á–µ—Ä–µ–∑ –ë–î –∏–ª–∏ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º get_session
            router_recommendations = analysis_result.get("router_recommendations", {})

            # 2.6 –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            deep_time = (datetime.now() - deep_start).total_seconds() * 1000
            logger.info(
                f"‚úÖ Deep analysis completed for user {user_id} in {deep_time:.0f}ms "
                f"(model: {analysis_result.get('processing_metadata', {}).get('model_used', 'unknown')}, "
                f"vectors: {'‚úÖ' if vectorization_success else '‚ùå'}, "
                f"DP: {'‚úÖ' if dp_update_success else '‚ùå'})"
            )

            # ‚úÖ 2.7 –û—Ç–º–µ—á–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ background task
            if analysis_id and self.onboarding_dao:
                await self.onboarding_dao.mark_background_task_completed(
                    analysis_id,
                    int(deep_time),
                    success=(vectorization_success and dp_update_success)
                )

            # 2.8 –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ –æ–Ω–ª–∞–π–Ω)
            # TODO: –î–æ–±–∞–≤–∏—Ç—å push notification –∏–ª–∏ websocket –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç UI
            # await self._notify_deep_analysis_ready(user_id, analysis_result)

        except asyncio.CancelledError:
            # ‚úÖ Graceful handling –ø—Ä–∏ shutdown
            logger.warning(f"üõë Deep analysis cancelled for user {user_id} due to shutdown")
            raise  # Re-raise —á—Ç–æ–±—ã task –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è

        except Exception as e:
            logger.error(
                f"‚ùå Deep analysis pipeline failed for user {user_id}: {e}",
                exc_info=True  # –ü–æ–ª–Ω—ã–π traceback –¥–ª—è debugging
            )

            # ‚úÖ –û—Ç–º–µ—á–∞–µ–º failed —Å—Ç–∞—Ç—É—Å—ã –µ—Å–ª–∏ –Ω–µ –±—ã–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
            if analysis_id and self.onboarding_dao:
                try:
                    # –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞ - –æ—Ç–º–µ—á–∞–µ–º failed
                    if not vectorization_success:
                        await self.onboarding_dao.update_vectorization_status(
                            analysis_id,
                            "failed",
                            str(e)[:500]
                        )

                    # –ï—Å–ª–∏ DP –Ω–µ –æ–±–Ω–æ–≤–ª–µ–Ω - –æ—Ç–º–µ—á–∞–µ–º failed
                    if not dp_update_success:
                        await self.onboarding_dao.update_dp_update_status(
                            analysis_id,
                            "failed",
                            str(e)[:500]
                        )

                    # –û—Ç–º–µ—á–∞–µ–º task –∫–∞–∫ failed
                    deep_time = (datetime.now() - deep_start).total_seconds() * 1000
                    await self.onboarding_dao.mark_background_task_completed(
                        analysis_id,
                        int(deep_time),
                        success=False
                    )
                except Exception as inner_e:
                    logger.error(f"‚ùå Failed to update error statuses: {inner_e}")

    def _prepare_analysis_context(self, user_id: int, session: Dict, answer: str, answer_id: Optional[int] = None) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""

        history = session.get("answer_history") or []

        # –ó–∞—â–∏—Ç–∞ –æ—Ç None –≤ answer
        safe_answer = answer if answer is not None else ""

        return {
            "user_id": user_id,
            "answer_id": answer_id,  # –î–ª—è —Å–≤—è–∑–∏ –∞–Ω–∞–ª–∏–∑–∞ —Å –æ—Ç–≤–µ—Ç–æ–º –≤ –ë–î
            "question_number": len(history) + 1,
            "session_started": session.get("started_at"),
            "previous_answers_count": len(history),
            "previous_domains": [
                item.get("question", {}).get("classification", {}).get("domain", "UNKNOWN")
                for item in session.get("question_history", [])
            ],

            # –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞
            "user_answer": safe_answer,
            "answer_length": len(safe_answer),
            "response_time_seconds": 30,  # TODO: –†–µ–∞–ª—å–Ω–æ –∏–∑–º–µ—Ä—è—Ç—å –≤—Ä–µ–º—è

            # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            "trust_level": session.get("trust_level", 0.5),
            "energy_level": session.get("energy_level", 0.7),
            "fatigue_level": session.get("user_fatigue_level", 0.0),
            "engagement_level": self._estimate_engagement(history, safe_answer),

            # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
            "session_length_minutes": self._calculate_session_length(session),
            "avg_answer_length": self._calculate_avg_answer_length(history),
            "emotional_trajectory": self._analyze_emotional_trajectory(history)
        }

    def _estimate_engagement(self, history: List[Dict], current_answer: str) -> float:
        """–û—Ü–µ–Ω–∫–∞ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        # –ó–∞—â–∏—Ç–∞ –æ—Ç None –≤ current_answer
        safe_current_answer = current_answer if current_answer is not None else ""

        if not history:
            return 0.7 if len(safe_current_answer) > 50 else 0.4

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤ (—Ñ–∏–ª—å—Ç—Ä—É–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è)
        recent_lengths = [
            len(item.get("answer") or "")
            for item in history[-3:]
            if item.get("answer") is not None
        ]
        recent_lengths.append(len(safe_current_answer))

        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç—ã —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –¥–ª–∏–Ω–Ω–µ–µ - —Ä–∞—Å—Ç–µ—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å
        if len(recent_lengths) > 1:
            trend = (recent_lengths[-1] - recent_lengths[0]) / max(1, len(recent_lengths))
            base_engagement = min(1.0, len(safe_current_answer) / 100.0)
            return max(0.1, min(1.0, base_engagement + trend / 100.0))

        return 0.5

    def _calculate_session_length(self, session: Dict) -> float:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –¥–ª–∏–Ω—É —Å–µ—Å—Å–∏–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö"""

        started = session.get("started_at")
        if not started:
            return 0.0

        if isinstance(started, str):
            try:
                started_dt = datetime.fromisoformat(started.replace("Z", "+00:00"))
            except:
                return 0.0
        else:
            started_dt = started

        return (datetime.now() - started_dt.replace(tzinfo=None)).total_seconds() / 60.0

    def _calculate_avg_answer_length(self, history: List[Dict]) -> float:
        """–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–æ–≤"""

        if not history:
            return 0.0

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (–Ω–µ –ø—Ä–æ–ø—É—Å–∫–∏)
        lengths = [len(item.get("answer", "")) for item in (history or []) if item.get("answer")]
        return sum(lengths) / len(lengths) if lengths else 0.0

    def _analyze_emotional_trajectory(self, history: List[Dict]) -> str:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —Å–µ—Å—Å–∏–∏"""

        if not history or len(history) < 2:
            return "starting"

        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (—Ñ–∏–ª—å—Ç—Ä—É–µ–º None)
        recent_answers = [
            item.get("answer") or ""
            for item in history[-3:]
            if item.get("answer") is not None
        ]

        positive_words = sum(
            answer.lower().count(word)
            for answer in recent_answers
            for word in ["—Ö–æ—Ä–æ—à–æ", "–æ—Ç–ª–∏—á–Ω–æ", "—Ä–∞–¥", "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "–Ω—Ä–∞–≤–∏—Ç—Å—è"]
        )

        negative_words = sum(
            answer.lower().count(word)
            for answer in recent_answers
            for word in ["—Å–ª–æ–∂–Ω–æ", "—Ç—è–∂–µ–ª–æ", "—Ç—Ä—É–¥–Ω–æ", "—É—Å—Ç–∞–ª"]
        )

        if positive_words > negative_words:
            return "positive_trend"
        elif negative_words > positive_words:
            return "challenging_trend"
        else:
            return "stable_neutral"

    async def _retry_pending_answers(self, user_id: int):
        """
        –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ pending –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        try:
            # –ò—â–µ–º pending –æ—Ç–≤–µ—Ç—ã —Å retry_count < 3
            query = """
                SELECT ua.id, ua.session_id, ua.question_json_id, ua.raw_answer, ua.retry_count
                FROM selfology.user_answers_new ua
                JOIN selfology.onboarding_sessions os ON ua.session_id = os.id
                WHERE os.user_id = $1
                  AND ua.analysis_status = 'pending'
                  AND ua.retry_count < 3
                ORDER BY ua.id
                LIMIT 10
            """

            async with self.db_service.get_connection() as conn:
                pending_answers = await conn.fetch(query, user_id)

            if not pending_answers:
                logger.info(f"‚úÖ No pending answers to retry for user {user_id}")
                return

            logger.info(f"üîÑ Found {len(pending_answers)} pending answers to retry for user {user_id}")

            # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            for answer in pending_answers:
                answer_id = answer['id']
                question_id = answer['question_json_id']
                raw_answer = answer['raw_answer']
                retry_count = answer['retry_count']

                logger.info(f"üîÑ Retrying analysis for answer {answer_id} (attempt {retry_count + 1}/3)")

                try:
                    # –ü–æ–ª—É—á–∞–µ–º –≤–æ–ø—Ä–æ—Å –∏–∑ core
                    question = self.question_core.get_question_by_id(question_id)

                    if not question:
                        logger.warning(f"‚ö†Ô∏è Question {question_id} not found, skipping")
                        continue

                    # –ó–∞–ø—É—Å–∫–∞–µ–º deep analysis –∑–∞–Ω–æ–≤–æ
                    await self._run_deep_analysis_pipeline(
                        user_id,
                        answer_id,
                        question['text'],
                        raw_answer,
                        question.get('classification', {})
                    )

                    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º retry_count
                    update_query = """
                        UPDATE selfology.user_answers_new
                        SET retry_count = retry_count + 1
                        WHERE id = $1
                    """
                    async with self.db_service.get_connection() as conn:
                        await conn.execute(update_query, answer_id)

                    logger.info(f"‚úÖ Successfully retried analysis for answer {answer_id}")

                except Exception as e:
                    logger.error(f"‚ùå Error retrying answer {answer_id}: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–∏–º –æ—Ç–≤–µ—Ç–æ–º
                    continue

            logger.info(f"‚úÖ Completed retry for {len(pending_answers)} pending answers")

        except Exception as e:
            logger.error(f"‚ùå Error in _retry_pending_answers: {e}")

    async def _setup_vector_storage(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è"""

        try:
            logger.info("üìà Setting up vector storage collections...")

            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ EmbeddingCreator
            setup_success = await self.embedding_creator.setup_qdrant_collections()

            if setup_success:
                logger.info("‚úÖ Vector storage collections ready")
            else:
                logger.warning("‚ö†Ô∏è Vector storage setup incomplete - will retry later")

        except Exception as e:
            logger.error(f"‚ùå Error setting up vector storage: {e}")

    async def get_system_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ–π —Å–∏—Å—Ç–µ–º—ã –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞"""

        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            analysis_stats = await self.answer_analyzer.get_analysis_stats()
            embedding_stats = await self.embedding_creator.get_embedding_stats()

            return {
                "system_version": "2.0",
                "status": "operational",
                "components": {
                    "question_router": "ready",
                    "answer_analyzer": "ready",
                    "embedding_creator": "ready",
                    "vector_storage": "mock_mode"  # TODO: real Qdrant status
                },
                "active_sessions": len(self.active_sessions),
                "statistics": {
                    "analysis": analysis_stats,
                    "embeddings": embedding_stats
                },
                "last_updated": datetime.now().isoformat()
            }

        except Exception as e:
            logger.error(f"‚ùå Error getting system status: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    # ============================================================================
    # GRACEFUL SHUTDOWN & OBSERVABILITY METHODS
    # ============================================================================

    async def shutdown(self, timeout: float = 30.0) -> Dict[str, Any]:
        """
        Graceful shutdown orchestrator —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è background tasks

        –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û–ï –†–ï–®–ï–ù–ò–ï:
        - –°–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ–º tasks –æ shutdown —á–µ—Ä–µ–∑ event
        - –ñ–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö tasks —Å timeout
        - –û—Ç–º–µ–Ω—è–µ—Ç –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ tasks –ø–æ—Å–ª–µ timeout
        - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É shutdown –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

        Args:
            timeout: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è tasks (—Å–µ–∫—É–Ω–¥—ã)

        Returns:
            Dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π shutdown
        """
        logger.info(f"üõë Starting graceful shutdown of OnboardingOrchestrator (timeout: {timeout}s)")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º shutdown event –¥–ª—è —Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ tasks
        self._shutdown_event.set()

        if not self._background_tasks:
            logger.info("‚úÖ No background tasks to wait for")
            return {
                "status": "clean_shutdown",
                "tasks_completed": 0,
                "tasks_cancelled": 0,
                "shutdown_time": 0.0
            }

        shutdown_start = datetime.now()
        initial_task_count = len(self._background_tasks)

        logger.info(f"‚è≥ Waiting for {initial_task_count} background tasks to complete (timeout: {timeout}s)")

        try:
            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö tasks —Å timeout
            await asyncio.wait_for(
                asyncio.gather(*self._background_tasks, return_exceptions=True),
                timeout=timeout
            )

            completed_count = initial_task_count - len(self._background_tasks)
            shutdown_time = (datetime.now() - shutdown_start).total_seconds()

            logger.info(
                f"‚úÖ All background tasks completed gracefully "
                f"({completed_count} tasks in {shutdown_time:.2f}s)"
            )

            return {
                "status": "graceful_shutdown",
                "tasks_completed": completed_count,
                "tasks_cancelled": 0,
                "shutdown_time": shutdown_time
            }

        except asyncio.TimeoutError:
            # Timeout - –æ—Ç–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è tasks
            remaining_tasks = list(self._background_tasks)
            cancelled_count = len(remaining_tasks)

            logger.warning(
                f"‚è±Ô∏è Shutdown timeout ({timeout}s) - cancelling {cancelled_count} remaining tasks"
            )

            for task in remaining_tasks:
                task.cancel()
                task_name = task.get_name() or "unnamed"
                logger.warning(f"‚ùå Cancelling task: {task_name}")

            # –ñ–¥–µ–º –æ—Ç–º–µ–Ω—ã tasks (–±—ã—Å—Ç—Ä–æ)
            await asyncio.gather(*remaining_tasks, return_exceptions=True)

            shutdown_time = (datetime.now() - shutdown_start).total_seconds()
            completed_count = initial_task_count - cancelled_count

            logger.warning(
                f"‚ö†Ô∏è Forced shutdown completed: {completed_count} completed, "
                f"{cancelled_count} cancelled ({shutdown_time:.2f}s)"
            )

            return {
                "status": "forced_shutdown",
                "tasks_completed": completed_count,
                "tasks_cancelled": cancelled_count,
                "shutdown_time": shutdown_time
            }

    def get_background_tasks_status(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–∫—Ç–∏–≤–Ω—ã—Ö background tasks –¥–ª—è observability

        Returns:
            Dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –≤—Å–µ—Ö background tasks
        """
        tasks_info = []

        for task in self._background_tasks:
            task_name = task.get_name() or "unnamed"
            task_info = {
                "name": task_name,
                "done": task.done(),
                "cancelled": task.cancelled()
            }

            # –î–æ–±–∞–≤–ª—è–µ–º exception info –µ—Å–ª–∏ task –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π
            if task.done() and not task.cancelled():
                try:
                    exc = task.exception()
                    if exc:
                        task_info["exception"] = str(exc)
                        task_info["exception_type"] = type(exc).__name__
                except asyncio.CancelledError:
                    task_info["cancelled"] = True

            tasks_info.append(task_info)

        return {
            "total_tasks": len(self._background_tasks),
            "active_tasks": sum(1 for t in self._background_tasks if not t.done()),
            "completed_tasks": sum(1 for t in self._background_tasks if t.done() and not t.cancelled()),
            "cancelled_tasks": sum(1 for t in self._background_tasks if t.cancelled()),
            "failed_tasks": sum(
                1 for t in self._background_tasks
                if t.done() and not t.cancelled() and t.exception()
            ),
            "tasks": tasks_info,
            "shutdown_initiated": self._shutdown_event.is_set()
        }

    # ============================================================
    # –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° –ü–†–û–ì–†–ê–ú–ú–ê–ú–ò (Phase 4)
    # ============================================================

    async def _ensure_database_initialized(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î –∏ ProgramRouter –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã."""
        if not self.db_service:
            from os import environ
            self.db_service = DatabaseService(
                host=environ.get("DB_HOST", "localhost"),
                port=int(environ.get("DB_PORT", 5434)),
                user=environ.get("DB_USER", "selfology_user"),
                password=environ.get("DB_PASSWORD", "selfology_secure_2024"),
                database=environ.get("DB_NAME", "selfology")
            )
            await self.db_service.initialize()
            self.onboarding_dao = OnboardingDAO(self.db_service)
            self.personality_dao = DigitalPersonalityDAO(self.db_service)
            await self.onboarding_dao.create_onboarding_tables()
            self.question_router.onboarding_dao = self.onboarding_dao
            logger.info("üóÑÔ∏è Database initialized for program mode")

        if not self.program_router and self.db_service and self.db_service.pool:
            self.program_router = ProgramRouter(db_pool=self.db_service.pool)
            logger.info("üì¶ ProgramRouter initialized for block-based programs")

    async def get_available_programs(self, user_id: int) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–æ–≥—Ä–∞–º–º —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
        """
        await self._ensure_database_initialized()

        if not self.program_router:
            logger.warning("‚ö†Ô∏è ProgramRouter not initialized, returning empty list")
            return []

        try:
            programs = await self.program_router.get_available_programs(user_id)
            logger.info(f"üìã Found {len(programs)} available programs for user {user_id}")
            return programs
        except Exception as e:
            logger.error(f"‚ùå Error getting programs: {e}")
            return []

    async def start_program(
        self,
        user_id: int,
        program_id: str
    ) -> Dict[str, Any]:
        """
        –ù–∞—á–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            program_id: ID –ø—Ä–æ–≥—Ä–∞–º–º—ã

        Returns:
            Dict —Å –ø–µ—Ä–≤—ã–º –≤–æ–ø—Ä–æ—Å–æ–º –ø—Ä–æ–≥—Ä–∞–º–º—ã
        """
        await self._ensure_database_initialized()

        if not self.program_router:
            raise Exception("ProgramRouter not initialized")

        try:
            logger.info(f"üì¶ Starting program {program_id} for user {user_id}")

            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–≥—Ä–∞–º–º—ã (—Å–æ–∑–¥–∞—ë—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            context = await self.program_router.get_program_context(user_id, program_id)
            if not context:
                raise Exception(f"Program {program_id} not found")

            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å
            question = await self.program_router.get_first_question_in_program(
                user_id, program_id
            )

            if not question:
                raise Exception(f"No questions in program {program_id}")

            return {
                "status": "started",
                "program_id": program_id,
                "program_name": context.program_name,
                "question": question,
                "block_name": question.get("block_name"),
                "block_type": question.get("block_type"),
                "total_blocks": context.total_blocks
            }

        except Exception as e:
            logger.error(f"‚ùå Error starting program: {e}")
            raise

    async def get_next_program_question(
        self,
        user_id: int,
        program_id: str,
        answered_question_ids: List[str]
    ) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ.

        –õ–æ–≥–∏–∫–∞:
        1. –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ —Ç–µ–∫—É—â–µ–º –±–ª–æ–∫–µ
        2. –ï—Å–ª–∏ –±–ª–æ–∫ –∑–∞–∫–æ–Ω—á–µ–Ω, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –±–ª–æ–∫—É
        3. –ï—Å–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–∫–æ–Ω—á–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            program_id: ID –ø—Ä–æ–≥—Ä–∞–º–º—ã
            answered_question_ids: –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—á–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤

        Returns:
            –°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ None –µ—Å–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
        """
        if not self.program_router:
            raise Exception("ProgramRouter not initialized")

        try:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ —Ç–µ–∫—É—â–µ–º –±–ª–æ–∫–µ
            question = await self.program_router.get_next_question_in_block(
                user_id, program_id, answered_question_ids
            )

            if question:
                return {
                    "status": "in_progress",
                    "question": question,
                    "block_name": question.get("block_name"),
                    "block_type": question.get("block_type")
                }

            # –ë–ª–æ–∫ –∑–∞–∫–æ–Ω—á–µ–Ω, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É
            next_block = await self.program_router.get_next_block(user_id, program_id)

            if not next_block:
                # –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
                await self.program_router.complete_program(user_id, program_id)
                return {
                    "status": "completed",
                    "message": "–ü–æ–∑–¥—Ä–∞–≤–ª—è–µ–º! –í—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É."
                }

            # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π –≤–æ–ø—Ä–æ—Å –Ω–æ–≤–æ–≥–æ –±–ª–æ–∫–∞
            question = await self.program_router.get_next_question_in_block(
                user_id, program_id, answered_question_ids
            )

            if question:
                return {
                    "status": "new_block",
                    "block_name": next_block["name"],
                    "block_type": next_block["type"],
                    "question": question
                }

            # –ù–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ –Ω–æ–≤–æ–º –±–ª–æ–∫–µ (–Ω–µ –¥–æ–ª–∂–Ω–æ —Å–ª—É—á–∏—Ç—å—Å—è)
            logger.warning(f"‚ö†Ô∏è No questions in new block: {next_block['block_id']}")
            return None

        except Exception as e:
            logger.error(f"‚ùå Error getting next program question: {e}")
            raise

    async def get_program_progress(
        self,
        user_id: int,
        program_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ.

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
        """
        if not self.program_router:
            return None

        try:
            context = await self.program_router.get_program_context(user_id, program_id)
            if not context:
                return None

            return {
                "program_id": program_id,
                "program_name": context.program_name,
                "current_block": context.current_block_id,
                "current_block_type": context.current_block_type.value if context.current_block_type else None,
                "blocks_completed": len(context.blocks_completed),
                "total_blocks": context.total_blocks,
                "completion_percentage": context.completion_percentage,
                "questions_answered": context.questions_answered if hasattr(context, 'questions_answered') else 0
            }

        except Exception as e:
            logger.error(f"‚ùå Error getting program progress: {e}")
            return None

    async def process_program_answer(
        self,
        user_id: int,
        program_id: str,
        question_id: str,
        answer_text: str
    ) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ä–µ–∂–∏–º–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã.

        –í—ã–ø–æ–ª–Ω—è–µ—Ç:
        1. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –ë–î (—Å program_id)
        2. –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ AnswerAnalyzer
        3. –°–æ–∑–¥–∞–Ω–∏–µ embeddings
        4. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info(f"üìù Processing program answer: user={user_id}, program={program_id}, question={question_id}")

        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ program_questions
            question_metadata = await self._get_program_question_metadata(question_id)

            # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ë–î
            answer_id = await self.onboarding_dao.save_answer(
                user_id=user_id,
                question_id=question_id,
                answer_text=answer_text
            )

            # 3. –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ (background task)
            asyncio.create_task(self._analyze_program_answer_background(
                user_id=user_id,
                answer_id=answer_id,
                question_id=question_id,
                answer_text=answer_text,
                question_metadata=question_metadata,
                program_id=program_id
            ))

            # 4. –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é
            session = self.sessions.get(user_id)
            if session:
                session['questions_answered'] = session.get('questions_answered', 0) + 1

            return {
                "status": "success",
                "answer_id": answer_id,
                "quick_insight": "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à –æ—Ç–≤–µ—Ç! –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é..."
            }

        except Exception as e:
            logger.error(f"‚ùå Error processing program answer: {e}")
            return {
                "status": "error",
                "error": str(e)
            }

    async def _get_program_question_metadata(self, question_id: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ program_questions."""
        try:
            async with self.db_pool.acquire() as conn:
                row = await conn.fetchrow("""
                    SELECT
                        pq.text,
                        pq.depth_level,
                        pq.domain,
                        pq.energy_dynamic,
                        pq.emotional_weight,
                        pq.recommended_model,
                        pb.block_type,
                        pb.name as block_name
                    FROM selfology.program_questions pq
                    JOIN selfology.program_blocks pb ON pq.block_id = pb.block_id
                    WHERE pq.question_id = $1
                """, question_id)

                if row:
                    return dict(row)
                return {}

        except Exception as e:
            logger.error(f"‚ùå Error getting question metadata: {e}")
            return {}

    async def _analyze_program_answer_background(
        self,
        user_id: int,
        answer_id: int,
        question_id: str,
        answer_text: str,
        question_metadata: Dict[str, Any],
        program_id: str
    ):
        """Background task –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º–µ."""
        try:
            logger.info(f"üî¨ Background analysis for program answer: user={user_id}, answer={answer_id}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º question dict
            question = {
                "id": question_id,
                "text": question_metadata.get("text", ""),
                "classification": {
                    "depth_level": question_metadata.get("depth_level", "SURFACE"),
                    "domain": question_metadata.get("domain", "IDENTITY"),
                    "energy_dynamic": question_metadata.get("energy_dynamic", "NEUTRAL")
                }
            }

            # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ AnswerAnalyzer
            analysis_result = await self.answer_analyzer.analyze_answer(
                user_id=user_id,
                question=question,
                answer=answer_text,
                session_context={
                    "program_id": program_id,
                    "block_type": question_metadata.get("block_type"),
                    "block_name": question_metadata.get("block_name")
                }
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
            await self.onboarding_dao.save_answer_analysis(
                answer_id=answer_id,
                analysis_result=analysis_result
            )

            # –°–æ–∑–¥–∞—ë–º embeddings
            await self.embedding_creator.create_embeddings(
                user_id=user_id,
                answer_text=answer_text,
                analysis=analysis_result,
                context={
                    "program_id": program_id,
                    "question_id": question_id,
                    "block_type": question_metadata.get("block_type")
                }
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏
            await self.personality_extractor.update_profile(user_id, analysis_result)

            logger.info(f"‚úÖ Background analysis completed for answer {answer_id}")

        except Exception as e:
            logger.error(f"‚ùå Error in background analysis: {e}")
