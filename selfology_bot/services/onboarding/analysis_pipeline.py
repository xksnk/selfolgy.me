"""
AnalysisPipeline - –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

–ò–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω:
1. AI –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ (AnswerAnalyzer)
2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ª–∏—á–Ω–æ—Å—Ç–∏ (PersonalityExtractor)
3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è (DigitalPersonalityDAO)
4. –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ (EmbeddingCreator)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    pipeline = AnalysisPipeline(db_pool)
    await pipeline.initialize()
    result = await pipeline.process_answer(user_id, question_data, answer_text)
"""

import logging
import asyncio
from typing import Dict, Any, Optional
from datetime import datetime
from dataclasses import dataclass
from contextlib import asynccontextmanager

import asyncpg

logger = logging.getLogger(__name__)


class PoolWrapper:
    """
    Wrapper –¥–ª—è asyncpg.Pool —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º DatabaseService.

    DigitalPersonalityDAO –æ–∂–∏–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –º–µ—Ç–æ–¥–æ–º get_connection(),
    –∞ —É –Ω–∞—Å –µ—Å—Ç—å Pool. –≠—Ç–æ—Ç wrapper –¥–µ–ª–∞–µ—Ç –∏—Ö —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏.
    """

    def __init__(self, pool: asyncpg.Pool):
        self.pool = pool

    @asynccontextmanager
    async def get_connection(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑ –ø—É–ª–∞ (–∫–∞–∫ –≤ DatabaseService)"""
        async with self.pool.acquire() as connection:
            yield connection


@dataclass
class AnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞"""
    success: bool
    analysis_id: Optional[int] = None
    ai_analysis: Optional[Dict] = None
    personality_updated: bool = False
    vectors_created: bool = False
    processing_time_ms: int = 0
    error: Optional[str] = None


class AnalysisPipeline:
    """
    –ï–¥–∏–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–æ–≤.

    –ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç:
    - AnswerAnalyzer: AI –∞–Ω–∞–ª–∏–∑ (Big Five, —ç–º–æ—Ü–∏–∏, –∏–Ω—Å–∞–π—Ç—ã)
    - PersonalityExtractor: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    - DigitalPersonalityDAO: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –≤ PostgreSQL
    - EmbeddingCreator: –≤–µ–∫—Ç–æ—Ä—ã –≤ Qdrant
    """

    def __init__(self, db_pool: asyncpg.Pool = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.

        Args:
            db_pool: –ü—É–ª –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∫ PostgreSQL
        """
        self.db_pool = db_pool
        self._initialized = False

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –≤ initialize())
        self.answer_analyzer = None
        self.personality_extractor = None
        self.embedding_creator = None
        self.personality_dao = None

        logger.info("üìä AnalysisPipeline created (not initialized yet)")

    async def initialize(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if self._initialized:
            return True

        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (lazy import –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
            from selfology_bot.analysis.answer_analyzer import AnswerAnalyzer
            from selfology_bot.analysis.personality_extractor import PersonalityExtractor
            from selfology_bot.analysis.embedding_creator import EmbeddingCreator
            from selfology_bot.database.digital_personality_dao import DigitalPersonalityDAO

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            self.answer_analyzer = AnswerAnalyzer()
            self.personality_extractor = PersonalityExtractor()
            self.embedding_creator = EmbeddingCreator()

            # DAO —Ç—Ä–µ–±—É–µ—Ç –æ–±—ä–µ–∫—Ç —Å get_connection() - –∏—Å–ø–æ–ª—å–∑—É–µ–º wrapper
            if self.db_pool:
                db_wrapper = PoolWrapper(self.db_pool)
                self.personality_dao = DigitalPersonalityDAO(db_wrapper)
            else:
                logger.warning("‚ö†Ô∏è No db_pool - personality updates will be skipped")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            await self._setup_qdrant_collections()

            self._initialized = True
            logger.info("‚úÖ AnalysisPipeline initialized with all components")
            return True

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize AnalysisPipeline: {e}")
            return False

    async def _setup_qdrant_collections(self):
        """–°–æ–∑–¥–∞—Ç—å Qdrant –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        if self.embedding_creator:
            try:
                await self.embedding_creator.setup_qdrant_collections()
                logger.info("‚úÖ Qdrant collections ready")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Qdrant setup warning: {e}")

    async def process_answer(
        self,
        user_id: int,
        question_data: Dict[str, Any],
        answer_text: str,
        answer_history: Optional[list] = None
    ) -> AnalysisResult:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            question_data: –î–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å–∞ (text, id, metadata)
            answer_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            answer_history: –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)

        Returns:
            AnalysisResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        if not self._initialized:
            await self.initialize()

        start_time = datetime.now()
        result = AnalysisResult(success=False)

        try:
            logger.info(f"üî¨ Starting analysis pipeline for user {user_id}")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # –≠–¢–ê–ü 1: AI –ê–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            user_context = self._build_user_context(user_id, answer_history)

            ai_analysis = await self.answer_analyzer.analyze_answer(
                question_data=question_data,
                user_answer=answer_text,
                user_context=user_context
            )

            result.ai_analysis = ai_analysis
            logger.info(f"‚úÖ AI analysis complete for user {user_id}")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # –≠–¢–ê–ü 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            if self.personality_dao:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
                    existing_personality = await self.personality_dao.get_personality(user_id)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞
                    extracted = await self.personality_extractor.extract_from_answer(
                        question_text=question_data.get("text", ""),
                        user_answer=answer_text,
                        question_metadata=question_data.get("block_metadata", {}),
                        existing_personality=existing_personality
                    )

                    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –ø—Ä–æ—Ñ–∏–ª—å
                    if existing_personality:
                        merged = self.personality_extractor.merge_extractions(
                            existing_personality,
                            extracted
                        )
                        await self.personality_dao.update_personality(user_id, merged, merge=True)
                        logger.info(f"üß¨ Updated digital personality for user {user_id}")
                    else:
                        await self.personality_dao.create_personality(user_id, extracted)
                        logger.info(f"üß¨ Created digital personality for user {user_id}")

                    result.personality_updated = True

                except Exception as e:
                    logger.error(f"‚ùå Personality update failed for user {user_id}: {e}")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # –≠–¢–ê–ü 3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ Qdrant
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            if self.embedding_creator:
                try:
                    is_update = bool(answer_history and len(answer_history) > 0)

                    vector_success = await self.embedding_creator.create_personality_vector(
                        user_id=user_id,
                        analysis_result=ai_analysis,
                        is_update=is_update
                    )

                    result.vectors_created = vector_success
                    if vector_success:
                        logger.info(f"üìä Vectors created for user {user_id}")
                    else:
                        logger.warning(f"‚ö†Ô∏è Vector creation returned False for user {user_id}")

                except Exception as e:
                    logger.error(f"‚ùå Vector creation failed for user {user_id}: {e}")

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # –§–ò–ù–ê–õ: –ü–æ–¥—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            result.processing_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            result.success = True

            logger.info(
                f"‚úÖ Analysis pipeline completed for user {user_id} in {result.processing_time_ms}ms "
                f"(personality: {'‚úÖ' if result.personality_updated else '‚ùå'}, "
                f"vectors: {'‚úÖ' if result.vectors_created else '‚ùå'})"
            )

        except Exception as e:
            result.error = str(e)
            result.processing_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            logger.error(f"‚ùå Analysis pipeline failed for user {user_id}: {e}", exc_info=True)

        return result

    def _build_user_context(
        self,
        user_id: int,
        answer_history: Optional[list] = None
    ) -> Dict[str, Any]:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            "user_id": user_id,
            "answer_history": answer_history or [],
            "total_answers": len(answer_history) if answer_history else 0,
            "session_start": datetime.now().isoformat()
        }

    async def shutdown(self):
        """Graceful shutdown –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        logger.info("üõë AnalysisPipeline shutting down")
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç —è–≤–Ω–æ–≥–æ shutdown
        self._initialized = False
