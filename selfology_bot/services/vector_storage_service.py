"""
Vector Storage Service Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ embeddings Ð² Qdrant

Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ 5 ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸ÑÐ¼Ð¸:
- episodic_memory (768d)
- semantic_knowledge (2048d)
- emotional_thematic (1536d)
- psychological_constructs (1024d)
- meta_patterns (1024d)
"""

import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Filter, FieldCondition, MatchValue
import numpy as np
import logging

from selfology_bot.services.embedding_service import get_embedding_service
from core.error_collector import error_collector

logger = logging.getLogger(__name__)


class VectorStorageService:
    """
    Unified service Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² 5 ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸ÑÑ… Qdrant
    """

    def __init__(self, host: str = "localhost", port: int = 6333):
        self.client = QdrantClient(host=host, port=port)
        self.embedding_service = get_embedding_service()

        # ÐšÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸ Ð¸ Ð¸Ñ… Ñ€Ð°Ð·Ð¼ÐµÑ€Ð½Ð¾ÑÑ‚Ð¸
        self.collections = {
            "episodic_memory": 768,
            "semantic_knowledge": 2048,
            "emotional_thematic": 1536,
            "psychological_constructs": 1024,
            "meta_patterns": 1024
        }

        logger.info(f"VectorStorageService initialized (Qdrant: {host}:{port})")

    # ===================
    # SETUP METHODS
    # ===================

    async def setup_collections(self) -> bool:
        """
        Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ 5 ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¹ Ð´Ð»Ñ VectorStorageService

        Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ Ð¾Ð½Ð±Ð¾Ñ€Ð´Ð¸Ð½Ð³Ð° ÐŸÐ•Ð Ð•Ð” Ð¿ÐµÑ€Ð²Ñ‹Ð¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼
        """
        from qdrant_client.models import VectorParams, Distance

        try:
            logger.info("ðŸ—ï¸ Setting up VectorStorageService collections...")

            collections_config = [
                {
                    "name": "episodic_memory",
                    "size": 768,  # RuBERT
                    "distance": Distance.COSINE,
                    "description": "Raw user answers for semantic search"
                },
                {
                    "name": "semantic_knowledge",
                    "size": 2048,  # OpenAI text-embedding-3-large
                    "distance": Distance.COSINE,
                    "description": "AI analyses and psychological insights"
                },
                {
                    "name": "emotional_thematic",
                    "size": 1536,  # Hybrid (RuBERT 768 + emotion 768)
                    "distance": Distance.COSINE,
                    "description": "Emotional patterns and themes"
                },
                {
                    "name": "psychological_constructs",
                    "size": 1024,  # OpenAI 1024d
                    "distance": Distance.COSINE,
                    "description": "Core beliefs, distortions, defenses"
                },
                {
                    "name": "meta_patterns",
                    "size": 1024,  # OpenAI 1024d
                    "distance": Distance.COSINE,
                    "description": "Blind spots, growth areas, meta-patterns"
                }
            ]

            created_count = 0
            for config in collections_config:
                try:
                    # Check if exists
                    existing = self.client.get_collections()
                    collection_names = [c.name for c in existing.collections]

                    if config["name"] in collection_names:
                        logger.info(f"âœ… Collection '{config['name']}' already exists")
                        created_count += 1
                        continue

                    # Create collection
                    self.client.create_collection(
                        collection_name=config["name"],
                        vectors_config=VectorParams(
                            size=config["size"],
                            distance=config["distance"]
                        )
                    )
                    logger.info(f"âœ… Created '{config['name']}' ({config['description']})")
                    created_count += 1

                except Exception as e:
                    logger.error(f"âŒ Failed to create '{config['name']}': {e}")
                    raise  # ÐÐ• Ð¿Ð¾Ð´Ð°Ð²Ð»ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÑƒ

            success = created_count == len(collections_config)
            if success:
                logger.info(f"ðŸŽ‰ VectorStorageService: {created_count} collections ready")

            return success

        except Exception as e:
            logger.error(f"âŒ VectorStorageService setup failed: {e}")
            return False

    # ===================
    # STORE METHODS
    # ===================

    async def store_episodic(
        self,
        user_id: int,
        text: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÑÑ‹Ñ€Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð² episodic_memory

        Returns: point_id (UUID)
        """
        # Generate embedding
        embedding = self.embedding_service.encode_episodic(text)

        # Create point
        point_id = str(uuid.uuid4())
        payload = {
            "user_id": user_id,
            "text": text[:500],  # Truncate for payload
            "created_at": datetime.now(timezone.utc).isoformat(),
            "type": "user_answer",
            **(metadata or {})
        }

        # Upsert to Qdrant
        self.client.upsert(
            collection_name="episodic_memory",
            points=[PointStruct(
                id=point_id,
                vector=embedding.tolist(),
                payload=payload
            )]
        )

        logger.info(f"âœ… Stored episodic memory for user {user_id}: {point_id}")
        return point_id

    async def store_semantic(
        self,
        user_id: int,
        analysis_text: str,
        turn_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ AI Ð°Ð½Ð°Ð»Ð¸Ð· Ð² semantic_knowledge

        Returns: point_id (UUID)
        """
        embedding = self.embedding_service.encode_semantic(analysis_text)

        point_id = str(uuid.uuid4())
        payload = {
            "user_id": user_id,
            "analysis": analysis_text[:1000],
            "turn_id": turn_id,
            "created_at": datetime.now(timezone.utc).isoformat(),
            "type": "ai_analysis",
            **(metadata or {})
        }

        self.client.upsert(
            collection_name="semantic_knowledge",
            points=[PointStruct(
                id=point_id,
                vector=embedding.tolist(),
                payload=payload
            )]
        )

        logger.info(f"âœ… Stored semantic knowledge for user {user_id}: {point_id}")
        return point_id

    async def store_emotional(
        self,
        user_id: int,
        text: str,
        emotion: str,
        intensity: float = 0.5,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð² emotional_thematic

        Returns: point_id (UUID)
        """
        embedding = self.embedding_service.encode_emotional(text, emotion)

        point_id = str(uuid.uuid4())
        payload = {
            "user_id": user_id,
            "text": text[:500],
            "emotion": emotion,
            "intensity": intensity,
            "created_at": datetime.now(timezone.utc).isoformat(),
            "type": "emotional_pattern",
            **(metadata or {})
        }

        self.client.upsert(
            collection_name="emotional_thematic",
            points=[PointStruct(
                id=point_id,
                vector=embedding.tolist(),
                payload=payload
            )]
        )

        logger.info(f"âœ… Stored emotional pattern for user {user_id}: {emotion}")
        return point_id

    async def store_construct(
        self,
        user_id: int,
        construct_text: str,
        construct_type: str,  # 'core_belief', 'defense_mechanism', etc
        confidence: float = 0.5,
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ‚ Ð² psychological_constructs

        Returns: point_id (UUID)
        """
        embedding = self.embedding_service.encode_construct(construct_text)

        point_id = str(uuid.uuid4())
        payload = {
            "user_id": user_id,
            "text": construct_text,
            "construct_type": construct_type,
            "confidence": confidence,
            "created_at": datetime.now(timezone.utc).isoformat(),
            **(metadata or {})
        }

        self.client.upsert(
            collection_name="psychological_constructs",
            points=[PointStruct(
                id=point_id,
                vector=embedding.tolist(),
                payload=payload
            )]
        )

        logger.info(f"âœ… Stored {construct_type} for user {user_id}: {point_id}")
        return point_id

    async def store_pattern(
        self,
        user_id: int,
        pattern_text: str,
        pattern_type: str,  # 'blind_spot', 'growth_area', etc
        metadata: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ð°-Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½ Ð² meta_patterns

        Returns: point_id (UUID)
        """
        embedding = self.embedding_service.encode_pattern(pattern_text)

        point_id = str(uuid.uuid4())
        payload = {
            "user_id": user_id,
            "text": pattern_text,
            "pattern_type": pattern_type,
            "created_at": datetime.now(timezone.utc).isoformat(),
            **(metadata or {})
        }

        self.client.upsert(
            collection_name="meta_patterns",
            points=[PointStruct(
                id=point_id,
                vector=embedding.tolist(),
                payload=payload
            )]
        )

        logger.info(f"âœ… Stored {pattern_type} for user {user_id}: {point_id}")
        return point_id

    # ===================
    # SEARCH METHODS
    # ===================

    async def search_episodic(
        self,
        user_id: int,
        query: str,
        top_k: int = 10,
        score_threshold: float = 0.5
    ) -> List[Dict[str, Any]]:
        """
        ÐŸÐ¾Ð¸ÑÐº Ð² episodic_memory Ð¿Ð¾ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ
        """
        try:
            query_embedding = self.embedding_service.encode_episodic(query)

            results = self.client.search(
                collection_name="episodic_memory",
                query_vector=query_embedding.tolist(),
                query_filter=Filter(
                    must=[FieldCondition(key="user_id", match=MatchValue(value=user_id))]
                ),
                limit=top_k,
                score_threshold=score_threshold
            )

            return [
                {
                    "id": str(r.id),
                    "score": r.score,
                    "text": r.payload.get("text"),
                    "created_at": r.payload.get("created_at"),
                    **r.payload
                }
                for r in results
            ]
        except Exception as e:
            logger.error(f"âŒ search_episodic failed for user {user_id}: {e}")
            await error_collector.collect(
                error=e,
                service="VectorStorageService",
                component="search_episodic",
                user_id=user_id,
                context={"query_length": len(query), "top_k": top_k}
            )
            return []  # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ

    async def search_emotional(
        self,
        user_id: int,
        query: str,
        emotion: Optional[str] = None,
        top_k: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ÐŸÐ¾Ð¸ÑÐº ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¾Ð²
        """
        query_embedding = self.embedding_service.encode_emotional(query, emotion)

        filter_conditions = [
            FieldCondition(key="user_id", match=MatchValue(value=user_id))
        ]

        if emotion:
            filter_conditions.append(
                FieldCondition(key="emotion", match=MatchValue(value=emotion))
            )

        results = self.client.search(
            collection_name="emotional_thematic",
            query_vector=query_embedding.tolist(),
            query_filter=Filter(must=filter_conditions),
            limit=top_k
        )

        return [
            {
                "id": str(r.id),
                "score": r.score,
                **r.payload
            }
            for r in results
        ]

    async def search_constructs(
        self,
        user_id: int,
        query: str,
        construct_type: Optional[str] = None,
        top_k: int = 10
    ) -> List[Dict[str, Any]]:
        """
        ÐŸÐ¾Ð¸ÑÐº Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐºÑ‚Ð¾Ð²
        """
        query_embedding = self.embedding_service.encode_construct(query)

        filter_conditions = [
            FieldCondition(key="user_id", match=MatchValue(value=user_id))
        ]

        if construct_type:
            filter_conditions.append(
                FieldCondition(key="construct_type", match=MatchValue(value=construct_type))
            )

        results = self.client.search(
            collection_name="psychological_constructs",
            query_vector=query_embedding.tolist(),
            query_filter=Filter(must=filter_conditions),
            limit=top_k
        )

        return [
            {
                "id": str(r.id),
                "score": r.score,
                **r.payload
            }
            for r in results
        ]

    # ===================
    # UTILITY METHODS
    # ===================

    def get_collection_stats(self) -> Dict[str, int]:
        """Get point counts for all collections"""
        stats = {}
        for collection in self.collections:
            try:
                info = self.client.get_collection(collection)
                stats[collection] = info.points_count
            except Exception as e:
                stats[collection] = -1
                logger.error(f"Failed to get stats for {collection}: {e}")
        return stats

    def health_check(self) -> bool:
        """Check Qdrant connectivity"""
        try:
            self.client.get_collections()
            return True
        except Exception as e:
            logger.error(f"Qdrant health check failed: {e}")
            return False


# Singleton
_vector_storage = None

def get_vector_storage() -> VectorStorageService:
    """Get singleton VectorStorageService instance"""
    global _vector_storage
    if _vector_storage is None:
        _vector_storage = VectorStorageService()
    return _vector_storage
