#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ Qdrant
–¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö answer_analysis –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏–º–µ—é—Ç –≤–µ–∫—Ç–æ—Ä–æ–≤.
"""

import asyncio
import os
import sys
import asyncpg
import json
from datetime import datetime
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from selfology_bot.analysis.embedding_creator import EmbeddingCreator


async def get_analyses_for_user(user_id: int):
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ answer_analysis –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ user_answer_id)"""

    conn = await asyncpg.connect(
        host=os.getenv("DB_HOST", "localhost"),
        port=int(os.getenv("DB_PORT", 5432)),
        user=os.getenv("DB_USER", "n8n"),
        password=os.getenv("DB_PASSWORD", "sS67wM+1zMBRFHAW4kj9HwFl5J6+veo7Nirx0/I+oiU="),
        database=os.getenv("DB_NAME", "n8n")
    )

    try:
        rows = await conn.fetch("""
            WITH latest_analysis AS (
                SELECT
                    aa.id,
                    aa.user_answer_id,
                    aa.raw_ai_response,
                    ua.raw_answer,
                    ua.question_json_id,
                    ROW_NUMBER() OVER (PARTITION BY aa.user_answer_id ORDER BY aa.id DESC) as rn
                FROM selfology.answer_analysis aa
                JOIN selfology.user_answers_new ua ON aa.user_answer_id = ua.id
                JOIN selfology.onboarding_sessions os ON ua.session_id = os.id
                WHERE os.user_id = $1
                  AND aa.raw_ai_response IS NOT NULL
            )
            SELECT id, user_answer_id, raw_ai_response, raw_answer, question_json_id
            FROM latest_analysis
            WHERE rn = 1
            ORDER BY user_answer_id
        """, user_id)

        return rows

    finally:
        await conn.close()


async def create_vectors_for_analysis(
    analysis_id: int,
    user_answer_id: int,
    raw_ai_response: dict,
    raw_answer: str,
    question_json_id: str,
    user_id: int
):
    """–°–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –≤ Qdrant –¥–ª—è –æ–¥–Ω–æ–≥–æ analysis"""

    print(f"\n  üìù Answer #{user_answer_id} (q_{question_json_id})")
    print(f"     Analysis ID: {analysis_id}")

    try:
        embedding_creator = EmbeddingCreator()
        print(f"     üîç OpenAI client initialized: {embedding_creator.openai_client is not None}")
        print(f"     üîç Qdrant client initialized: {embedding_creator.qdrant_client is not None}")

        # raw_ai_response –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π JSON - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        if isinstance(raw_ai_response, str):
            try:
                raw_ai_response = json.loads(raw_ai_response)
            except json.JSONDecodeError:
                print(f"     ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å raw_ai_response")
                return False

        # –ò–∑–≤–ª–µ–∫–∞–µ–º personality_summary –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        personality_summary = raw_ai_response.get('personality_summary', {})

        if not personality_summary:
            print(f"     ‚ùå personality_summary –ø—É—Å—Ç –≤ raw_ai_response")
            return False

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å raw_ai_response + –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
        analysis_result = dict(raw_ai_response)  # –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ –ø–æ–ª—è
        analysis_result["answer_text"] = raw_answer
        analysis_result["question_id"] = question_json_id
        analysis_result["timestamp"] = datetime.now().isoformat()

        print(f"     üî¨ –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ Qdrant...")
        print(f"     üîç personality_summary keys: {list(personality_summary.keys())}")
        print(f"     üîç has 'narrative': {'narrative' in personality_summary}")
        print(f"     üîç has 'nano': {'nano' in personality_summary}")
        print(f"     üîç narrative length: {len(str(personality_summary.get('narrative', '')))}")
        print(f"     üîç nano length: {len(str(personality_summary.get('nano', '')))}")

        # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã (is_update=True —á—Ç–æ–±—ã –Ω–µ —Ä—É–≥–∞–ª—Å—è –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)
        success = await embedding_creator.create_personality_vector(
            user_id=user_id,
            analysis_result=analysis_result,
            is_update=True
        )

        print(f"     üîç create_personality_vector returned: {success}")

        if success:
            print(f"     ‚úÖ –í–µ–∫—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–Ω—ã")
            return True
        else:
            print(f"     ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ (check logs)")
            # –î–æ–±–∞–≤–∏–º –¥–µ–±–∞–≥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            print(f"     üîç Debug: analysis_result keys = {list(analysis_result.keys())}")
            print(f"     üîç Debug: personality_summary type = {type(analysis_result['personality_summary'])}")
            if isinstance(analysis_result['personality_summary'], dict):
                print(f"     üîç Debug: personality_summary keys = {list(analysis_result['personality_summary'].keys())}")
            return False

    except Exception as e:
        print(f"     ‚ùå EXCEPTION: {e}")
        import traceback
        traceback.print_exc()
        return False


async def reprocess_vectors(user_id: int, dry_run: bool = False):
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –≤—Å–µ—Ö analyses –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

    print(f"\n{'='*60}")
    print(f"üîÑ REPROCESS VECTORS FOR USER {user_id}")
    print(f"{'='*60}")

    if dry_run:
        print("‚ö†Ô∏è  DRY RUN —Ä–µ–∂–∏–º - –∏–∑–º–µ–Ω–µ–Ω–∏—è –ù–ï –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\n")

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ analyses
    print("üìä –ü–æ–ª—É—á–∞–µ–º analyses –∏–∑ –ë–î...")
    analyses = await get_analyses_for_user(user_id)

    print(f"   –ù–∞–π–¥–µ–Ω–æ: {len(analyses)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö analyses")

    if len(analyses) == 0:
        print("\n‚úÖ –ù–µ—Ç analyses –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        return

    if dry_run:
        print("\nüìã –°–ø–∏—Å–æ–∫ analyses –¥–ª—è reprocess:")
        for row in analyses:
            print(f"  - Analysis #{row['id']}, Answer #{row['user_answer_id']}, Question: q_{row['question_json_id']}")
        print(f"\n–î–ª—è –∑–∞–ø—É—Å–∫–∞ reprocess —É–¥–∞–ª–∏—Ç–µ —Ñ–ª–∞–≥ --dry-run")
        return

    # Reprocess –∫–∞–∂–¥–æ–≥–æ
    success_count = 0
    failed_count = 0

    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º reprocess...\n")

    for row in analyses:
        success = await create_vectors_for_analysis(
            analysis_id=row['id'],
            user_answer_id=row['user_answer_id'],
            raw_ai_response=row['raw_ai_response'],
            raw_answer=row['raw_answer'],
            question_json_id=row['question_json_id'],
            user_id=user_id
        )

        if success:
            success_count += 1
        else:
            failed_count += 1

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        await asyncio.sleep(1)

    # –ò—Ç–æ–≥–∏
    print(f"\n{'='*60}")
    print(f"üìä –ò–¢–û–ì–ò REPROCESS")
    print(f"{'='*60}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {success_count}")
    print(f"‚ùå –û—à–∏–±–∫–∏: {failed_count}")
    print(f"üìà –í—Å–µ–≥–æ: {len(analyses)}")

    if success_count == len(analyses):
        print(f"\nüéâ –í–°–ï –í–ï–ö–¢–û–†–´ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–´!")
        print(f"\nüí° –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å—Ç–∏—Ç–µ /onboarding_profile –≤ Telegram –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
    else:
        print(f"\n‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å")


async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""

    if len(sys.argv) < 2:
        print("Usage: python reprocess_vectors_simple.py <user_id> [--dry-run]")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python reprocess_vectors_simple.py 98005572")
        print("  python reprocess_vectors_simple.py 98005572 --dry-run")
        sys.exit(1)

    user_id = int(sys.argv[1])
    dry_run = "--dry-run" in sys.argv

    await reprocess_vectors(user_id, dry_run=dry_run)


if __name__ == "__main__":
    asyncio.run(main())
