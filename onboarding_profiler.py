#!/usr/bin/env python3
"""
üî¨ Selfology Onboarding Profiler v2.0
–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ü–∏—Ñ—Ä–æ–≤–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê –û–¢–ß–ï–¢–ê:
1. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ (–ø–µ—Ä–≤—ã–º –±–ª–æ–∫–æ–º)
2. üí¨ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º
3. üìà –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (Qdrant)
4. üîÑ –ê–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è (–∫—Ä–∞—Ç–∫–æ)
"""

import asyncio
import json
import requests
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker


class OnboardingProfiler:
    """–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫ —Å–∏—Å—Ç–µ–º—ã –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ —Ü–∏—Ñ—Ä–æ–≤—É—é –ª–∏—á–Ω–æ—Å—Ç—å"""

    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–ª—è Telegram)
    DIVIDER_MAIN = "=" * 44  # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç–µ–º
    DIVIDER_SUB = "‚îÅ" * 44   # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–æ–¥—Ç–µ–º
    MAX_WIDTH = 44           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏

    def __init__(self):
        self.DATABASE_URL = "postgresql+asyncpg://n8n:sS67wM+1zMBRFHAW4kj9HwFl5J6+veo7Nirx0/I+oiU=@localhost:5432/n8n"
        self.engine = create_async_engine(self.DATABASE_URL, echo=False)
        self.async_session = sessionmaker(self.engine, class_=AsyncSession, expire_on_commit=False)
        self.qdrant_url = "http://localhost:6333"

    async def get_all_user_answers(self, user_id: int) -> List[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –í–°–ï –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞ –≤—Å–µ –≤—Ä–µ–º—è

        –í–ö–õ–Æ–ß–ê–ï–¢:
        - –û–±—ã—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏–∑ user_answers_new
        - Context stories –∏–∑ user_context_stories

        Returns:
            List of answers with analysis info + processing statuses
        """
        async with self.async_session() as session:
            result = await session.execute(text("""
                -- –û–±—ã—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (–±–µ—Ä–µ–º –ü–û–°–õ–ï–î–ù–ò–ô –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
                SELECT
                    ua.id as answer_id,
                    ua.session_id,
                    ua.question_json_id,
                    ua.raw_answer,
                    ua.answer_length,
                    ua.answered_at,
                    ua.analysis_status,
                    aa.id as analysis_id,
                    aa.ai_model_used,
                    aa.processing_time_ms,
                    aa.quality_score,
                    aa.confidence_score,
                    aa.raw_ai_response,
                    aa.vectorization_status,
                    aa.vectorization_error,
                    aa.dp_update_status,
                    aa.dp_update_error,
                    aa.background_task_completed,
                    aa.background_task_duration_ms,
                    aa.retry_count,
                    'answer' as item_type
                FROM selfology.user_answers_new ua
                JOIN selfology.onboarding_sessions os ON ua.session_id = os.id
                LEFT JOIN LATERAL (
                    SELECT * FROM selfology.answer_analysis
                    WHERE user_answer_id = ua.id
                    ORDER BY id DESC
                    LIMIT 1
                ) aa ON true
                WHERE os.user_id = :user_id

                UNION ALL

                -- Context stories (–±–µ—Ä–µ–º –ü–û–°–õ–ï–î–ù–ò–ô –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ story)
                SELECT
                    cs.id as answer_id,
                    cs.session_id,
                    'system_context_story' as question_json_id,
                    cs.story_text as raw_answer,
                    LENGTH(cs.story_text) as answer_length,
                    cs.created_at as answered_at,
                    'completed' as analysis_status,
                    aa.id as analysis_id,
                    aa.ai_model_used,
                    aa.processing_time_ms,
                    aa.quality_score,
                    aa.confidence_score,
                    aa.raw_ai_response,
                    aa.vectorization_status,
                    aa.vectorization_error,
                    aa.dp_update_status,
                    aa.dp_update_error,
                    aa.background_task_completed,
                    aa.background_task_duration_ms,
                    aa.retry_count,
                    'story' as item_type
                FROM selfology.user_context_stories cs
                LEFT JOIN LATERAL (
                    SELECT * FROM selfology.answer_analysis
                    WHERE context_story_id = cs.id
                    ORDER BY id DESC
                    LIMIT 1
                ) aa ON true
                WHERE cs.user_id = :user_id AND cs.is_active = true

                ORDER BY answered_at ASC
            """), {"user_id": user_id})

            answers = []
            for row in result:
                answers.append({
                    "answer_id": row[0],
                    "session_id": row[1],
                    "question_json_id": row[2],
                    "raw_answer": row[3],
                    "answer_length": row[4],
                    "answered_at": row[5],
                    "analysis_status": row[6],
                    "analysis_id": row[7],
                    "ai_model_used": row[8],
                    "processing_time_ms": row[9],
                    "quality_score": row[10],
                    "confidence_score": row[11],
                    "raw_ai_response": row[12],
                    "vectorization_status": row[13],
                    "vectorization_error": row[14],
                    "dp_update_status": row[15],
                    "dp_update_error": row[16],
                    "background_task_completed": row[17],
                    "background_task_duration_ms": row[18],
                    "retry_count": row[19],
                    "item_type": row[20]  # 'answer' –∏–ª–∏ 'story'
                })

            return answers

    async def get_digital_personality(self, user_id: int) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å digital personality –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        async with self.async_session() as session:
            result = await session.execute(text("""
                SELECT
                    identity, interests, goals, barriers,
                    relationships, values, current_state,
                    skills, experiences, health,
                    total_answers_analyzed,
                    completeness_score,
                    last_updated
                FROM selfology.digital_personality
                WHERE user_id = :user_id
            """), {"user_id": user_id})

            row = result.fetchone()
            if not row:
                return None

            return {
                "identity": row[0],
                "interests": row[1],
                "goals": row[2],
                "barriers": row[3],
                "relationships": row[4],
                "values": row[5],
                "current_state": row[6],
                "skills": row[7],
                "experiences": row[8],
                "health": row[9],
                "total_answers_analyzed": row[10],
                "completeness_score": row[11],
                "last_updated": row[12]
            }

    async def get_active_session(self, user_id: int) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        async with self.async_session() as session:
            result = await session.execute(text("""
                SELECT
                    id, status, questions_asked, questions_answered,
                    last_strategy, domains_covered, heavy_count,
                    started_at
                FROM selfology.onboarding_sessions
                WHERE user_id = :user_id AND status = 'active'
                ORDER BY started_at DESC
                LIMIT 1
            """), {"user_id": user_id})

            row = result.fetchone()
            if not row:
                return None

            return {
                "id": row[0],
                "status": row[1],
                "questions_asked": row[2],
                "questions_answered": row[3],
                "last_strategy": row[4],
                "domains_covered": row[5] or [],
                "heavy_count": row[6],
                "started_at": row[7]
            }

    async def get_recent_sessions(self, user_id: int, limit: int = 2) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–µ—Å—Å–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≤–∫–ª—é—á–∞—è –∞–∫—Ç–∏–≤–Ω—É—é)"""
        async with self.async_session() as session:
            result = await session.execute(text("""
                SELECT
                    id, status, questions_asked, questions_answered,
                    started_at
                FROM selfology.onboarding_sessions
                WHERE user_id = :user_id
                ORDER BY started_at DESC
                LIMIT :limit
            """), {"user_id": user_id, "limit": limit})

            sessions = []
            for row in result:
                sessions.append({
                    "id": row[0],
                    "status": row[1],
                    "questions_asked": row[2],
                    "questions_answered": row[3],
                    "started_at": row[4]
                })
            return sessions

    def check_qdrant_vectors(self, user_id: int) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Qdrant

        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –ø–æ –∫–∞–∂–¥–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        """
        collections_info = {}
        target_collections = [
            "personality_evolution",
            "personality_profiles",
            "quick_match"
        ]

        try:
            for collection_name in target_collections:
                try:
                    # Scroll —á–µ—Ä–µ–∑ –≤—Å–µ —Ç–æ—á–∫–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ user_id
                    response = requests.post(
                        f"{self.qdrant_url}/collections/{collection_name}/points/scroll",
                        json={
                            "filter": {
                                "must": [
                                    {"key": "user_id", "match": {"value": user_id}}
                                ]
                            },
                            "limit": 1000,
                            "with_payload": True
                        },
                        timeout=5
                    )

                    if response.status_code == 200:
                        data = response.json()
                        points = data.get("result", {}).get("points", [])

                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π timestamp
                        last_update = None
                        if points:
                            timestamps = [
                                p.get("payload", {}).get("timestamp")
                                for p in points
                                if p.get("payload", {}).get("timestamp")
                            ]
                            if timestamps:
                                last_update = max(timestamps)

                        collections_info[collection_name] = {
                            "count": len(points),
                            "last_update": last_update,
                            "status": "ok"
                        }
                    else:
                        collections_info[collection_name] = {
                            "count": 0,
                            "status": f"error_{response.status_code}"
                        }

                except Exception as e:
                    collections_info[collection_name] = {
                        "count": 0,
                        "status": f"error: {str(e)}"
                    }

        except Exception as e:
            # –û–±—â–∞—è –æ—à–∏–±–∫–∞ Qdrant
            for col in target_collections:
                collections_info[col] = {
                    "count": 0,
                    "status": "qdrant_unavailable"
                }

        return collections_info

    def format_statistics_section(
        self,
        user_id: int,
        answers: List[Dict],
        personality: Optional[Dict],
        qdrant_info: Dict
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–∫—Ü–∏—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""

        total_answers = len(answers)
        analyzed_count = sum(1 for a in answers if a['analysis_id'] is not None)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –≤ Qdrant (—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 1 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å)
        qdrant_profile_exists = qdrant_info.get("personality_profiles", {}).get("count", 0) > 0
        qdrant_last_update = qdrant_info.get("personality_profiles", {}).get("last_update")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º digital personality (—Ç–æ–∂–µ 1 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å)
        dp_exists = personality is not None
        dp_last_update = personality.get("last_updated") if personality else None

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏
        completeness = int(personality.get("completeness_score", 0) * 100) if personality else 0

        output = []
        output.append(self.DIVIDER_MAIN)
        output.append("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ù–ë–û–†–î–ò–ù–ì–ê")
        output.append(self.DIVIDER_MAIN)
        output.append("")
        output.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: #{user_id}")
        output.append(f"–í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤: {total_answers}")
        output.append("")
        output.append(self.DIVIDER_SUB)
        output.append("–≠–¢–ê–ü–´ –û–ë–†–ê–ë–û–¢–ö–ò:")
        output.append(self.DIVIDER_SUB)

        # –≠—Ç–∞–ø—ã
        output.append(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ SQL:      {total_answers} –æ—Ç–≤–µ—Ç–æ–≤")

        ai_pct = int(analyzed_count / total_answers * 100) if total_answers > 0 else 0
        output.append(f"{'‚úÖ' if ai_pct == 100 else '‚ö†Ô∏è'} AI –ê–Ω–∞–ª–∏–∑:            {analyzed_count} / {total_answers} ({ai_pct}%)")

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ñ–∏–ª—è
        if qdrant_profile_exists:
            update_info = f" (–æ–±–Ω–æ–≤–ª–µ–Ω: {qdrant_last_update})" if qdrant_last_update else ""
            output.append(f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å –≤ Qdrant:    —Å–æ–∑–¥–∞–Ω{update_info}")
        else:
            output.append(f"‚ùå –ü—Ä–æ—Ñ–∏–ª—å –≤ Qdrant:    –Ω–µ —Å–æ–∑–¥–∞–Ω")

        # Digital Personality - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ñ–∏–ª—è
        if dp_exists:
            update_info = f" (–æ–±–Ω–æ–≤–ª–µ–Ω–∞: {dp_last_update.strftime('%Y-%m-%d %H:%M')})" if dp_last_update else ""
            output.append(f"‚úÖ Digital Personality: —Å–æ–∑–¥–∞–Ω–∞{update_info}")
        else:
            output.append(f"‚ùå Digital Personality: –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")

        # Digital Personality —Å–µ–∫—Ü–∏—è
        if personality:
            output.append("")
            output.append(self.DIVIDER_SUB)
            output.append("–¶–ò–§–†–û–í–ê–Ø –õ–ò–ß–ù–û–°–¢–¨:")
            output.append(self.DIVIDER_SUB)
            output.append(f"Completeness: {completeness}%")

            last_update = personality.get("last_updated")
            if last_update:
                output.append(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {last_update.strftime('%Y-%m-%d %H:%M')}")

            output.append("")
            output.append("–ó–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å–ª–æ–∏:")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å–ª–æ–π
            layers = [
                ("identity", "–ª–∏—á–Ω–æ—Å—Ç—å"),
                ("interests", "–∏–Ω—Ç–µ—Ä–µ—Å—ã"),
                ("goals", "—Ü–µ–ª–∏"),
                ("barriers", "–±–∞—Ä—å–µ—Ä—ã"),
                ("relationships", "–æ—Ç–Ω–æ—à–µ–Ω–∏—è"),
                ("values", "—Ü–µ–Ω–Ω–æ—Å—Ç–∏"),
                ("current_state", "—Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"),
                ("skills", "–Ω–∞–≤—ã–∫–∏"),
                ("experiences", "–æ–ø—ã—Ç"),
                ("health", "–∑–¥–æ—Ä–æ–≤—å–µ")
            ]

            for layer_key, layer_name in layers:
                layer_data = personality.get(layer_key, [])
                if isinstance(layer_data, list):
                    count = len(layer_data)
                elif isinstance(layer_data, dict):
                    count = len(layer_data)
                else:
                    count = 0

                status = "‚úÖ" if count > 0 else "‚ùå"
                output.append(f"  {status} {layer_name}: {count} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        else:
            output.append("")
            output.append("‚ö†Ô∏è Digital Personality –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")

        return "\n".join(output)

    def format_answers_section(self, answers: List[Dict], qdrant_info: Dict, recent_session_ids: List[int]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–∫—Ü–∏—é –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º

        –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ:
        - –û—Ç–≤–µ—Ç—ã –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 2 —Å–µ—Å—Å–∏–π (—Ç–µ–∫—É—â–∞—è + –ø—Ä–µ–¥—ã–¥—É—â–∞—è)
        - –û—Ç–≤–µ—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏ (–∏–∑ –ª—é–±—ã—Ö —Å–µ—Å—Å–∏–π)
        """

        # –§–∏–ª—å—Ç—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
        filtered_answers = []
        for answer in answers:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫
            has_error = (
                answer.get('vectorization_status') == 'failed' or
                answer.get('dp_update_status') == 'failed' or
                answer.get('vectorization_error') or
                answer.get('dp_update_error')
            )

            # –í–∫–ª—é—á–∞–µ–º –µ—Å–ª–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 2 —Å–µ—Å—Å–∏–π –ò–õ–ò –µ—Å—Ç—å –æ—à–∏–±–∫–∞
            if answer['session_id'] in recent_session_ids or has_error:
                filtered_answers.append(answer)

        output = []
        output.append("")
        output.append(self.DIVIDER_MAIN)
        output.append("üí¨ –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –í–û–ü–†–û–°–ê–ú")
        output.append(self.DIVIDER_MAIN)

        if not filtered_answers:
            output.append("")
            output.append("–ù–µ—Ç –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            output.append("")
            return "\n".join(output)

        output.append(f"")
        output.append(f"–ü–æ–∫–∞–∑–∞–Ω–æ: {len(filtered_answers)} –∏–∑ {len(answers)} –æ—Ç–≤–µ—Ç–æ–≤")
        output.append(f"(–ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–µ—Å—Å–∏–∏ + –æ—Ç–≤–µ—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏)")
        output.append("")

        for i, answer in enumerate(filtered_answers, 1):
            # ‚úÖ –†–ï–ê–õ–¨–ù–´–ï –°–¢–ê–¢–£–°–´ –∏–∑ –ë–î (–Ω–µ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –∞ —Ä–µ–∞–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)
            sql_status = "‚úÖ"
            ai_status = "‚úÖ" if answer['analysis_id'] else "‚ùå"

            # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –†–ï–ê–õ–¨–ù–´–ô —Å—Ç–∞—Ç—É—Å –∏–∑ –ë–î
            vectorization_status = answer.get('vectorization_status', 'pending')
            if vectorization_status == 'success':
                qdrant_status = "‚úÖ"
            elif vectorization_status == 'failed':
                qdrant_status = "‚ùå"
            else:  # pending
                qdrant_status = "‚è≥"

            # DP update - –∏—Å–ø–æ–ª—å–∑—É–µ–º –†–ï–ê–õ–¨–ù–´–ô —Å—Ç–∞—Ç—É—Å –∏–∑ –ë–î
            dp_status_value = answer.get('dp_update_status', 'pending')
            if dp_status_value == 'success':
                dp_status = "‚úÖ"
            elif dp_status_value == 'failed':
                dp_status = "‚ùå"
            else:  # pending
                dp_status = "‚è≥"

            # Background task —Å—Ç–∞—Ç—É—Å
            task_completed = answer.get('background_task_completed', False)
            task_mark = "‚ö°" if task_completed else "‚è≥"

            # Retry count
            retry_count = answer.get('retry_count') or 0
            retry_mark = f" üîÑx{retry_count}" if retry_count > 0 else ""

            # –î–æ–±–∞–≤–ª—è–µ–º [STORY] –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è context stories
            item_prefix = "[STORY] " if answer.get('item_type') == 'story' else ""
            output.append(f"#{i}  {item_prefix}{answer['question_json_id']}  {sql_status}SQL {ai_status}AI {qdrant_status}Qdrant {dp_status}–õ–∏—á–Ω–æ—Å—Ç—å {task_mark}{retry_mark}")

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            if answer['analysis_id']:
                model = answer['ai_model_used'] or "unknown"
                time_ms = answer['processing_time_ms'] or 0
                quality = answer['quality_score'] or 0.0
                confidence = answer['confidence_score'] or 0.0
                task_duration = answer.get('background_task_duration_ms')

                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–Ω–∞–ª–∏–∑–µ
                task_info = f", Task:{task_duration}ms" if task_duration else ""
                output.append(f"    –ê–Ω–∞–ª–∏–∑: {model} ({time_ms}ms{task_info}, Q:{quality:.2f}, C:{confidence:.2f})")

                # ‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
                vec_error = answer.get('vectorization_error')
                if vec_error:
                    short_error = vec_error[:50] + "..." if len(vec_error) > 50 else vec_error
                    output.append(f"    ‚ùå –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è: {short_error}")

                dp_error = answer.get('dp_update_error')
                if dp_error:
                    short_error = dp_error[:50] + "..." if len(dp_error) > 50 else dp_error
                    output.append(f"    ‚ùå DP Update: {short_error}")

                # –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ª–∏—á–Ω–æ—Å—Ç—å (–∏–∑ raw_ai_response)
                if answer['raw_ai_response']:
                    try:
                        ai_response = answer['raw_ai_response']
                        if isinstance(ai_response, str):
                            ai_response = json.loads(ai_response)

                        personality_summary = ai_response.get("personality_summary", {})
                        if personality_summary:
                            affected_layers = [k for k, v in personality_summary.items() if v]
                            if affected_layers:
                                layers_str = ", ".join(affected_layers[:3])  # –ü–µ—Ä–≤—ã–µ 3
                                output.append(f"    –í–ª–∏—è–Ω–∏–µ: {layers_str}")
                    except:
                        pass
            else:
                output.append(f"    –°—Ç–∞—Ç—É—Å: AI –∞–Ω–∞–ª–∏–∑ pending")

            output.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–∞–º–∏

        return "\n".join(output)

    def format_qdrant_section(self, user_id: int, qdrant_info: Dict, answers_count: int = 0) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–∫—Ü–∏—é Qdrant –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏"""

        output = []
        output.append(self.DIVIDER_MAIN)
        output.append("üìà –í–ï–ö–¢–û–†–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (Qdrant)")
        output.append(self.DIVIDER_MAIN)
        output.append("")

        collections = [
            ("personality_evolution", "3072D", "–≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑"),
            ("personality_profiles", "1536D", "–ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ"),
            ("quick_match", "512D", "–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫")
        ]

        counts = []

        for col_name, dimension, purpose in collections:
            col_info = qdrant_info.get(col_name, {})
            count = col_info.get("count", 0)
            status = col_info.get("status", "unknown")

            counts.append(count)

            output.append(f"{col_name} ({dimension}):")
            output.append(f"  –í–µ–∫—Ç–æ—Ä–æ–≤: {count}")
            output.append(f"  –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {purpose}")

            if col_info.get("last_update"):
                output.append(f"  –ü–æ—Å–ª–µ–¥–Ω–∏–π: {col_info['last_update']}")

            if status != "ok":
                output.append(f"  ‚ö†Ô∏è –°—Ç–∞—Ç—É—Å: {status}")

            output.append("")

        # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å —É—á–µ—Ç–æ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
        # personality_evolution: 2 –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –æ—Ç–≤–µ—Ç (evolution_point + breakthrough_snapshot)
        # personality_profiles: 1 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        # quick_match: 1 –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        output.append(self.DIVIDER_SUB)

        expected_evolution = answers_count * 2  # 2 –≤–µ–∫—Ç–æ—Ä–∞ –Ω–∞ –æ—Ç–≤–µ—Ç
        expected_profile = 1 if answers_count > 0 else 0
        expected_match = 1 if answers_count > 0 else 0

        is_synced = (
            counts[0] == expected_evolution and
            counts[1] == expected_profile and
            counts[2] == expected_match
        )

        if is_synced:
            output.append(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã [{counts[0]}, {counts[1]}, {counts[2]}]")
            output.append(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: [{expected_evolution}, {expected_profile}, {expected_match}] –¥–ª—è {answers_count} –æ—Ç–≤–µ—Ç–æ–≤")
        else:
            output.append("‚ö†Ô∏è –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")
            output.append(f"   –¢–µ–∫—É—â–µ–µ: [{counts[0]}, {counts[1]}, {counts[2]}]")
            output.append(f"   –û–∂–∏–¥–∞–ª–æ—Å—å: [{expected_evolution}, {expected_profile}, {expected_match}] –¥–ª—è {answers_count} –æ—Ç–≤–µ—Ç–æ–≤")

        return "\n".join(output)

    def format_session_section(self, session: Optional[Dict]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–µ–∫—Ü–∏—é –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏"""

        output = []
        output.append("")
        output.append(self.DIVIDER_MAIN)
        output.append("üîÑ –ê–ö–¢–ò–í–ù–ê–Ø –°–ï–°–°–ò–Ø")
        output.append(self.DIVIDER_MAIN)
        output.append("")

        if not session:
            output.append("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏")
            return "\n".join(output)

        output.append(f"Session ID: {session['id']}")
        output.append(f"–°—Ç–∞—Ç—É—Å: {session['status']}")

        strategy = session.get('last_strategy', 'Not set')
        output.append(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy}")

        answered = session.get('questions_answered', 0)
        target_questions = 20  # –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –∑–∞ —Å–µ—Å—Å–∏—é
        output.append(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {answered} / {target_questions} –≤–æ–ø—Ä–æ—Å–æ–≤ ({int(answered/target_questions*100) if answered <= target_questions else 100}%)")

        domains = session.get('domains_covered', [])
        if domains:
            output.append(f"–î–æ–º–µ–Ω—ã: {', '.join(domains)} ({len(domains)}/13)")

        heavy = session.get('heavy_count', 0)
        output.append(f"Heavy –≤–æ–ø—Ä–æ—Å–æ–≤: {heavy}")

        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏
        started = session.get('started_at')
        if started:
            duration = datetime.now() - started
            hours = int(duration.total_seconds() / 3600)
            minutes = int((duration.total_seconds() % 3600) / 60)
            output.append(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {hours}—á {minutes}–º–∏–Ω")

        return "\n".join(output)

    async def profile_user(self, user_id: int) -> str:
        """
        –ü–æ–ª–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        """

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        answers = await self.get_all_user_answers(user_id)
        personality = await self.get_digital_personality(user_id)
        session = await self.get_active_session(user_id)
        recent_sessions = await self.get_recent_sessions(user_id, limit=2)
        qdrant_info = self.check_qdrant_vectors(user_id)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 2 —Å–µ—Å—Å–∏–π –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        recent_session_ids = [s['id'] for s in recent_sessions]

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ digital personality –≤ qdrant_info –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        qdrant_info["dp_exists"] = personality is not None

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏–∏
        sections = []

        # 1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–ø–µ—Ä–≤—ã–º)
        sections.append(self.format_statistics_section(user_id, answers, personality, qdrant_info))

        # 2. –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —Å–µ—Å—Å–∏–∏ + –æ—à–∏–±–∫–∏)
        if answers:
            sections.append(self.format_answers_section(answers, qdrant_info, recent_session_ids))

        # 3. Qdrant –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ø–∞–º—è—Ç—å
        sections.append(self.format_qdrant_section(user_id, qdrant_info, len(answers)))

        # 4. –ê–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è (–≤ –∫–æ–Ω—Ü–µ)
        sections.append(self.format_session_section(session))

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–º–µ—Å—Ç–µ
        full_report = "\n".join(sections)

        return full_report


async def main():
    """Main entry point"""
    import sys

    user_id = 98005572  # Default user

    if len(sys.argv) > 1:
        try:
            user_id = int(sys.argv[1])
        except ValueError:
            print(f"‚ùå Invalid user_id: {sys.argv[1]}")
            sys.exit(1)

    profiler = OnboardingProfiler()
    report = await profiler.profile_user(user_id)

    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    print(report)


if __name__ == "__main__":
    asyncio.run(main())
